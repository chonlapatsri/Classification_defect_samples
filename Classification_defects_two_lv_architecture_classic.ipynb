{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This jupyter notebook contains a sample code that represents my work on classification machine learning model to predict Labels\n",
    "\n",
    "**caveat: the performance of the model given the dummy dataset is terrible. It was much better with a dataset for the problem that it meant to solve. This highlights the importance of the quality of data for machine learning.\n",
    "\n",
    "\n",
    "we start by creating a dummy dataset before proceeding to data preparation, model building, hyperparameter tuning, and evaluation of different classical and ensemble algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset Preparation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defect_1</th>\n",
       "      <th>defect_2</th>\n",
       "      <th>defect_3</th>\n",
       "      <th>defect_4</th>\n",
       "      <th>defect_5</th>\n",
       "      <th>defect_1_Type</th>\n",
       "      <th>defect_2_Type</th>\n",
       "      <th>defect_3_Type</th>\n",
       "      <th>defect_4_Type</th>\n",
       "      <th>defect_5_Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Youden</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>ROC_Curve</th>\n",
       "      <th>PR_Curve</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822777</td>\n",
       "      <td>0.435442</td>\n",
       "      <td>0.969205</td>\n",
       "      <td>0.300649</td>\n",
       "      <td>0.344244</td>\n",
       "      <td>0.990124</td>\n",
       "      <td>0.194701</td>\n",
       "      <td>0.855578</td>\n",
       "      <td>0.729733</td>\n",
       "      <td>0.575982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287993</td>\n",
       "      <td>0.570625</td>\n",
       "      <td>0.492448</td>\n",
       "      <td>0.199096</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.321194</td>\n",
       "      <td>0.603665</td>\n",
       "      <td>0.367773</td>\n",
       "      <td>0.385339</td>\n",
       "      <td>0.218806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973183</td>\n",
       "      <td>0.746135</td>\n",
       "      <td>0.836329</td>\n",
       "      <td>0.061496</td>\n",
       "      <td>0.684760</td>\n",
       "      <td>0.893113</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.087472</td>\n",
       "      <td>0.197169</td>\n",
       "      <td>0.404432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167534</td>\n",
       "      <td>0.874471</td>\n",
       "      <td>0.321978</td>\n",
       "      <td>0.385309</td>\n",
       "      <td>0.487941</td>\n",
       "      <td>0.999110</td>\n",
       "      <td>0.445915</td>\n",
       "      <td>0.067640</td>\n",
       "      <td>0.896716</td>\n",
       "      <td>0.650193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910177</td>\n",
       "      <td>0.305891</td>\n",
       "      <td>0.239071</td>\n",
       "      <td>0.823517</td>\n",
       "      <td>0.849586</td>\n",
       "      <td>0.157490</td>\n",
       "      <td>0.097317</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0.728263</td>\n",
       "      <td>0.608657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   defect_1  defect_2  defect_3  defect_4  defect_5 defect_1_Type  \\\n",
       "0         0         1         0         0         1             D   \n",
       "1         0         0         0         1         0             C   \n",
       "2         1         1         1         0         1             B   \n",
       "3         1         1         0         0         1             A   \n",
       "4         0         0         0         0         1             B   \n",
       "\n",
       "  defect_2_Type defect_3_Type defect_4_Type defect_5_Type  ...    Recall  \\\n",
       "0             D             C             C             B  ...  0.822777   \n",
       "1             A             A             C             A  ...  0.287993   \n",
       "2             B             B             D             A  ...  0.973183   \n",
       "3             B             B             A             B  ...  0.167534   \n",
       "4             D             A             A             A  ...  0.910177   \n",
       "\n",
       "        TPR       FPR       TNR       FNR    Youden Balanced_Accuracy  \\\n",
       "0  0.435442  0.969205  0.300649  0.344244  0.990124          0.194701   \n",
       "1  0.570625  0.492448  0.199096  0.053197  0.321194          0.603665   \n",
       "2  0.746135  0.836329  0.061496  0.684760  0.893113          0.529915   \n",
       "3  0.874471  0.321978  0.385309  0.487941  0.999110          0.445915   \n",
       "4  0.305891  0.239071  0.823517  0.849586  0.157490          0.097317   \n",
       "\n",
       "   ROC_Curve  PR_Curve        AP  \n",
       "0   0.855578  0.729733  0.575982  \n",
       "1   0.367773  0.385339  0.218806  \n",
       "2   0.087472  0.197169  0.404432  \n",
       "3   0.067640  0.896716  0.650193  \n",
       "4   0.125099  0.728263  0.608657  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dummy dataset of 100,000 rows in total that fit the problem\n",
    "# Define the number of rows for each dataframe\n",
    "num_rows = 100000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'defect_1': np.random.randint(0, 2, size=num_rows),\n",
    "    'defect_2': np.random.randint(0, 2, size=num_rows),\n",
    "    'defect_3': np.random.randint(0, 2, size=num_rows),\n",
    "    'defect_4': np.random.randint(0, 2, size=num_rows),\n",
    "    'defect_5': np.random.randint(0, 2, size=num_rows),\n",
    "    'defect_1_Type': np.random.choice(['A', 'B', 'C', 'D'], size=num_rows),\n",
    "    'defect_2_Type': np.random.choice(['A', 'B', 'C', 'D'], size=num_rows),\n",
    "    'defect_3_Type': np.random.choice(['A', 'B', 'C', 'D'], size=num_rows),\n",
    "    'defect_4_Type': np.random.choice(['A', 'B', 'C', 'D'], size=num_rows),\n",
    "    'defect_5_Type': np.random.choice(['A', 'B', 'C', 'D'], size=num_rows),\n",
    "    'Reference': np.random.randint(0, 10, size=num_rows),\n",
    "    'Lane': np.random.choice(['V1', 'V2'], size=num_rows),\n",
    "    'TailleZone': np.random.randint(0, 100, size=num_rows),\n",
    "    'Courbure': np.random.uniform(0, 1, size=num_rows),\n",
    "    'CourbureVert': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vitesse': np.random.uniform(0, 100, size=num_rows),\n",
    "    'SensMarche': np.random.choice(['Forward', 'Backward'], size=num_rows),\n",
    "    'Lat_acc_tete_Max': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_tete_Max_Pos': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Lat_acc_tete_Max_Pos_Moy': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Lat_acc_tete_Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_tete_P2Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_milieu_Max': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_milieu_Max_Pos': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Lat_acc_milieu_Max_Pos_Moy': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Lat_acc_milieu_Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_milieu_P2Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_queue_Max': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_queue_Max_Pos': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Lat_acc_queue_Max_Pos_Moy': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Lat_acc_queue_Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Lat_acc_queue_P2Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_tete_Max': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Vert_acc_tete_Max_Pos': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Vert_acc_tete_Max_Pos_Moy': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Vert_acc_tete_Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_tete_P2Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_milieu_Max': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_milieu_Max_Pos': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Vert_acc_milieu_Max_Pos_Moy': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Vert_acc_milieu_Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_milieu_P2Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_queue_Max': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_queue_Max_Pos': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Vert_acc_queue_Max_Pos_Moy': np.random.uniform(0, 100, size=num_rows),\n",
    "    'Vert_acc_queue_Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Vert_acc_queue_P2Avg': np.random.uniform(0, 1, size=num_rows),\n",
    "    'G_Mean': np.random.uniform(0, 1, size=num_rows),\n",
    "    'AUC': np.random.uniform(0, 1, size=num_rows),\n",
    "    'F-Measure': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Specificity': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Precision': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Recall': np.random.uniform(0, 1, size=num_rows),\n",
    "    'TPR': np.random.uniform(0, 1, size=num_rows),\n",
    "    'FPR': np.random.uniform(0, 1, size=num_rows),\n",
    "    'TNR': np.random.uniform(0, 1, size=num_rows),\n",
    "    'FNR': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Youden': np.random.uniform(0, 1, size=num_rows),\n",
    "    'Balanced_Accuracy': np.random.uniform(0, 1, size=num_rows),\n",
    "    'ROC_Curve': np.random.uniform(0, 1, size=num_rows),\n",
    "    'PR_Curve': np.random.uniform(0, 1, size=num_rows),\n",
    "    'AP': np.random.uniform(0, 1, size=num_rows)\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['defect_1', 'defect_2', 'defect_3', 'defect_4', 'defect_5', 'defect_1_Type', 'defect_2_Type', 'defect_3_Type', 'defect_4_Type', 'defect_5_Type', 'Reference', 'Lane', 'TailleZone', 'Courbure', 'CourbureVert', 'Vitesse', 'SensMarche', 'Lat_acc_tete_Max', 'Lat_acc_tete_Max_Pos', 'Lat_acc_tete_Max_Pos_Moy', 'Lat_acc_tete_Avg', 'Lat_acc_tete_P2Avg', 'Lat_acc_milieu_Max', 'Lat_acc_milieu_Max_Pos', 'Lat_acc_milieu_Max_Pos_Moy', 'Lat_acc_milieu_Avg', 'Lat_acc_milieu_P2Avg', 'Lat_acc_queue_Max', 'Lat_acc_queue_Max_Pos', 'Lat_acc_queue_Max_Pos_Moy', 'Lat_acc_queue_Avg', 'Lat_acc_queue_P2Avg', 'Vert_acc_tete_Max', 'Vert_acc_tete_Max_Pos', 'Vert_acc_tete_Max_Pos_Moy', 'Vert_acc_tete_Avg', 'Vert_acc_tete_P2Avg', 'Vert_acc_milieu_Max', 'Vert_acc_milieu_Max_Pos', 'Vert_acc_milieu_Max_Pos_Moy', 'Vert_acc_milieu_Avg', 'Vert_acc_milieu_P2Avg', 'Vert_acc_queue_Max', 'Vert_acc_queue_Max_Pos', 'Vert_acc_queue_Max_Pos_Moy', 'Vert_acc_queue_Avg', 'Vert_acc_queue_P2Avg', 'G_Mean', 'AUC', 'F-Measure', 'Specificity', 'Precision', 'Recall', 'TPR', 'FPR', 'TNR', 'FNR', 'Youden', 'Balanced_Accuracy', 'ROC_Curve', 'PR_Curve', 'AP']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns\n",
    "geo_param_to_remove = ['defect_1', 'defect_2', 'defect_3', 'defect_4', 'defect_5']\n",
    "for col in df.columns.tolist():\n",
    "    if 'PR' in col or 'NR' in col:\n",
    "        geo_param_to_remove.append(col)\n",
    "\n",
    "zone_info_to_remove = ['G_Mean', 'AUC', 'F-Measure', 'Specificity', 'Precision', 'Recall' \n",
    "                       , 'Youden', 'Balanced_Accuracy', 'ROC_Curve', 'PR_Curve', 'AP']\n",
    "\n",
    "remove_list = geo_param_to_remove + zone_info_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['defect_1_Type', 'defect_2_Type', 'defect_3_Type', 'defect_4_Type', 'defect_5_Type', 'Reference', 'Lane', 'TailleZone', 'Courbure', 'CourbureVert', 'Vitesse', 'SensMarche', 'Lat_acc_tete_Max', 'Lat_acc_tete_Max_Pos', 'Lat_acc_tete_Max_Pos_Moy', 'Lat_acc_tete_Avg', 'Lat_acc_tete_P2Avg', 'Lat_acc_milieu_Max', 'Lat_acc_milieu_Max_Pos', 'Lat_acc_milieu_Max_Pos_Moy', 'Lat_acc_milieu_Avg', 'Lat_acc_milieu_P2Avg', 'Lat_acc_queue_Max', 'Lat_acc_queue_Max_Pos', 'Lat_acc_queue_Max_Pos_Moy', 'Lat_acc_queue_Avg', 'Lat_acc_queue_P2Avg', 'Vert_acc_tete_Max', 'Vert_acc_tete_Max_Pos', 'Vert_acc_tete_Max_Pos_Moy', 'Vert_acc_tete_Avg', 'Vert_acc_tete_P2Avg', 'Vert_acc_milieu_Max', 'Vert_acc_milieu_Max_Pos', 'Vert_acc_milieu_Max_Pos_Moy', 'Vert_acc_milieu_Avg', 'Vert_acc_milieu_P2Avg', 'Vert_acc_queue_Max', 'Vert_acc_queue_Max_Pos', 'Vert_acc_queue_Max_Pos_Moy', 'Vert_acc_queue_Avg', 'Vert_acc_queue_P2Avg']\n"
     ]
    }
   ],
   "source": [
    "df.drop(remove_list, axis=1, inplace=True)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More columns and rows filtering can be done here, in the original data there are others\n",
    "df[\"Lane\"] = df.apply(lambda x: 'V1' if 'V1' in x[\"Lane\"] else 'V2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check for null values, in this case there isn't any because it's a dummy dataset\n",
    "print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column that collects every defect types that exist in the zone which will be used for stratification\n",
    "Defect_types = ['defect_1_Type', 'defect_2_Type', 'defect_3_Type', 'defect_4_Type', 'defect_5_Type']\n",
    "df[\"labels\"] = df.apply(lambda x: ','.join(x[x.index.isin(Defect_types)].index\n",
    "                                           [x[x.index.isin(Defect_types)] != 'A' ]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the df into final_test_set and global_train_set using defect combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: labels, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find row with a unique combination of types that only have one sample which will create problem during split\n",
    "df[\"labels\"].value_counts().loc[lambda x: x<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row that have unique combination (we will add them to the test set), before dropping them from the main df\n",
    "unique_combination_ind = df[\"labels\"].value_counts().loc[lambda x: x<2].index\n",
    "unique_combination_df = df[df[\"labels\"].isin(unique_combination_ind)]\n",
    "\n",
    "#print(unique_combination_df)\n",
    "\n",
    "# drop rows with unique_combination\n",
    "#print(\"before drop: \", df.shape)\n",
    "df = df.drop(df[df[\"labels\"].isin(unique_combination_ind)].index).reset_index(drop=True)\n",
    "#print(\"after drop: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "# Defect_cat is 0 for without Niv or Nall, 1 for with Niv, Nall, or Both \n",
    "for train_index, test_index in split.split(df, df[\"labels\"]):\n",
    "    Global_train_set = df.loc[train_index]\n",
    "    Final_test_set_original = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defect_1_Type,defect_2_Type,defect_3_Type,defect_4_Type,defect_5_Type    4734\n",
       "defect_1_Type,defect_2_Type,defect_3_Type,defect_5_Type                  1603\n",
       "defect_1_Type,defect_2_Type,defect_4_Type,defect_5_Type                  1600\n",
       "defect_2_Type,defect_3_Type,defect_4_Type,defect_5_Type                  1583\n",
       "defect_1_Type,defect_3_Type,defect_4_Type,defect_5_Type                  1582\n",
       "defect_1_Type,defect_2_Type,defect_3_Type,defect_4_Type                  1568\n",
       "defect_2_Type,defect_3_Type,defect_4_Type                                 543\n",
       "defect_1_Type,defect_2_Type,defect_3_Type                                 537\n",
       "defect_1_Type,defect_4_Type,defect_5_Type                                 535\n",
       "defect_1_Type,defect_3_Type,defect_5_Type                                 534\n",
       "defect_3_Type,defect_4_Type,defect_5_Type                                 534\n",
       "defect_2_Type,defect_3_Type,defect_5_Type                                 527\n",
       "defect_1_Type,defect_2_Type,defect_4_Type                                 525\n",
       "defect_1_Type,defect_2_Type,defect_5_Type                                 525\n",
       "defect_1_Type,defect_3_Type,defect_4_Type                                 519\n",
       "defect_2_Type,defect_4_Type,defect_5_Type                                 510\n",
       "defect_1_Type,defect_2_Type                                               184\n",
       "defect_1_Type,defect_3_Type                                               178\n",
       "defect_1_Type,defect_5_Type                                               175\n",
       "defect_3_Type,defect_5_Type                                               174\n",
       "defect_2_Type,defect_5_Type                                               173\n",
       "defect_2_Type,defect_4_Type                                               173\n",
       "defect_2_Type,defect_3_Type                                               170\n",
       "defect_1_Type,defect_4_Type                                               169\n",
       "defect_3_Type,defect_4_Type                                               169\n",
       "defect_4_Type,defect_5_Type                                               167\n",
       "defect_1_Type                                                              62\n",
       "defect_5_Type                                                              59\n",
       "defect_3_Type                                                              58\n",
       "defect_2_Type                                                              56\n",
       "defect_4_Type                                                              53\n",
       "                                                                           21\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the unique combination rows to the Final_test_set\n",
    "Final_test_set_original = pd.concat([Final_test_set_original, unique_combination_df], ignore_index=True)\n",
    "\n",
    "Final_test_set_original[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the labels colmun from test and train sets\n",
    "Global_train_set = Global_train_set.drop(\"labels\", axis=1)\n",
    "Final_test_set_original = Final_test_set_original.drop(\"labels\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defect_1_Type</th>\n",
       "      <th>defect_2_Type</th>\n",
       "      <th>defect_3_Type</th>\n",
       "      <th>defect_4_Type</th>\n",
       "      <th>defect_5_Type</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Lane</th>\n",
       "      <th>TailleZone</th>\n",
       "      <th>Courbure</th>\n",
       "      <th>CourbureVert</th>\n",
       "      <th>...</th>\n",
       "      <th>Vert_acc_milieu_Max</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_milieu_Avg</th>\n",
       "      <th>Vert_acc_milieu_P2Avg</th>\n",
       "      <th>Vert_acc_queue_Max</th>\n",
       "      <th>Vert_acc_queue_Max_Pos</th>\n",
       "      <th>Vert_acc_queue_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_queue_Avg</th>\n",
       "      <th>Vert_acc_queue_P2Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41865</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>V1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.208951</td>\n",
       "      <td>0.606896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905396</td>\n",
       "      <td>37.544277</td>\n",
       "      <td>49.289932</td>\n",
       "      <td>0.754303</td>\n",
       "      <td>0.301337</td>\n",
       "      <td>0.890809</td>\n",
       "      <td>86.361178</td>\n",
       "      <td>91.888751</td>\n",
       "      <td>0.677081</td>\n",
       "      <td>0.686660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71755</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>V1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.567851</td>\n",
       "      <td>0.798085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406362</td>\n",
       "      <td>22.134893</td>\n",
       "      <td>97.297302</td>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.757654</td>\n",
       "      <td>0.822322</td>\n",
       "      <td>11.185659</td>\n",
       "      <td>72.559423</td>\n",
       "      <td>0.581428</td>\n",
       "      <td>0.835744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27506</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>V1</td>\n",
       "      <td>92</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.687940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190775</td>\n",
       "      <td>27.378394</td>\n",
       "      <td>71.036832</td>\n",
       "      <td>0.602301</td>\n",
       "      <td>0.364936</td>\n",
       "      <td>0.715889</td>\n",
       "      <td>29.833565</td>\n",
       "      <td>17.281313</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>0.636451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81915</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>V1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218358</td>\n",
       "      <td>0.608949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715811</td>\n",
       "      <td>95.706315</td>\n",
       "      <td>7.458945</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.876993</td>\n",
       "      <td>0.994526</td>\n",
       "      <td>50.824356</td>\n",
       "      <td>81.578388</td>\n",
       "      <td>0.712349</td>\n",
       "      <td>0.053036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50373</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>V2</td>\n",
       "      <td>71</td>\n",
       "      <td>0.062902</td>\n",
       "      <td>0.882730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412475</td>\n",
       "      <td>68.919184</td>\n",
       "      <td>64.241055</td>\n",
       "      <td>0.619083</td>\n",
       "      <td>0.221865</td>\n",
       "      <td>0.379381</td>\n",
       "      <td>87.778234</td>\n",
       "      <td>7.489518</td>\n",
       "      <td>0.545681</td>\n",
       "      <td>0.427628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      defect_1_Type defect_2_Type defect_3_Type defect_4_Type defect_5_Type  \\\n",
       "41865             A             C             A             C             A   \n",
       "71755             C             C             C             A             B   \n",
       "27506             A             C             D             D             D   \n",
       "81915             A             B             A             C             C   \n",
       "50373             C             C             B             B             C   \n",
       "\n",
       "       Reference Lane  TailleZone  Courbure  CourbureVert  ...  \\\n",
       "41865          0   V1          72  0.208951      0.606896  ...   \n",
       "71755          2   V1          55  0.567851      0.798085  ...   \n",
       "27506          4   V1          92  0.071343      0.687940  ...   \n",
       "81915          0   V1           5  0.218358      0.608949  ...   \n",
       "50373          2   V2          71  0.062902      0.882730  ...   \n",
       "\n",
       "       Vert_acc_milieu_Max Vert_acc_milieu_Max_Pos  \\\n",
       "41865             0.905396               37.544277   \n",
       "71755             0.406362               22.134893   \n",
       "27506             0.190775               27.378394   \n",
       "81915             0.715811               95.706315   \n",
       "50373             0.412475               68.919184   \n",
       "\n",
       "       Vert_acc_milieu_Max_Pos_Moy  Vert_acc_milieu_Avg  \\\n",
       "41865                    49.289932             0.754303   \n",
       "71755                    97.297302             0.057798   \n",
       "27506                    71.036832             0.602301   \n",
       "81915                     7.458945             0.695200   \n",
       "50373                    64.241055             0.619083   \n",
       "\n",
       "       Vert_acc_milieu_P2Avg  Vert_acc_queue_Max  Vert_acc_queue_Max_Pos  \\\n",
       "41865               0.301337            0.890809               86.361178   \n",
       "71755               0.757654            0.822322               11.185659   \n",
       "27506               0.364936            0.715889               29.833565   \n",
       "81915               0.876993            0.994526               50.824356   \n",
       "50373               0.221865            0.379381               87.778234   \n",
       "\n",
       "       Vert_acc_queue_Max_Pos_Moy  Vert_acc_queue_Avg  Vert_acc_queue_P2Avg  \n",
       "41865                   91.888751            0.677081              0.686660  \n",
       "71755                   72.559423            0.581428              0.835744  \n",
       "27506                   17.281313            0.017870              0.636451  \n",
       "81915                   81.578388            0.712349              0.053036  \n",
       "50373                    7.489518            0.545681              0.427628  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End final test set split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 2-A training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Global_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'long_defect_cat' column where 0 for defect_4 and defect_5 are 'A', 1 for defect_4, defect_5, or Both being others\n",
    "df[\"long_defect_cat\"] = df.apply(lambda x: 0 if x['defect_4_Type'] == 'A' or x['defect_5_Type'] == 'A' else 1, axis=1)\n",
    "#df[['Niv_Type','Nall_Type',\"long_defect_cat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reference', 'Lane', 'TailleZone', 'Courbure', 'CourbureVert', 'Vitesse', 'SensMarche', 'Lat_acc_tete_Max', 'Lat_acc_tete_Max_Pos', 'Lat_acc_tete_Max_Pos_Moy', 'Lat_acc_tete_Avg', 'Lat_acc_tete_P2Avg', 'Lat_acc_milieu_Max', 'Lat_acc_milieu_Max_Pos', 'Lat_acc_milieu_Max_Pos_Moy', 'Lat_acc_milieu_Avg', 'Lat_acc_milieu_P2Avg', 'Lat_acc_queue_Max', 'Lat_acc_queue_Max_Pos', 'Lat_acc_queue_Max_Pos_Moy', 'Lat_acc_queue_Avg', 'Lat_acc_queue_P2Avg', 'Vert_acc_tete_Max', 'Vert_acc_tete_Max_Pos', 'Vert_acc_tete_Max_Pos_Moy', 'Vert_acc_tete_Avg', 'Vert_acc_tete_P2Avg', 'Vert_acc_milieu_Max', 'Vert_acc_milieu_Max_Pos', 'Vert_acc_milieu_Max_Pos_Moy', 'Vert_acc_milieu_Avg', 'Vert_acc_milieu_P2Avg', 'Vert_acc_queue_Max', 'Vert_acc_queue_Max_Pos', 'Vert_acc_queue_Max_Pos_Moy', 'Vert_acc_queue_Avg', 'Vert_acc_queue_P2Avg', 'long_defect_cat']\n"
     ]
    }
   ],
   "source": [
    "# Drop all '_type' columns and AB_tete and AC_tete\n",
    "df.drop(['defect_1_Type', 'defect_2_Type', 'defect_3_Type', 'defect_4_Type', 'defect_5_Type']\n",
    "        , axis=1, inplace=True)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lane</th>\n",
       "      <th>SensMarche</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41865</th>\n",
       "      <td>V1</td>\n",
       "      <td>Forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71755</th>\n",
       "      <td>V1</td>\n",
       "      <td>Backward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27506</th>\n",
       "      <td>V1</td>\n",
       "      <td>Forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81915</th>\n",
       "      <td>V1</td>\n",
       "      <td>Backward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50373</th>\n",
       "      <td>V2</td>\n",
       "      <td>Forward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lane SensMarche\n",
       "41865   V1    Forward\n",
       "71755   V1   Backward\n",
       "27506   V1    Forward\n",
       "81915   V1   Backward\n",
       "50373   V2    Forward"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find if there is any column that is not numeric \n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reference    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add categorical columns that are number manually can convert them to categorical type\n",
    "other_cat_col = ['Reference']\n",
    "df[other_cat_col] = df[other_cat_col].astype(\"category\")\n",
    "df[other_cat_col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_encoded = ordinal_encoder.fit_transform(df_cat)\n",
    "#print(df_cat_encoded)\n",
    "\n",
    "df[df_cat.columns.tolist()] = df_cat_encoded\n",
    "df[df_cat.columns.tolist()] = df[df_cat.columns.tolist()].astype(\"category\")\n",
    "#df[df_cat.columns.tolist()].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Visualisation on train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a step to see the influences of each feature (or representative of a feature) on labels. The insight acquired in this step can be used for feature selection. However, we are uisng randomly generated dataset and won't be seeing anything so we skip this part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Oversampling the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    74933\n",
       "0     5067\n",
       "Name: long_defect_cat, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df[\"long_defect_cat\"]\n",
    "X_train = df.drop(\"long_defect_cat\", axis=1)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.936662\n",
       "0    0.063338\n",
       "Name: long_defect_cat, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check the ratio of the labels\n",
    "df[\"long_defect_cat\"].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want more class 0 so use oversampling to make it 50:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling Counter({1: 74933, 0: 5067})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print('Before oversampling', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Counter({0: 76110, 1: 74933})\n"
     ]
    }
   ],
   "source": [
    "if oversampling:\n",
    "    from imblearn.over_sampling import ADASYN\n",
    "    ada = ADASYN(sampling_strategy=1, random_state = 42) # sampling_strategy = float only works for Binary \n",
    "    \n",
    "    X_train_pre_transf, y_train_pre_transf = ada.fit_resample(X_train, y_train)\n",
    "    counter = Counter(y_train_pre_transf)\n",
    "    print('After', counter)\n",
    "else:\n",
    "    X_train_pre_transf = X_train\n",
    "    y_train_pre_transf = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Lane</th>\n",
       "      <th>TailleZone</th>\n",
       "      <th>Courbure</th>\n",
       "      <th>CourbureVert</th>\n",
       "      <th>Vitesse</th>\n",
       "      <th>SensMarche</th>\n",
       "      <th>Lat_acc_tete_Max</th>\n",
       "      <th>Lat_acc_tete_Max_Pos</th>\n",
       "      <th>Lat_acc_tete_Max_Pos_Moy</th>\n",
       "      <th>...</th>\n",
       "      <th>Vert_acc_milieu_Max</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_milieu_Avg</th>\n",
       "      <th>Vert_acc_milieu_P2Avg</th>\n",
       "      <th>Vert_acc_queue_Max</th>\n",
       "      <th>Vert_acc_queue_Max_Pos</th>\n",
       "      <th>Vert_acc_queue_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_queue_Avg</th>\n",
       "      <th>Vert_acc_queue_P2Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.208951</td>\n",
       "      <td>0.606896</td>\n",
       "      <td>37.029094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724853</td>\n",
       "      <td>40.485842</td>\n",
       "      <td>22.184719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905396</td>\n",
       "      <td>37.544277</td>\n",
       "      <td>49.289932</td>\n",
       "      <td>0.754303</td>\n",
       "      <td>0.301337</td>\n",
       "      <td>0.890809</td>\n",
       "      <td>86.361178</td>\n",
       "      <td>91.888751</td>\n",
       "      <td>0.677081</td>\n",
       "      <td>0.686660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.567851</td>\n",
       "      <td>0.798085</td>\n",
       "      <td>57.191099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>64.006048</td>\n",
       "      <td>27.548878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406362</td>\n",
       "      <td>22.134893</td>\n",
       "      <td>97.297302</td>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.757654</td>\n",
       "      <td>0.822322</td>\n",
       "      <td>11.185659</td>\n",
       "      <td>72.559423</td>\n",
       "      <td>0.581428</td>\n",
       "      <td>0.835744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.687940</td>\n",
       "      <td>74.292031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.561670</td>\n",
       "      <td>64.371349</td>\n",
       "      <td>80.608878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190775</td>\n",
       "      <td>27.378394</td>\n",
       "      <td>71.036832</td>\n",
       "      <td>0.602301</td>\n",
       "      <td>0.364936</td>\n",
       "      <td>0.715889</td>\n",
       "      <td>29.833565</td>\n",
       "      <td>17.281313</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>0.636451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218358</td>\n",
       "      <td>0.608949</td>\n",
       "      <td>59.237997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728388</td>\n",
       "      <td>14.884909</td>\n",
       "      <td>80.736501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715811</td>\n",
       "      <td>95.706315</td>\n",
       "      <td>7.458945</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.876993</td>\n",
       "      <td>0.994526</td>\n",
       "      <td>50.824356</td>\n",
       "      <td>81.578388</td>\n",
       "      <td>0.712349</td>\n",
       "      <td>0.053036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.062902</td>\n",
       "      <td>0.882730</td>\n",
       "      <td>54.048309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193552</td>\n",
       "      <td>24.668405</td>\n",
       "      <td>49.470311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412475</td>\n",
       "      <td>68.919184</td>\n",
       "      <td>64.241055</td>\n",
       "      <td>0.619083</td>\n",
       "      <td>0.221865</td>\n",
       "      <td>0.379381</td>\n",
       "      <td>87.778234</td>\n",
       "      <td>7.489518</td>\n",
       "      <td>0.545681</td>\n",
       "      <td>0.427628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reference Lane  TailleZone  Courbure  CourbureVert    Vitesse SensMarche  \\\n",
       "0         0  0.0          72  0.208951      0.606896  37.029094        1.0   \n",
       "1         2  0.0          55  0.567851      0.798085  57.191099        0.0   \n",
       "2         4  0.0          92  0.071343      0.687940  74.292031        1.0   \n",
       "3         0  0.0           5  0.218358      0.608949  59.237997        0.0   \n",
       "4         2  1.0          71  0.062902      0.882730  54.048309        1.0   \n",
       "\n",
       "   Lat_acc_tete_Max  Lat_acc_tete_Max_Pos  Lat_acc_tete_Max_Pos_Moy  ...  \\\n",
       "0          0.724853             40.485842                 22.184719  ...   \n",
       "1          0.115556             64.006048                 27.548878  ...   \n",
       "2          0.561670             64.371349                 80.608878  ...   \n",
       "3          0.728388             14.884909                 80.736501  ...   \n",
       "4          0.193552             24.668405                 49.470311  ...   \n",
       "\n",
       "   Vert_acc_milieu_Max  Vert_acc_milieu_Max_Pos  Vert_acc_milieu_Max_Pos_Moy  \\\n",
       "0             0.905396                37.544277                    49.289932   \n",
       "1             0.406362                22.134893                    97.297302   \n",
       "2             0.190775                27.378394                    71.036832   \n",
       "3             0.715811                95.706315                     7.458945   \n",
       "4             0.412475                68.919184                    64.241055   \n",
       "\n",
       "   Vert_acc_milieu_Avg  Vert_acc_milieu_P2Avg  Vert_acc_queue_Max  \\\n",
       "0             0.754303               0.301337            0.890809   \n",
       "1             0.057798               0.757654            0.822322   \n",
       "2             0.602301               0.364936            0.715889   \n",
       "3             0.695200               0.876993            0.994526   \n",
       "4             0.619083               0.221865            0.379381   \n",
       "\n",
       "   Vert_acc_queue_Max_Pos  Vert_acc_queue_Max_Pos_Moy  Vert_acc_queue_Avg  \\\n",
       "0               86.361178                   91.888751            0.677081   \n",
       "1               11.185659                   72.559423            0.581428   \n",
       "2               29.833565                   17.281313            0.017870   \n",
       "3               50.824356                   81.578388            0.712349   \n",
       "4               87.778234                    7.489518            0.545681   \n",
       "\n",
       "   Vert_acc_queue_P2Avg  \n",
       "0              0.686660  \n",
       "1              0.835744  \n",
       "2              0.636451  \n",
       "3              0.053036  \n",
       "4              0.427628  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(X_train_pre_transf[df_cat.columns.tolist()].value_counts())\n",
    "X_train_pre_transf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set = X_train_pre_transf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TailleZone', 'Courbure', 'CourbureVert', 'Vitesse', 'Lat_acc_tete_Max', 'Lat_acc_tete_Max_Pos', 'Lat_acc_tete_Max_Pos_Moy', 'Lat_acc_tete_Avg', 'Lat_acc_tete_P2Avg', 'Lat_acc_milieu_Max', 'Lat_acc_milieu_Max_Pos', 'Lat_acc_milieu_Max_Pos_Moy', 'Lat_acc_milieu_Avg', 'Lat_acc_milieu_P2Avg', 'Lat_acc_queue_Max', 'Lat_acc_queue_Max_Pos', 'Lat_acc_queue_Max_Pos_Moy', 'Lat_acc_queue_Avg', 'Lat_acc_queue_P2Avg', 'Vert_acc_tete_Max', 'Vert_acc_tete_Max_Pos', 'Vert_acc_tete_Max_Pos_Moy', 'Vert_acc_tete_Avg', 'Vert_acc_tete_P2Avg', 'Vert_acc_milieu_Max', 'Vert_acc_milieu_Max_Pos', 'Vert_acc_milieu_Max_Pos_Moy', 'Vert_acc_milieu_Avg', 'Vert_acc_milieu_P2Avg', 'Vert_acc_queue_Max', 'Vert_acc_queue_Max_Pos', 'Vert_acc_queue_Max_Pos_Moy', 'Vert_acc_queue_Avg', 'Vert_acc_queue_P2Avg']\n",
      "['Reference', 'Lane', 'SensMarche']\n"
     ]
    }
   ],
   "source": [
    "cat_attribs = X_train_set.select_dtypes(include='category').columns.tolist()\n",
    "#print(cat_attribs)\n",
    "\n",
    "X_train_num_lst = X_train_set.drop(cat_attribs, axis=1).columns.tolist()\n",
    "X_train_cat_lst = X_train_set[cat_attribs].columns.tolist()\n",
    "\n",
    "print(X_train_num_lst)\n",
    "print(X_train_cat_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforamtion class to add, combine, fuse, extract features for the numeric PL\n",
    "# stat_feature_head_to_tail is to use only the absolute 'ab_maximum' or 'average' value of each statistical feature from head, middle, or tail measurement (and None means to keep all of them)  \n",
    "class Attrib_transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stat_feature_head_to_tail = 'ab_maximum'):\n",
    "        self.stat_feature_head_to_tail = stat_feature_head_to_tail\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.stat_feature_head_to_tail is not None:\n",
    "            stat_feature = ['Max', 'Max_Pos', 'Max_Pos_Moy', 'Avg', 'P2Avg']\n",
    "            acc_measurement = ['Lat_acc', 'Vert_acc']\n",
    "            \n",
    "            new_X = X.copy() # so the original df is not changed\n",
    "            # See the commnad line argument and match it to pre-defined case \n",
    "            match self.stat_feature_head_to_tail:\n",
    "                case 'ab_maximum':\n",
    "                    for stat in stat_feature:\n",
    "                        for acc in acc_measurement:\n",
    "                            # get a new column name\n",
    "                            col_name = acc + '_' + stat\n",
    "                            \n",
    "                            # create a list of all measurement location of the acceleration stat of interest\n",
    "                            acc_tete = acc + '_tete_' + stat\n",
    "                            acc_milieu = acc + '_milieu_' + stat\n",
    "                            acc_queue = acc + '_queue_' + stat\n",
    "                            all_location_list = [acc_tete, acc_milieu, acc_queue]\n",
    "                            \n",
    "                            # Get the absolute maximum value of each row, keep the sign, and put them in a new colmun \n",
    "                            row_max = X[all_location_list].abs().max(axis=1)\n",
    "                            new_X[col_name] = X[all_location_list].max(axis=1).mask(lambda x: x < row_max, -row_max)\n",
    "                            new_X = new_X.drop(all_location_list, axis=1)\n",
    "                \n",
    "                case 'average':\n",
    "                    for stat in stat_feature:\n",
    "                        for acc in acc_measurement:\n",
    "                            # get a new column name\n",
    "                            col_name = acc + '_' + stat\n",
    "                            \n",
    "                            # create a list of all measurement location of the acceleration stat of interest\n",
    "                            acc_tete = acc + '_tete_' + stat\n",
    "                            acc_milieu = acc + '_milieu_' + stat\n",
    "                            acc_queue = acc + '_queue_' + stat\n",
    "                            all_location_list = [acc_tete, acc_milieu, acc_queue]\n",
    "                            \n",
    "                            # Get the mean value of each row and put them in a new colmun \n",
    "                            new_X[col_name] = X[all_location_list].mean(axis=1)\n",
    "                            new_X = new_X.drop(all_location_list, axis=1)\n",
    "                    \n",
    "                case _:   # 'case _' is for any other input that does not match None or the above\n",
    "                    sys.exit(\"please choose from 'ab_maximum', 'average', or \\\n",
    "                    'None' for stat_feature_head_to_tail in Attrib_transformer\")\n",
    "                \n",
    "            #print(list(new_X.columns))\n",
    "            return new_X\n",
    "            \n",
    "        else:\n",
    "            return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforamtion class to drop unwanted features\n",
    "class Attrib_drop(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d_list=[], keep_only_Vert_acc=False):\n",
    "        self.d_list = d_list\n",
    "        self.keep_only_Vert_acc = keep_only_Vert_acc\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.keep_only_Vert_acc:\n",
    "            Vert_acc_indices = []\n",
    "            for i, col in enumerate(X.columns):\n",
    "                if 'Vert_acc' in col:\n",
    "                    Vert_acc_indices.append(i)\n",
    "            return X.iloc[:,Vert_acc_indices]\n",
    "        elif self.d_list:\n",
    "            keep_indices = []\n",
    "            for i, col in enumerate(X.columns):\n",
    "                if col not in self.d_list:\n",
    "                    keep_indices.append(i)\n",
    "            return X.iloc[:,keep_indices]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the numerical features to be dropped to manually drop columns from the df\n",
    "drop_list_num = [] # Here we can add columns that should be dropped from the df\n",
    "\n",
    "num_pl = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attrib_transform', Attrib_transformer(stat_feature_head_to_tail='average')),\n",
    "    ('attrib_drop', Attrib_drop(keep_only_Vert_acc=False, d_list=drop_list_num)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "#For testing num_pl\n",
    "#num_prep = num_pl.fit_transform(X_train_set[X_train_num_lst])\n",
    "#print('shape after transformation: ', num_prep.shape)\n",
    "#num_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the categorical features to be dropped to manually drop columns from the df\n",
    "drop_list_cat = []\n",
    "\n",
    "cat_pl = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('attrib_drop', Attrib_drop()),\n",
    "    ('One_Hot', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "# For testing cat_pl\n",
    "#cat_prep = cat_pl.fit_transform(X_train_set[X_train_cat_lst])\n",
    "#cat_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_pl = ColumnTransformer([\n",
    "    (\"num\", num_pl, X_train_num_lst),\n",
    "    #(\"cat\", cat_pl, X_train_cat_lst),\n",
    "])\n",
    "\n",
    "X_train_prep = full_pl.fit_transform(X_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after transformation:  (151043, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.80488482, -1.09990012,  0.40208365, ...,  0.94477262,\n",
       "        -0.69997285,  0.41282526],\n",
       "       [ 0.19421266,  0.25230262,  1.12420772, ..., -0.67243601,\n",
       "        -0.3018721 ,  0.34719126],\n",
       "       [ 1.52332264, -1.61835805,  0.70818961, ..., -1.08141544,\n",
       "        -1.18449052,  0.68211035],\n",
       "       ...,\n",
       "       [-0.02131869,  0.43091085,  0.52740305, ..., -0.46254154,\n",
       "        -0.51842364, -0.42214444],\n",
       "       [-0.73975651, -1.26127068,  0.78844375, ...,  0.43855588,\n",
       "         1.93918401, -0.92161758],\n",
       "       [ 0.26605644,  1.72387195,  0.04632851, ...,  1.59572576,\n",
       "        -0.75735296, -1.85486868]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape after transformation: ', X_train_prep.shape)\n",
    "X_train_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 OPTIONAL: PCA for unsupervised feature selectiion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components:  13\n"
     ]
    }
   ],
   "source": [
    "use_PCA = True\n",
    "\n",
    "if use_PCA:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
    "              svd_solver='auto', tol=0.0, whiten=False)\n",
    "    \n",
    "    X_train_prep = pca.fit_transform(X_train_prep)\n",
    "    print('number of components: ', pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after transformation:  (151043, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.60057635e+00,  2.37404319e-01,  1.89919683e-01, ...,\n",
       "         4.57500090e-01,  1.88537573e+00,  1.37207737e+00],\n",
       "       [-1.23672846e+00,  6.51396434e-01,  1.07452821e+00, ...,\n",
       "        -1.40521318e+00,  4.44789894e-01, -8.98634139e-01],\n",
       "       [ 6.46629644e-01, -7.07380012e-01,  9.43012286e-01, ...,\n",
       "         5.95578858e-01,  7.45073369e-01,  5.33574824e-01],\n",
       "       ...,\n",
       "       [-2.12943840e+00, -3.52897642e-01, -3.59909781e-01, ...,\n",
       "         4.97386736e-01, -6.47698561e-02,  8.50319644e-02],\n",
       "       [-6.03319904e-01, -7.25611382e-01,  3.35437469e-04, ...,\n",
       "        -8.77263003e-01, -1.17854445e+00,  3.00555275e-02],\n",
       "       [-1.49030151e+00, -1.19179935e+00, -1.13129471e+00, ...,\n",
       "        -4.95647206e-01,  1.22229294e+00,  2.55936966e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape after transformation: ', X_train_prep.shape)\n",
    "X_train_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tuning Base Classifier's hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hyperopt for hyperparameter tuning\n",
    "from hyperopt import fmin, tpe, hp, Trials, space_eval, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# set number of randomised trial to carry out\n",
    "n_iteration = 7\n",
    "\n",
    "#This command can be used to randomly sample parameter set from a space\n",
    "#from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "#ho_sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [5:36:48<00:00, 2886.90s/trial, best loss: -0.55874156096377]\n",
      "Best parameters: {'C': [9.704052240884993], 'gamma_poly': [0.011785053924241283], 'gamma_rbf': [], 'gamma_sigmoid': [], 'kernel': [1]}\n",
      "Best score: 0.55874156096377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def tune_svm(params):\n",
    "    svm_clf = SVC(**params['kernel'], C=params['C'])\n",
    "    acc = cross_val_score(svm_clf, X_train_prep, y_train_pre_transf, scoring=\"accuracy\", cv=2, n_jobs=-1).mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"kernel\": hp.choice(\"kernel\",[\n",
    "    {\"kernel\": 'linear', \"gamma\": 'scale'}, \n",
    "    {\"kernel\": 'poly', \"gamma\": hp.loguniform(\"gamma_poly\", np.log(0.01), np.log(0.1))},\n",
    "    {\"kernel\": 'rbf', \"gamma\": hp.loguniform(\"gamma_rbf\", np.log(0.01), np.log(0.1))},\n",
    "    {\"kernel\": 'sigmoid', \"gamma\": hp.loguniform(\"gamma_sigmoid\", np.log(0.01), np.log(0.1))},\n",
    "    ]),\n",
    "    \"C\": hp.uniform(\"C\", 1, 10),\n",
    "}\n",
    "\n",
    "trials=Trials() # Trails() must be reassign each time to reset its value\n",
    "best_search_svm = fmin(fn=tune_svm, space=space, algo=tpe.suggest, max_evals=n_iteration, trials=trials)\n",
    "\n",
    "best_trial_svm = trials.best_trial\n",
    "best_params_svm = best_trial_svm[\"misc\"][\"vals\"]\n",
    "best_score_svm = -best_trial_svm[\"result\"][\"loss\"]\n",
    "\n",
    "print(\"Best parameters:\", best_params_svm)\n",
    "print(\"Best score:\", best_score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=9.704052240884993, gamma=0.011785053924241283, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=9.704052240884993, gamma=0.011785053924241283, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=9.704052240884993, gamma=0.011785053924241283, kernel='poly')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit the classifier with the best hyperparameter set\n",
    "temp_params_dict = space_eval(space, best_search_svm)\n",
    "final_params_svm = {\n",
    "    'C': temp_params_dict['C'],\n",
    "    'kernel': temp_params_dict['kernel']['kernel'],\n",
    "    'gamma': temp_params_dict['kernel']['gamma'],\n",
    "}\n",
    "\n",
    "svm_clf = SVC(**final_params_svm)\n",
    "svm_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:11<00:00,  1.65s/trial, best loss: -0.5118873199988916]\n",
      "Best parameters: {'C': [1.9731587368372532], 'l1_ratio': [0.45130243014950067], 'penalty_lbfgs': [], 'penalty_ncg': [], 'penalty_saga': [2], 'solver': [2]}\n",
      "Best score: 0.5118873199988916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def tune_LR(params):\n",
    "    LR_clf = LogisticRegression(**params['solver'], C=params['C'], l1_ratio=params['l1_ratio'])\n",
    "    acc = cross_val_score(LR_clf, X_train_prep, y_train_pre_transf, scoring=\"accuracy\", cv=2, n_jobs=-1).mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"solver\": hp.choice(\"solver\",[\n",
    "    {\"solver\": 'newton-cg', \"penalty\": hp.choice(\"penalty_ncg\", ['l2', None])}, \n",
    "    {\"solver\": 'lbfgs', \"penalty\": hp.choice(\"penalty_lbfgs\", ['l2', None])},\n",
    "    {\"solver\": 'saga', \"penalty\": hp.choice(\"penalty_saga\", ['elasticnet', 'l1', 'l2', None])},\n",
    "    ]),\n",
    "    \"C\": hp.uniform(\"C\", 1.0, 10.0),\n",
    "    \"l1_ratio\": hp.uniform(\"l1_ratio\", 0, 1),\n",
    "}\n",
    "\n",
    "trials=Trials() # Trails() must be reassign each time to reset its value\n",
    "best_search_LR = fmin(fn=tune_LR, space = space, algo=tpe.suggest, max_evals=n_iteration, trials=trials)\n",
    "\n",
    "best_trial_LR = trials.best_trial\n",
    "best_params_LR = best_trial_LR[\"misc\"][\"vals\"]\n",
    "best_score_LR = -best_trial_LR[\"result\"][\"loss\"]\n",
    "\n",
    "print(\"Best parameters:\", best_params_LR)\n",
    "print(\"Best score:\", best_score_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.9731587368372532, n_jobs=-1, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.9731587368372532, n_jobs=-1, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.9731587368372532, n_jobs=-1, solver='saga')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit the classifier with the best hyperparameter set\n",
    "temp_params_dict = space_eval(space, best_search_LR)\n",
    "final_params_LR = {\n",
    "    'C': temp_params_dict['C'],\n",
    "    'solver': temp_params_dict['solver']['solver'],\n",
    "    'penalty': temp_params_dict['solver']['penalty'],\n",
    "    'l1_ratio': temp_params_dict['l1_ratio'] if temp_params_dict['solver']['penalty'] == 'elasticnet' else None,\n",
    "}\n",
    "\n",
    "LR_clf = LogisticRegression(**final_params_LR, n_jobs=-1)\n",
    "LR_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:15<00:00,  2.26s/trial, best loss: -0.6703522152239905]\n",
      "Best parameters: {'criterion': [2], 'max_depth': [3], 'max_features': [1], 'min_samples_leaf': [0]}\n",
      "Best score: 0.6703522152239905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def tune_Tree(params):\n",
    "    Tree_clf = DecisionTreeClassifier(**params)\n",
    "    acc = cross_val_score(Tree_clf, X_train_prep, y_train_pre_transf, scoring=\"accuracy\", cv=2, n_jobs=-1).mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"max_features\": hp.choice(\"max_features\",['sqrt', 'log2', None]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\",[5, 10, 15, None]),\n",
    "    \"criterion\": hp.choice(\"criterion\",['gini', 'entropy', 'log_loss']),\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", [1, 2, 3, 4, 5]),\n",
    "}\n",
    "\n",
    "trials=Trials() # Trails() must be reassign each time to reset its value\n",
    "best_search_Tree = fmin(fn=tune_Tree, space = space, algo=tpe.suggest, max_evals=n_iteration, trials=trials)\n",
    "\n",
    "best_trial_Tree = trials.best_trial\n",
    "best_params_Tree = best_trial_Tree[\"misc\"][\"vals\"]\n",
    "best_score_Tree = -best_trial_Tree[\"result\"][\"loss\"]\n",
    "\n",
    "print(\"Best parameters:\", best_params_Tree)\n",
    "print(\"Best score:\", best_score_Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, max_features=&#x27;log2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, max_features=&#x27;log2&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='log_loss', max_features='log2')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit the classifier with the best hyperparameter set\n",
    "temp_params_dict = space_eval(space, best_search_Tree)\n",
    "final_params_Tree = {\n",
    "    'max_features': temp_params_dict['max_features'],\n",
    "    'max_depth': temp_params_dict['max_depth'],\n",
    "    'criterion': temp_params_dict['criterion'],\n",
    "    'min_samples_leaf': temp_params_dict['min_samples_leaf'],\n",
    "}\n",
    "\n",
    "Tree_clf = DecisionTreeClassifier(**final_params_Tree)\n",
    "Tree_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [17:54<00:00, 153.54s/trial, best loss: -0.7596976350418893]\n",
      "Best parameters: {'metric': [1], 'n_neighbors': [3.251236914700896], 'weights': [1]}\n",
      "Best score: 0.7596976350418893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def tune_KNN(params):\n",
    "    KNN_clf = KNeighborsClassifier(**params, n_jobs=-1)\n",
    "    acc = cross_val_score(KNN_clf, X_train_prep, y_train_pre_transf, scoring=\"accuracy\", cv=2, n_jobs=-1).mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"weights\": hp.choice(\"weights\",['uniform','distance']),\n",
    "    \"metric\": hp.choice(\"metric\",['minkowski','euclidean','manhattan']),\n",
    "    \"n_neighbors\": scope.int(hp.uniform(\"n_neighbors\", 3, 9)),\n",
    "}\n",
    "\n",
    "trials=Trials() # Trails() must be reassign each time to reset its value\n",
    "best_search_KNN = fmin(fn=tune_KNN, space = space, algo=tpe.suggest, max_evals=n_iteration, trials=trials)\n",
    "\n",
    "best_trial_KNN = trials.best_trial\n",
    "best_params_KNN = best_trial_KNN[\"misc\"][\"vals\"]\n",
    "best_score_KNN = -best_trial_KNN[\"result\"][\"loss\"]\n",
    "\n",
    "print(\"Best parameters:\", best_params_KNN)\n",
    "print(\"Best score:\", best_score_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1, n_neighbors=3,\n",
       "                     weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1, n_neighbors=3,\n",
       "                     weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_jobs=-1, n_neighbors=3,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit the classifier with the best hyperparameter set\n",
    "temp_params_dict = space_eval(space, best_search_KNN)\n",
    "final_params_KNN = {\n",
    "    'weights': temp_params_dict['weights'],\n",
    "    'metric': temp_params_dict['metric'],\n",
    "    'n_neighbors': temp_params_dict['n_neighbors'],\n",
    "}\n",
    "\n",
    "KNN_clf = KNeighborsClassifier(**final_params_KNN, n_jobs=-1)\n",
    "KNN_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [12:32<00:00, 107.47s/trial, best loss: -0.6672007924004572]\n",
      "Best parameters: {'activation': [0], 'alpha': [0.0007780975361284449], 'hidden_layer_sizes': [1], 'learning_rate_sgd': [], 'solver': [1]}\n",
      "Best score: 0.6672007924004572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def tune_mlp(params):\n",
    "    mlp_clf = MLPClassifier(**params['solver'], activation=params['activation'], \n",
    "                            hidden_layer_sizes=params['hidden_layer_sizes'], \n",
    "                            alpha=params['alpha'], max_iter=1500)\n",
    "    acc = cross_val_score(mlp_clf, X_train_prep, y_train_pre_transf, scoring=\"accuracy\", cv=2, n_jobs=-1).mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"solver\": hp.choice(\"solver\",[\n",
    "    {\"solver\": 'sgd', \"learning_rate\": hp.choice(\"learning_rate_sgd\", ['constant','adaptive'])}, \n",
    "    {\"solver\": 'lbfgs', \"learning_rate\": 'constant'},\n",
    "    {\"solver\": 'adam', \"learning_rate\": 'constant'},\n",
    "    ]),\n",
    "    \"activation\": hp.choice(\"activation\",['tanh', 'relu']),\n",
    "    \"hidden_layer_sizes\": hp.choice(\"hidden_layer_sizes\",[(10,30,10),(20,)]),\n",
    "    \"alpha\": hp.loguniform(\"alpha\", np.log(0.0001), np.log(0.01)),\n",
    "}\n",
    "\n",
    "trials=Trials() # Trails() must be reassign each time to reset its value\n",
    "best_search_mlp = fmin(fn=tune_mlp, space = space, algo=tpe.suggest, max_evals=n_iteration, trials=trials)\n",
    "\n",
    "best_trial_mlp = trials.best_trial\n",
    "best_params_mlp = best_trial_mlp[\"misc\"][\"vals\"]\n",
    "best_score_mlp = -best_trial_mlp[\"result\"][\"loss\"]\n",
    "\n",
    "print(\"Best parameters:\", best_params_mlp)\n",
    "print(\"Best score:\", best_score_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.0007780975361284449,\n",
       "              hidden_layer_sizes=(20,), max_iter=1500, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.0007780975361284449,\n",
       "              hidden_layer_sizes=(20,), max_iter=1500, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0007780975361284449,\n",
       "              hidden_layer_sizes=(20,), max_iter=1500, solver='lbfgs')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit the classifier with the best hyperparameter set\n",
    "temp_params_dict = space_eval(space, best_search_mlp)\n",
    "final_params_mlp = {\n",
    "    'activation': temp_params_dict['activation'],\n",
    "    'hidden_layer_sizes': temp_params_dict['hidden_layer_sizes'],\n",
    "    'alpha': temp_params_dict['alpha'],       \n",
    "    'solver': temp_params_dict['solver']['solver'],\n",
    "    'learning_rate': temp_params_dict['solver']['learning_rate'],\n",
    "}\n",
    "\n",
    "mlp_clf = MLPClassifier(**final_params_mlp, max_iter=1500)\n",
    "mlp_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ensemble techniques to improve model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 as a reference RandomForest (which is a Bagging classifier of DT) from Scikit-learn is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_features=&#x27;log2&#x27;, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_features=&#x27;log2&#x27;, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='log_loss', max_features='log2', n_jobs=-1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(**final_params_Tree, n_jobs=-1)\n",
    "\n",
    "rnd_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Bagging classifier on best_model from the previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 CatBoost (DT based) becuase of good perofrmance with previous study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/7 [00:00<?, ?trial/s, best loss=?]0:\tlearn: 0.6874611\ttotal: 237ms\tremaining: 21.1s\n",
      "1:\tlearn: 0.6829735\ttotal: 247ms\tremaining: 10.8s\n",
      "2:\tlearn: 0.6792266\ttotal: 255ms\tremaining: 7.39s\n",
      "3:\tlearn: 0.6759123\ttotal: 263ms\tremaining: 5.65s\n",
      "4:\tlearn: 0.6726832\ttotal: 270ms\tremaining: 4.59s\n",
      "5:\tlearn: 0.6699108\ttotal: 278ms\tremaining: 3.88s\n",
      "6:\tlearn: 0.6676551\ttotal: 285ms\tremaining: 3.37s\n",
      "7:\tlearn: 0.6650061\ttotal: 292ms\tremaining: 2.99s\n",
      "8:\tlearn: 0.6629257\ttotal: 299ms\tremaining: 2.69s\n",
      "9:\tlearn: 0.6607620\ttotal: 306ms\tremaining: 2.44s\n",
      "10:\tlearn: 0.6588020\ttotal: 313ms\tremaining: 2.25s\n",
      "11:\tlearn: 0.6569197\ttotal: 319ms\tremaining: 2.07s\n",
      "12:\tlearn: 0.6552239\ttotal: 325ms\tremaining: 1.93s\n",
      "13:\tlearn: 0.6536946\ttotal: 332ms\tremaining: 1.8s\n",
      "14:\tlearn: 0.6519640\ttotal: 338ms\tremaining: 1.69s\n",
      "15:\tlearn: 0.6505079\ttotal: 344ms\tremaining: 1.59s\n",
      "16:\tlearn: 0.6489253\ttotal: 351ms\tremaining: 1.51s\n",
      "17:\tlearn: 0.6474890\ttotal: 357ms\tremaining: 1.43s\n",
      "18:\tlearn: 0.6459424\ttotal: 364ms\tremaining: 1.36s\n",
      "19:\tlearn: 0.6445998\ttotal: 370ms\tremaining: 1.3s\n",
      "20:\tlearn: 0.6433140\ttotal: 377ms\tremaining: 1.24s\n",
      "21:\tlearn: 0.6419925\ttotal: 384ms\tremaining: 1.19s\n",
      "22:\tlearn: 0.6407712\ttotal: 391ms\tremaining: 1.14s\n",
      "23:\tlearn: 0.6397458\ttotal: 398ms\tremaining: 1.09s\n",
      "24:\tlearn: 0.6385520\ttotal: 405ms\tremaining: 1.05s\n",
      "25:\tlearn: 0.6374053\ttotal: 413ms\tremaining: 1.01s\n",
      "26:\tlearn: 0.6363686\ttotal: 419ms\tremaining: 978ms\n",
      "27:\tlearn: 0.6352921\ttotal: 427ms\tremaining: 944ms\n",
      "28:\tlearn: 0.6342557\ttotal: 433ms\tremaining: 912ms\n",
      "29:\tlearn: 0.6333762\ttotal: 442ms\tremaining: 884ms\n",
      "30:\tlearn: 0.6324590\ttotal: 451ms\tremaining: 858ms\n",
      "31:\tlearn: 0.6315978\ttotal: 460ms\tremaining: 833ms\n",
      "32:\tlearn: 0.6307277\ttotal: 468ms\tremaining: 809ms\n",
      "33:\tlearn: 0.6299765\ttotal: 476ms\tremaining: 784ms\n",
      "34:\tlearn: 0.6290775\ttotal: 483ms\tremaining: 760ms\n",
      "35:\tlearn: 0.6283239\ttotal: 491ms\tremaining: 736ms\n",
      "36:\tlearn: 0.6274623\ttotal: 499ms\tremaining: 715ms\n",
      "37:\tlearn: 0.6266543\ttotal: 507ms\tremaining: 693ms\n",
      "38:\tlearn: 0.6258280\ttotal: 514ms\tremaining: 672ms\n",
      "39:\tlearn: 0.6251249\ttotal: 521ms\tremaining: 652ms\n",
      "40:\tlearn: 0.6244818\ttotal: 528ms\tremaining: 631ms\n",
      "41:\tlearn: 0.6236569\ttotal: 535ms\tremaining: 612ms\n",
      "42:\tlearn: 0.6230406\ttotal: 542ms\tremaining: 593ms\n",
      "43:\tlearn: 0.6222870\ttotal: 549ms\tremaining: 574ms\n",
      "44:\tlearn: 0.6216774\ttotal: 557ms\tremaining: 557ms\n",
      "45:\tlearn: 0.6209921\ttotal: 564ms\tremaining: 539ms\n",
      "46:\tlearn: 0.6201863\ttotal: 571ms\tremaining: 522ms\n",
      "47:\tlearn: 0.6195278\ttotal: 578ms\tremaining: 506ms\n",
      "48:\tlearn: 0.6189238\ttotal: 585ms\tremaining: 489ms\n",
      "49:\tlearn: 0.6182261\ttotal: 593ms\tremaining: 474ms\n",
      "50:\tlearn: 0.6173614\ttotal: 601ms\tremaining: 459ms\n",
      "51:\tlearn: 0.6167644\ttotal: 608ms\tremaining: 444ms\n",
      "52:\tlearn: 0.6162342\ttotal: 616ms\tremaining: 430ms\n",
      "53:\tlearn: 0.6157087\ttotal: 623ms\tremaining: 415ms\n",
      "54:\tlearn: 0.6149026\ttotal: 631ms\tremaining: 402ms\n",
      "55:\tlearn: 0.6143472\ttotal: 640ms\tremaining: 388ms\n",
      "56:\tlearn: 0.6137554\ttotal: 647ms\tremaining: 375ms\n",
      "57:\tlearn: 0.6130739\ttotal: 657ms\tremaining: 362ms\n",
      "58:\tlearn: 0.6125356\ttotal: 664ms\tremaining: 349ms\n",
      "59:\tlearn: 0.6119422\ttotal: 672ms\tremaining: 336ms\n",
      "60:\tlearn: 0.6114406\ttotal: 679ms\tremaining: 323ms\n",
      "61:\tlearn: 0.6109036\ttotal: 687ms\tremaining: 310ms\n",
      "62:\tlearn: 0.6105197\ttotal: 704ms\tremaining: 302ms\n",
      "63:\tlearn: 0.6099472\ttotal: 710ms\tremaining: 289ms\n",
      "64:\tlearn: 0.6095567\ttotal: 717ms\tremaining: 276ms\n",
      "65:\tlearn: 0.6090273\ttotal: 724ms\tremaining: 263ms\n",
      "66:\tlearn: 0.6083843\ttotal: 732ms\tremaining: 251ms\n",
      "67:\tlearn: 0.6079335\ttotal: 739ms\tremaining: 239ms\n",
      "68:\tlearn: 0.6073918\ttotal: 746ms\tremaining: 227ms\n",
      "69:\tlearn: 0.6069436\ttotal: 754ms\tremaining: 215ms\n",
      "70:\tlearn: 0.6063717\ttotal: 761ms\tremaining: 204ms\n",
      "71:\tlearn: 0.6057808\ttotal: 769ms\tremaining: 192ms\n",
      "72:\tlearn: 0.6053606\ttotal: 776ms\tremaining: 181ms\n",
      "73:\tlearn: 0.6049663\ttotal: 784ms\tremaining: 169ms\n",
      "74:\tlearn: 0.6044623\ttotal: 791ms\tremaining: 158ms\n",
      "75:\tlearn: 0.6041296\ttotal: 798ms\tremaining: 147ms\n",
      "76:\tlearn: 0.6035514\ttotal: 806ms\tremaining: 136ms\n",
      "77:\tlearn: 0.6030746\ttotal: 813ms\tremaining: 125ms\n",
      "78:\tlearn: 0.6027254\ttotal: 821ms\tremaining: 114ms\n",
      "79:\tlearn: 0.6023693\ttotal: 828ms\tremaining: 103ms\n",
      "80:\tlearn: 0.6019676\ttotal: 836ms\tremaining: 92.9ms\n",
      "81:\tlearn: 0.6016109\ttotal: 843ms\tremaining: 82.2ms\n",
      "82:\tlearn: 0.6013138\ttotal: 850ms\tremaining: 71.7ms\n",
      "83:\tlearn: 0.6008881\ttotal: 858ms\tremaining: 61.3ms\n",
      "84:\tlearn: 0.6003651\ttotal: 866ms\tremaining: 50.9ms\n",
      "85:\tlearn: 0.6000757\ttotal: 873ms\tremaining: 40.6ms\n",
      "86:\tlearn: 0.5996080\ttotal: 881ms\tremaining: 30.4ms\n",
      "87:\tlearn: 0.5991408\ttotal: 890ms\tremaining: 20.2ms\n",
      "88:\tlearn: 0.5987322\ttotal: 898ms\tremaining: 10.1ms\n",
      "89:\tlearn: 0.5983850\ttotal: 905ms\tremaining: 0us\n",
      "0:\tlearn: 0.6884798\ttotal: 10.7ms\tremaining: 956ms\n",
      "1:\tlearn: 0.6850981\ttotal: 21.1ms\tremaining: 929ms\n",
      "2:\tlearn: 0.6826602\ttotal: 29.3ms\tremaining: 848ms\n",
      "3:\tlearn: 0.6803429\ttotal: 36.9ms\tremaining: 794ms\n",
      "4:\tlearn: 0.6779817\ttotal: 44ms\tremaining: 748ms\n",
      "5:\tlearn: 0.6755292\ttotal: 50.5ms\tremaining: 707ms\n",
      "6:\tlearn: 0.6738627\ttotal: 56.5ms\tremaining: 670ms\n",
      "7:\tlearn: 0.6720190\ttotal: 62.2ms\tremaining: 638ms\n",
      "8:\tlearn: 0.6704588\ttotal: 68.3ms\tremaining: 615ms\n",
      "9:\tlearn: 0.6686025\ttotal: 74.6ms\tremaining: 597ms\n",
      "10:\tlearn: 0.6668992\ttotal: 81.4ms\tremaining: 584ms\n",
      "11:\tlearn: 0.6654865\ttotal: 88.2ms\tremaining: 573ms\n",
      "12:\tlearn: 0.6639850\ttotal: 95ms\tremaining: 563ms\n",
      "13:\tlearn: 0.6627283\ttotal: 103ms\tremaining: 559ms\n",
      "14:\tlearn: 0.6614804\ttotal: 110ms\tremaining: 550ms\n",
      "15:\tlearn: 0.6606111\ttotal: 117ms\tremaining: 541ms\n",
      "16:\tlearn: 0.6592019\ttotal: 124ms\tremaining: 533ms\n",
      "17:\tlearn: 0.6582270\ttotal: 131ms\tremaining: 524ms\n",
      "18:\tlearn: 0.6570965\ttotal: 138ms\tremaining: 515ms\n",
      "19:\tlearn: 0.6559676\ttotal: 145ms\tremaining: 506ms\n",
      "20:\tlearn: 0.6548525\ttotal: 152ms\tremaining: 498ms\n",
      "21:\tlearn: 0.6538405\ttotal: 159ms\tremaining: 491ms\n",
      "22:\tlearn: 0.6528679\ttotal: 166ms\tremaining: 483ms\n",
      "23:\tlearn: 0.6519362\ttotal: 172ms\tremaining: 474ms\n",
      "24:\tlearn: 0.6511607\ttotal: 182ms\tremaining: 473ms\n",
      "25:\tlearn: 0.6503583\ttotal: 190ms\tremaining: 469ms\n",
      "26:\tlearn: 0.6493791\ttotal: 199ms\tremaining: 464ms\n",
      "27:\tlearn: 0.6484848\ttotal: 206ms\tremaining: 457ms\n",
      "28:\tlearn: 0.6477364\ttotal: 213ms\tremaining: 449ms\n",
      "29:\tlearn: 0.6470334\ttotal: 222ms\tremaining: 444ms\n",
      "30:\tlearn: 0.6463838\ttotal: 229ms\tremaining: 437ms\n",
      "31:\tlearn: 0.6456825\ttotal: 236ms\tremaining: 428ms\n",
      "32:\tlearn: 0.6450145\ttotal: 244ms\tremaining: 421ms\n",
      "33:\tlearn: 0.6443122\ttotal: 251ms\tremaining: 413ms\n",
      "34:\tlearn: 0.6437126\ttotal: 258ms\tremaining: 405ms\n",
      "35:\tlearn: 0.6430226\ttotal: 266ms\tremaining: 398ms\n",
      "36:\tlearn: 0.6423336\ttotal: 273ms\tremaining: 392ms\n",
      "37:\tlearn: 0.6417149\ttotal: 281ms\tremaining: 385ms\n",
      "38:\tlearn: 0.6410551\ttotal: 288ms\tremaining: 377ms\n",
      "39:\tlearn: 0.6405363\ttotal: 296ms\tremaining: 369ms\n",
      "40:\tlearn: 0.6398910\ttotal: 302ms\tremaining: 361ms\n",
      "41:\tlearn: 0.6390468\ttotal: 310ms\tremaining: 354ms\n",
      "42:\tlearn: 0.6384088\ttotal: 317ms\tremaining: 347ms\n",
      "43:\tlearn: 0.6377592\ttotal: 325ms\tremaining: 339ms\n",
      "44:\tlearn: 0.6371966\ttotal: 332ms\tremaining: 332ms\n",
      "45:\tlearn: 0.6366327\ttotal: 339ms\tremaining: 324ms\n",
      "46:\tlearn: 0.6360226\ttotal: 346ms\tremaining: 317ms\n",
      "47:\tlearn: 0.6354552\ttotal: 353ms\tremaining: 309ms\n",
      "48:\tlearn: 0.6349002\ttotal: 361ms\tremaining: 302ms\n",
      "49:\tlearn: 0.6343849\ttotal: 368ms\tremaining: 295ms\n",
      "50:\tlearn: 0.6338361\ttotal: 376ms\tremaining: 287ms\n",
      "51:\tlearn: 0.6332962\ttotal: 384ms\tremaining: 280ms\n",
      "52:\tlearn: 0.6328007\ttotal: 391ms\tremaining: 273ms\n",
      "53:\tlearn: 0.6322884\ttotal: 398ms\tremaining: 266ms\n",
      "54:\tlearn: 0.6317450\ttotal: 406ms\tremaining: 258ms\n",
      "55:\tlearn: 0.6314355\ttotal: 413ms\tremaining: 251ms\n",
      "56:\tlearn: 0.6310275\ttotal: 420ms\tremaining: 243ms\n",
      "57:\tlearn: 0.6306256\ttotal: 428ms\tremaining: 236ms\n",
      "58:\tlearn: 0.6301491\ttotal: 436ms\tremaining: 229ms\n",
      "59:\tlearn: 0.6297049\ttotal: 445ms\tremaining: 222ms\n",
      "60:\tlearn: 0.6293513\ttotal: 452ms\tremaining: 215ms\n",
      "61:\tlearn: 0.6289073\ttotal: 460ms\tremaining: 208ms\n",
      "62:\tlearn: 0.6285076\ttotal: 467ms\tremaining: 200ms\n",
      "63:\tlearn: 0.6281426\ttotal: 475ms\tremaining: 193ms\n",
      "64:\tlearn: 0.6278097\ttotal: 481ms\tremaining: 185ms\n",
      "65:\tlearn: 0.6273598\ttotal: 488ms\tremaining: 178ms\n",
      "66:\tlearn: 0.6269091\ttotal: 496ms\tremaining: 170ms\n",
      "67:\tlearn: 0.6265269\ttotal: 503ms\tremaining: 163ms\n",
      "68:\tlearn: 0.6260131\ttotal: 511ms\tremaining: 156ms\n",
      "69:\tlearn: 0.6255998\ttotal: 518ms\tremaining: 148ms\n",
      "70:\tlearn: 0.6252497\ttotal: 526ms\tremaining: 141ms\n",
      "71:\tlearn: 0.6248591\ttotal: 533ms\tremaining: 133ms\n",
      "72:\tlearn: 0.6244810\ttotal: 541ms\tremaining: 126ms\n",
      "73:\tlearn: 0.6242255\ttotal: 548ms\tremaining: 119ms\n",
      "74:\tlearn: 0.6239701\ttotal: 555ms\tremaining: 111ms\n",
      "75:\tlearn: 0.6235700\ttotal: 563ms\tremaining: 104ms\n",
      "76:\tlearn: 0.6230371\ttotal: 570ms\tremaining: 96.3ms\n",
      "77:\tlearn: 0.6227987\ttotal: 577ms\tremaining: 88.8ms\n",
      "78:\tlearn: 0.6224100\ttotal: 584ms\tremaining: 81.4ms\n",
      "79:\tlearn: 0.6220822\ttotal: 592ms\tremaining: 74ms\n",
      "80:\tlearn: 0.6217471\ttotal: 599ms\tremaining: 66.6ms\n",
      "81:\tlearn: 0.6213744\ttotal: 607ms\tremaining: 59.2ms\n",
      "82:\tlearn: 0.6210648\ttotal: 614ms\tremaining: 51.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83:\tlearn: 0.6207141\ttotal: 622ms\tremaining: 44.4ms\n",
      "84:\tlearn: 0.6204005\ttotal: 631ms\tremaining: 37.1ms\n",
      "85:\tlearn: 0.6201454\ttotal: 639ms\tremaining: 29.7ms\n",
      "86:\tlearn: 0.6198047\ttotal: 646ms\tremaining: 22.3ms\n",
      "87:\tlearn: 0.6195142\ttotal: 654ms\tremaining: 14.9ms\n",
      "88:\tlearn: 0.6191632\ttotal: 662ms\tremaining: 7.43ms\n",
      "89:\tlearn: 0.6189119\ttotal: 669ms\tremaining: 0us\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                          | 1/7 [00:03<00:22,  3.73s/trial, best loss: -0.6564025529325774]0:\tlearn: 0.6747102\ttotal: 3.25s\tremaining: 5m 22s\n",
      "1:\tlearn: 0.6611379\ttotal: 5.29s\tremaining: 4m 19s\n",
      "2:\tlearn: 0.6492943\ttotal: 7.64s\tremaining: 4m 7s\n",
      "3:\tlearn: 0.6391690\ttotal: 10s\tremaining: 4m\n",
      "4:\tlearn: 0.6295053\ttotal: 12.5s\tremaining: 3m 57s\n",
      "5:\tlearn: 0.6213702\ttotal: 14.8s\tremaining: 3m 52s\n",
      "6:\tlearn: 0.6133086\ttotal: 17.1s\tremaining: 3m 47s\n",
      "7:\tlearn: 0.6038669\ttotal: 19.6s\tremaining: 3m 44s\n",
      "8:\tlearn: 0.5960810\ttotal: 21.9s\tremaining: 3m 41s\n",
      "9:\tlearn: 0.5861941\ttotal: 24.3s\tremaining: 3m 38s\n",
      "10:\tlearn: 0.5797100\ttotal: 26.4s\tremaining: 3m 33s\n",
      "11:\tlearn: 0.5738078\ttotal: 28.4s\tremaining: 3m 28s\n",
      "12:\tlearn: 0.5674397\ttotal: 30.4s\tremaining: 3m 23s\n",
      "13:\tlearn: 0.5601865\ttotal: 32.4s\tremaining: 3m 19s\n",
      "14:\tlearn: 0.5544203\ttotal: 34.4s\tremaining: 3m 15s\n",
      "15:\tlearn: 0.5468339\ttotal: 36.6s\tremaining: 3m 11s\n",
      "16:\tlearn: 0.5427623\ttotal: 38.5s\tremaining: 3m 8s\n",
      "17:\tlearn: 0.5384282\ttotal: 40.5s\tremaining: 3m 4s\n",
      "18:\tlearn: 0.5324394\ttotal: 42.6s\tremaining: 3m 1s\n",
      "19:\tlearn: 0.5286335\ttotal: 44.6s\tremaining: 2m 58s\n",
      "20:\tlearn: 0.5246928\ttotal: 46.6s\tremaining: 2m 55s\n",
      "21:\tlearn: 0.5204290\ttotal: 48.5s\tremaining: 2m 52s\n",
      "22:\tlearn: 0.5124304\ttotal: 50.6s\tremaining: 2m 49s\n",
      "23:\tlearn: 0.5084445\ttotal: 52.6s\tremaining: 2m 46s\n",
      "24:\tlearn: 0.5037687\ttotal: 54.6s\tremaining: 2m 43s\n",
      "25:\tlearn: 0.4970554\ttotal: 56.6s\tremaining: 2m 41s\n",
      "26:\tlearn: 0.4933455\ttotal: 58.6s\tremaining: 2m 38s\n",
      "27:\tlearn: 0.4895691\ttotal: 1m\tremaining: 2m 35s\n",
      "28:\tlearn: 0.4861581\ttotal: 1m 2s\tremaining: 2m 33s\n",
      "29:\tlearn: 0.4832517\ttotal: 1m 4s\tremaining: 2m 30s\n",
      "30:\tlearn: 0.4788367\ttotal: 1m 6s\tremaining: 2m 28s\n",
      "31:\tlearn: 0.4741040\ttotal: 1m 8s\tremaining: 2m 25s\n",
      "32:\tlearn: 0.4667482\ttotal: 1m 10s\tremaining: 2m 23s\n",
      "33:\tlearn: 0.4628892\ttotal: 1m 12s\tremaining: 2m 21s\n",
      "34:\tlearn: 0.4580577\ttotal: 1m 14s\tremaining: 2m 18s\n",
      "35:\tlearn: 0.4542018\ttotal: 1m 16s\tremaining: 2m 16s\n",
      "36:\tlearn: 0.4486787\ttotal: 1m 18s\tremaining: 2m 14s\n",
      "37:\tlearn: 0.4448590\ttotal: 1m 20s\tremaining: 2m 11s\n",
      "38:\tlearn: 0.4420002\ttotal: 1m 22s\tremaining: 2m 9s\n",
      "39:\tlearn: 0.4377938\ttotal: 1m 24s\tremaining: 2m 7s\n",
      "40:\tlearn: 0.4350234\ttotal: 1m 26s\tremaining: 2m 4s\n",
      "41:\tlearn: 0.4333271\ttotal: 1m 28s\tremaining: 2m 2s\n",
      "42:\tlearn: 0.4286055\ttotal: 1m 30s\tremaining: 2m\n",
      "43:\tlearn: 0.4258148\ttotal: 1m 32s\tremaining: 1m 58s\n",
      "44:\tlearn: 0.4235467\ttotal: 1m 34s\tremaining: 1m 55s\n",
      "45:\tlearn: 0.4195529\ttotal: 1m 36s\tremaining: 1m 53s\n",
      "46:\tlearn: 0.4157520\ttotal: 1m 38s\tremaining: 1m 51s\n",
      "47:\tlearn: 0.4139236\ttotal: 1m 40s\tremaining: 1m 49s\n",
      "48:\tlearn: 0.4108387\ttotal: 1m 42s\tremaining: 1m 47s\n",
      "49:\tlearn: 0.4086752\ttotal: 1m 44s\tremaining: 1m 44s\n",
      "50:\tlearn: 0.4054973\ttotal: 1m 46s\tremaining: 1m 42s\n",
      "51:\tlearn: 0.4034165\ttotal: 1m 48s\tremaining: 1m 40s\n",
      "52:\tlearn: 0.3997830\ttotal: 1m 50s\tremaining: 1m 38s\n",
      "53:\tlearn: 0.3973287\ttotal: 1m 52s\tremaining: 1m 36s\n",
      "54:\tlearn: 0.3946591\ttotal: 1m 54s\tremaining: 1m 33s\n",
      "55:\tlearn: 0.3911913\ttotal: 1m 56s\tremaining: 1m 31s\n",
      "56:\tlearn: 0.3894885\ttotal: 1m 58s\tremaining: 1m 29s\n",
      "57:\tlearn: 0.3879585\ttotal: 2m\tremaining: 1m 27s\n",
      "58:\tlearn: 0.3856785\ttotal: 2m 2s\tremaining: 1m 25s\n",
      "59:\tlearn: 0.3840611\ttotal: 2m 4s\tremaining: 1m 23s\n",
      "60:\tlearn: 0.3819240\ttotal: 2m 6s\tremaining: 1m 21s\n",
      "61:\tlearn: 0.3794090\ttotal: 2m 8s\tremaining: 1m 18s\n",
      "62:\tlearn: 0.3777833\ttotal: 2m 10s\tremaining: 1m 16s\n",
      "63:\tlearn: 0.3761579\ttotal: 2m 12s\tremaining: 1m 14s\n",
      "64:\tlearn: 0.3744674\ttotal: 2m 14s\tremaining: 1m 12s\n",
      "65:\tlearn: 0.3720334\ttotal: 2m 16s\tremaining: 1m 10s\n",
      "66:\tlearn: 0.3691299\ttotal: 2m 18s\tremaining: 1m 8s\n",
      "67:\tlearn: 0.3665994\ttotal: 2m 20s\tremaining: 1m 6s\n",
      "68:\tlearn: 0.3649498\ttotal: 2m 22s\tremaining: 1m 4s\n",
      "69:\tlearn: 0.3626578\ttotal: 2m 24s\tremaining: 1m 1s\n",
      "70:\tlearn: 0.3597441\ttotal: 2m 26s\tremaining: 59.8s\n",
      "71:\tlearn: 0.3581265\ttotal: 2m 28s\tremaining: 57.7s\n",
      "72:\tlearn: 0.3533202\ttotal: 2m 30s\tremaining: 55.6s\n",
      "73:\tlearn: 0.3512584\ttotal: 2m 32s\tremaining: 53.5s\n",
      "74:\tlearn: 0.3496511\ttotal: 2m 34s\tremaining: 51.4s\n",
      "75:\tlearn: 0.3476937\ttotal: 2m 36s\tremaining: 49.3s\n",
      "76:\tlearn: 0.3453552\ttotal: 2m 38s\tremaining: 47.4s\n",
      "77:\tlearn: 0.3422963\ttotal: 2m 40s\tremaining: 45.3s\n",
      "78:\tlearn: 0.3392751\ttotal: 2m 42s\tremaining: 43.3s\n",
      "79:\tlearn: 0.3371574\ttotal: 2m 44s\tremaining: 41.2s\n",
      "80:\tlearn: 0.3346543\ttotal: 2m 46s\tremaining: 39.1s\n",
      "81:\tlearn: 0.3326372\ttotal: 2m 48s\tremaining: 37s\n",
      "82:\tlearn: 0.3303278\ttotal: 2m 50s\tremaining: 35s\n",
      "83:\tlearn: 0.3282857\ttotal: 2m 52s\tremaining: 32.9s\n",
      "84:\tlearn: 0.3252143\ttotal: 2m 54s\tremaining: 30.9s\n",
      "85:\tlearn: 0.3217748\ttotal: 2m 56s\tremaining: 28.8s\n",
      "86:\tlearn: 0.3200608\ttotal: 2m 58s\tremaining: 26.7s\n",
      "87:\tlearn: 0.3177282\ttotal: 3m\tremaining: 24.7s\n",
      "88:\tlearn: 0.3154109\ttotal: 3m 2s\tremaining: 22.6s\n",
      "89:\tlearn: 0.3133359\ttotal: 3m 4s\tremaining: 20.5s\n",
      "90:\tlearn: 0.3113333\ttotal: 3m 6s\tremaining: 18.5s\n",
      "91:\tlearn: 0.3101303\ttotal: 3m 8s\tremaining: 16.4s\n",
      "92:\tlearn: 0.3075548\ttotal: 3m 10s\tremaining: 14.4s\n",
      "93:\tlearn: 0.3058089\ttotal: 3m 12s\tremaining: 12.3s\n",
      "94:\tlearn: 0.3031465\ttotal: 3m 14s\tremaining: 10.3s\n",
      "95:\tlearn: 0.3019840\ttotal: 3m 16s\tremaining: 8.2s\n",
      "96:\tlearn: 0.2992397\ttotal: 3m 18s\tremaining: 6.15s\n",
      "97:\tlearn: 0.2978082\ttotal: 3m 20s\tremaining: 4.1s\n",
      "98:\tlearn: 0.2968033\ttotal: 3m 22s\tremaining: 2.05s\n",
      "99:\tlearn: 0.2945086\ttotal: 3m 24s\tremaining: 0us\n",
      "0:\tlearn: 0.6794996\ttotal: 1.97s\tremaining: 3m 14s\n",
      "1:\tlearn: 0.6667435\ttotal: 3.94s\tremaining: 3m 12s\n",
      "2:\tlearn: 0.6570335\ttotal: 5.91s\tremaining: 3m 11s\n",
      "3:\tlearn: 0.6465561\ttotal: 7.87s\tremaining: 3m 8s\n",
      "4:\tlearn: 0.6391667\ttotal: 9.8s\tremaining: 3m 6s\n",
      "5:\tlearn: 0.6295509\ttotal: 11.8s\tremaining: 3m 4s\n",
      "6:\tlearn: 0.6228481\ttotal: 13.9s\tremaining: 3m 4s\n",
      "7:\tlearn: 0.6143522\ttotal: 15.8s\tremaining: 3m 2s\n",
      "8:\tlearn: 0.6073791\ttotal: 17.8s\tremaining: 2m 59s\n",
      "9:\tlearn: 0.5976774\ttotal: 19.8s\tremaining: 2m 58s\n",
      "10:\tlearn: 0.5912175\ttotal: 21.8s\tremaining: 2m 56s\n",
      "11:\tlearn: 0.5852378\ttotal: 23.7s\tremaining: 2m 54s\n",
      "12:\tlearn: 0.5787513\ttotal: 25.7s\tremaining: 2m 52s\n",
      "13:\tlearn: 0.5708817\ttotal: 27.7s\tremaining: 2m 50s\n",
      "14:\tlearn: 0.5644722\ttotal: 29.7s\tremaining: 2m 48s\n",
      "15:\tlearn: 0.5572164\ttotal: 31.8s\tremaining: 2m 47s\n",
      "16:\tlearn: 0.5502589\ttotal: 33.9s\tremaining: 2m 45s\n",
      "17:\tlearn: 0.5454057\ttotal: 35.9s\tremaining: 2m 43s\n",
      "18:\tlearn: 0.5398052\ttotal: 37.9s\tremaining: 2m 41s\n",
      "19:\tlearn: 0.5343359\ttotal: 39.9s\tremaining: 2m 39s\n",
      "20:\tlearn: 0.5303509\ttotal: 42s\tremaining: 2m 37s\n",
      "21:\tlearn: 0.5251551\ttotal: 43.9s\tremaining: 2m 35s\n",
      "22:\tlearn: 0.5201958\ttotal: 46s\tremaining: 2m 33s\n",
      "23:\tlearn: 0.5162697\ttotal: 48s\tremaining: 2m 32s\n",
      "24:\tlearn: 0.5116742\ttotal: 50s\tremaining: 2m 30s\n",
      "25:\tlearn: 0.5069543\ttotal: 52.1s\tremaining: 2m 28s\n",
      "26:\tlearn: 0.5028318\ttotal: 54.1s\tremaining: 2m 26s\n",
      "27:\tlearn: 0.4975742\ttotal: 56.1s\tremaining: 2m 24s\n",
      "28:\tlearn: 0.4928644\ttotal: 58.2s\tremaining: 2m 22s\n",
      "29:\tlearn: 0.4884798\ttotal: 1m\tremaining: 2m 20s\n",
      "30:\tlearn: 0.4838070\ttotal: 1m 2s\tremaining: 2m 18s\n",
      "31:\tlearn: 0.4797368\ttotal: 1m 4s\tremaining: 2m 16s\n",
      "32:\tlearn: 0.4740863\ttotal: 1m 6s\tremaining: 2m 14s\n",
      "33:\tlearn: 0.4697436\ttotal: 1m 8s\tremaining: 2m 13s\n",
      "34:\tlearn: 0.4648349\ttotal: 1m 10s\tremaining: 2m 11s\n",
      "35:\tlearn: 0.4577395\ttotal: 1m 12s\tremaining: 2m 9s\n",
      "36:\tlearn: 0.4541028\ttotal: 1m 15s\tremaining: 2m 7s\n",
      "37:\tlearn: 0.4501920\ttotal: 1m 17s\tremaining: 2m 5s\n",
      "38:\tlearn: 0.4470455\ttotal: 1m 19s\tremaining: 2m 3s\n",
      "39:\tlearn: 0.4431836\ttotal: 1m 21s\tremaining: 2m 1s\n",
      "40:\tlearn: 0.4399081\ttotal: 1m 23s\tremaining: 1m 59s\n",
      "41:\tlearn: 0.4372324\ttotal: 1m 25s\tremaining: 1m 58s\n",
      "42:\tlearn: 0.4319529\ttotal: 1m 27s\tremaining: 1m 56s\n",
      "43:\tlearn: 0.4293075\ttotal: 1m 29s\tremaining: 1m 54s\n",
      "44:\tlearn: 0.4250766\ttotal: 1m 31s\tremaining: 1m 52s\n",
      "45:\tlearn: 0.4219220\ttotal: 1m 33s\tremaining: 1m 50s\n",
      "46:\tlearn: 0.4184373\ttotal: 1m 36s\tremaining: 1m 48s\n",
      "47:\tlearn: 0.4144899\ttotal: 1m 38s\tremaining: 1m 46s\n",
      "48:\tlearn: 0.4118329\ttotal: 1m 40s\tremaining: 1m 44s\n",
      "49:\tlearn: 0.4097128\ttotal: 1m 42s\tremaining: 1m 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:\tlearn: 0.4062256\ttotal: 1m 44s\tremaining: 1m 40s\n",
      "51:\tlearn: 0.4027835\ttotal: 1m 46s\tremaining: 1m 38s\n",
      "52:\tlearn: 0.3997595\ttotal: 1m 49s\tremaining: 1m 36s\n",
      "53:\tlearn: 0.3979402\ttotal: 1m 51s\tremaining: 1m 35s\n",
      "54:\tlearn: 0.3961855\ttotal: 1m 53s\tremaining: 1m 33s\n",
      "55:\tlearn: 0.3936227\ttotal: 1m 56s\tremaining: 1m 31s\n",
      "56:\tlearn: 0.3914983\ttotal: 1m 58s\tremaining: 1m 29s\n",
      "57:\tlearn: 0.3897724\ttotal: 2m\tremaining: 1m 27s\n",
      "58:\tlearn: 0.3877037\ttotal: 2m 2s\tremaining: 1m 24s\n",
      "59:\tlearn: 0.3854996\ttotal: 2m 4s\tremaining: 1m 22s\n",
      "60:\tlearn: 0.3828436\ttotal: 2m 6s\tremaining: 1m 20s\n",
      "61:\tlearn: 0.3814505\ttotal: 2m 8s\tremaining: 1m 18s\n",
      "62:\tlearn: 0.3792185\ttotal: 2m 10s\tremaining: 1m 16s\n",
      "63:\tlearn: 0.3770447\ttotal: 2m 12s\tremaining: 1m 14s\n",
      "64:\tlearn: 0.3750288\ttotal: 2m 14s\tremaining: 1m 12s\n",
      "65:\tlearn: 0.3723384\ttotal: 2m 16s\tremaining: 1m 10s\n",
      "66:\tlearn: 0.3706358\ttotal: 2m 18s\tremaining: 1m 8s\n",
      "67:\tlearn: 0.3668615\ttotal: 2m 20s\tremaining: 1m 6s\n",
      "68:\tlearn: 0.3647710\ttotal: 2m 22s\tremaining: 1m 4s\n",
      "69:\tlearn: 0.3602807\ttotal: 2m 24s\tremaining: 1m 2s\n",
      "70:\tlearn: 0.3568188\ttotal: 2m 26s\tremaining: 1m\n",
      "71:\tlearn: 0.3550109\ttotal: 2m 29s\tremaining: 58s\n",
      "72:\tlearn: 0.3530297\ttotal: 2m 31s\tremaining: 55.9s\n",
      "73:\tlearn: 0.3497674\ttotal: 2m 33s\tremaining: 53.8s\n",
      "74:\tlearn: 0.3469706\ttotal: 2m 35s\tremaining: 51.7s\n",
      "75:\tlearn: 0.3430784\ttotal: 2m 37s\tremaining: 49.6s\n",
      "76:\tlearn: 0.3408966\ttotal: 2m 39s\tremaining: 47.5s\n",
      "77:\tlearn: 0.3380159\ttotal: 2m 41s\tremaining: 45.5s\n",
      "78:\tlearn: 0.3354221\ttotal: 2m 43s\tremaining: 43.4s\n",
      "79:\tlearn: 0.3331408\ttotal: 2m 45s\tremaining: 41.3s\n",
      "80:\tlearn: 0.3309783\ttotal: 2m 47s\tremaining: 39.2s\n",
      "81:\tlearn: 0.3287336\ttotal: 2m 49s\tremaining: 37.1s\n",
      "82:\tlearn: 0.3270140\ttotal: 2m 51s\tremaining: 35.1s\n",
      "83:\tlearn: 0.3250446\ttotal: 2m 53s\tremaining: 33s\n",
      "84:\tlearn: 0.3232998\ttotal: 2m 55s\tremaining: 30.9s\n",
      "85:\tlearn: 0.3206353\ttotal: 2m 57s\tremaining: 28.9s\n",
      "86:\tlearn: 0.3180207\ttotal: 2m 59s\tremaining: 26.8s\n",
      "87:\tlearn: 0.3155295\ttotal: 3m 1s\tremaining: 24.7s\n",
      "88:\tlearn: 0.3126994\ttotal: 3m 3s\tremaining: 22.7s\n",
      "89:\tlearn: 0.3111635\ttotal: 3m 5s\tremaining: 20.6s\n",
      "90:\tlearn: 0.3091552\ttotal: 3m 7s\tremaining: 18.5s\n",
      "91:\tlearn: 0.3068183\ttotal: 3m 9s\tremaining: 16.5s\n",
      "92:\tlearn: 0.3035882\ttotal: 3m 11s\tremaining: 14.4s\n",
      "93:\tlearn: 0.3016795\ttotal: 3m 13s\tremaining: 12.3s\n",
      "94:\tlearn: 0.3004796\ttotal: 3m 15s\tremaining: 10.3s\n",
      "95:\tlearn: 0.2976232\ttotal: 3m 17s\tremaining: 8.23s\n",
      "96:\tlearn: 0.2955325\ttotal: 3m 19s\tremaining: 6.17s\n",
      "97:\tlearn: 0.2943885\ttotal: 3m 21s\tremaining: 4.11s\n",
      "98:\tlearn: 0.2928002\ttotal: 3m 23s\tremaining: 2.06s\n",
      "99:\tlearn: 0.2898453\ttotal: 3m 25s\tremaining: 0us\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                  | 2/7 [06:56<20:20, 244.15s/trial, best loss: -0.7742167129955947]0:\tlearn: 0.6804708\ttotal: 78.6ms\tremaining: 5.43s\n",
      "1:\tlearn: 0.6705070\ttotal: 169ms\tremaining: 5.76s\n",
      "2:\tlearn: 0.6622853\ttotal: 278ms\tremaining: 6.2s\n",
      "3:\tlearn: 0.6564068\ttotal: 360ms\tremaining: 5.94s\n",
      "4:\tlearn: 0.6506195\ttotal: 436ms\tremaining: 5.67s\n",
      "5:\tlearn: 0.6446703\ttotal: 509ms\tremaining: 5.43s\n",
      "6:\tlearn: 0.6402626\ttotal: 584ms\tremaining: 5.25s\n",
      "7:\tlearn: 0.6353064\ttotal: 662ms\tremaining: 5.13s\n",
      "8:\tlearn: 0.6300755\ttotal: 742ms\tremaining: 5.03s\n",
      "9:\tlearn: 0.6259495\ttotal: 825ms\tremaining: 4.95s\n",
      "10:\tlearn: 0.6222444\ttotal: 903ms\tremaining: 4.84s\n",
      "11:\tlearn: 0.6184633\ttotal: 981ms\tremaining: 4.74s\n",
      "12:\tlearn: 0.6152124\ttotal: 1.06s\tremaining: 4.64s\n",
      "13:\tlearn: 0.6123773\ttotal: 1.14s\tremaining: 4.55s\n",
      "14:\tlearn: 0.6090957\ttotal: 1.22s\tremaining: 4.47s\n",
      "15:\tlearn: 0.6042429\ttotal: 1.3s\tremaining: 4.39s\n",
      "16:\tlearn: 0.6014020\ttotal: 1.38s\tremaining: 4.3s\n",
      "17:\tlearn: 0.5984975\ttotal: 1.46s\tremaining: 4.21s\n",
      "18:\tlearn: 0.5961483\ttotal: 1.53s\tremaining: 4.12s\n",
      "19:\tlearn: 0.5931578\ttotal: 1.61s\tremaining: 4.04s\n",
      "20:\tlearn: 0.5906692\ttotal: 1.69s\tremaining: 3.95s\n",
      "21:\tlearn: 0.5880379\ttotal: 1.77s\tremaining: 3.86s\n",
      "22:\tlearn: 0.5848215\ttotal: 1.85s\tremaining: 3.78s\n",
      "23:\tlearn: 0.5827221\ttotal: 1.93s\tremaining: 3.69s\n",
      "24:\tlearn: 0.5796376\ttotal: 2.01s\tremaining: 3.62s\n",
      "25:\tlearn: 0.5764517\ttotal: 2.09s\tremaining: 3.54s\n",
      "26:\tlearn: 0.5742799\ttotal: 2.17s\tremaining: 3.46s\n",
      "27:\tlearn: 0.5722523\ttotal: 2.25s\tremaining: 3.38s\n",
      "28:\tlearn: 0.5694308\ttotal: 2.33s\tremaining: 3.3s\n",
      "29:\tlearn: 0.5661597\ttotal: 2.42s\tremaining: 3.23s\n",
      "30:\tlearn: 0.5620141\ttotal: 2.52s\tremaining: 3.17s\n",
      "31:\tlearn: 0.5594592\ttotal: 2.6s\tremaining: 3.09s\n",
      "32:\tlearn: 0.5579018\ttotal: 2.68s\tremaining: 3.01s\n",
      "33:\tlearn: 0.5551037\ttotal: 2.76s\tremaining: 2.93s\n",
      "34:\tlearn: 0.5523248\ttotal: 2.85s\tremaining: 2.85s\n",
      "35:\tlearn: 0.5506910\ttotal: 2.93s\tremaining: 2.77s\n",
      "36:\tlearn: 0.5491695\ttotal: 3.01s\tremaining: 2.69s\n",
      "37:\tlearn: 0.5472269\ttotal: 3.09s\tremaining: 2.6s\n",
      "38:\tlearn: 0.5452123\ttotal: 3.17s\tremaining: 2.52s\n",
      "39:\tlearn: 0.5438835\ttotal: 3.25s\tremaining: 2.44s\n",
      "40:\tlearn: 0.5421494\ttotal: 3.33s\tremaining: 2.36s\n",
      "41:\tlearn: 0.5396453\ttotal: 3.42s\tremaining: 2.28s\n",
      "42:\tlearn: 0.5380119\ttotal: 3.5s\tremaining: 2.2s\n",
      "43:\tlearn: 0.5361742\ttotal: 3.58s\tremaining: 2.12s\n",
      "44:\tlearn: 0.5345346\ttotal: 3.66s\tremaining: 2.03s\n",
      "45:\tlearn: 0.5324612\ttotal: 3.74s\tremaining: 1.95s\n",
      "46:\tlearn: 0.5297865\ttotal: 3.82s\tremaining: 1.87s\n",
      "47:\tlearn: 0.5283377\ttotal: 3.9s\tremaining: 1.79s\n",
      "48:\tlearn: 0.5267722\ttotal: 3.98s\tremaining: 1.7s\n",
      "49:\tlearn: 0.5249225\ttotal: 4.06s\tremaining: 1.62s\n",
      "50:\tlearn: 0.5238479\ttotal: 4.13s\tremaining: 1.54s\n",
      "51:\tlearn: 0.5222743\ttotal: 4.21s\tremaining: 1.46s\n",
      "52:\tlearn: 0.5211426\ttotal: 4.29s\tremaining: 1.38s\n",
      "53:\tlearn: 0.5187329\ttotal: 4.37s\tremaining: 1.29s\n",
      "54:\tlearn: 0.5156212\ttotal: 4.46s\tremaining: 1.22s\n",
      "55:\tlearn: 0.5137060\ttotal: 4.55s\tremaining: 1.14s\n",
      "56:\tlearn: 0.5123883\ttotal: 4.64s\tremaining: 1.06s\n",
      "57:\tlearn: 0.5099495\ttotal: 4.73s\tremaining: 979ms\n",
      "58:\tlearn: 0.5085720\ttotal: 4.82s\tremaining: 898ms\n",
      "59:\tlearn: 0.5074147\ttotal: 4.9s\tremaining: 816ms\n",
      "60:\tlearn: 0.5056712\ttotal: 4.98s\tremaining: 735ms\n",
      "61:\tlearn: 0.5039795\ttotal: 5.06s\tremaining: 653ms\n",
      "62:\tlearn: 0.5011316\ttotal: 5.15s\tremaining: 572ms\n",
      "63:\tlearn: 0.4995795\ttotal: 5.23s\tremaining: 490ms\n",
      "64:\tlearn: 0.4981931\ttotal: 5.32s\tremaining: 409ms\n",
      "65:\tlearn: 0.4966062\ttotal: 5.4s\tremaining: 327ms\n",
      "66:\tlearn: 0.4949760\ttotal: 5.48s\tremaining: 245ms\n",
      "67:\tlearn: 0.4932256\ttotal: 5.56s\tremaining: 164ms\n",
      "68:\tlearn: 0.4911559\ttotal: 5.64s\tremaining: 81.8ms\n",
      "69:\tlearn: 0.4897289\ttotal: 5.72s\tremaining: 0us\n",
      "0:\tlearn: 0.6829632\ttotal: 76.2ms\tremaining: 5.25s\n",
      "1:\tlearn: 0.6749147\ttotal: 154ms\tremaining: 5.24s\n",
      "2:\tlearn: 0.6686231\ttotal: 241ms\tremaining: 5.38s\n",
      "3:\tlearn: 0.6633097\ttotal: 317ms\tremaining: 5.23s\n",
      "4:\tlearn: 0.6578378\ttotal: 396ms\tremaining: 5.14s\n",
      "5:\tlearn: 0.6533896\ttotal: 474ms\tremaining: 5.05s\n",
      "6:\tlearn: 0.6499065\ttotal: 548ms\tremaining: 4.94s\n",
      "7:\tlearn: 0.6458075\ttotal: 624ms\tremaining: 4.84s\n",
      "8:\tlearn: 0.6420234\ttotal: 701ms\tremaining: 4.75s\n",
      "9:\tlearn: 0.6386150\ttotal: 780ms\tremaining: 4.68s\n",
      "10:\tlearn: 0.6345851\ttotal: 863ms\tremaining: 4.63s\n",
      "11:\tlearn: 0.6312990\ttotal: 944ms\tremaining: 4.56s\n",
      "12:\tlearn: 0.6283445\ttotal: 1.02s\tremaining: 4.49s\n",
      "13:\tlearn: 0.6251537\ttotal: 1.11s\tremaining: 4.43s\n",
      "14:\tlearn: 0.6225061\ttotal: 1.19s\tremaining: 4.37s\n",
      "15:\tlearn: 0.6190686\ttotal: 1.27s\tremaining: 4.3s\n",
      "16:\tlearn: 0.6162695\ttotal: 1.36s\tremaining: 4.23s\n",
      "17:\tlearn: 0.6139769\ttotal: 1.44s\tremaining: 4.15s\n",
      "18:\tlearn: 0.6105121\ttotal: 1.52s\tremaining: 4.08s\n",
      "19:\tlearn: 0.6078978\ttotal: 1.6s\tremaining: 4s\n",
      "20:\tlearn: 0.6047871\ttotal: 1.68s\tremaining: 3.93s\n",
      "21:\tlearn: 0.6023866\ttotal: 1.76s\tremaining: 3.85s\n",
      "22:\tlearn: 0.6004121\ttotal: 1.84s\tremaining: 3.77s\n",
      "23:\tlearn: 0.5985777\ttotal: 1.92s\tremaining: 3.68s\n",
      "24:\tlearn: 0.5968886\ttotal: 2s\tremaining: 3.6s\n",
      "25:\tlearn: 0.5937393\ttotal: 2.1s\tremaining: 3.56s\n",
      "26:\tlearn: 0.5903932\ttotal: 2.18s\tremaining: 3.48s\n",
      "27:\tlearn: 0.5877746\ttotal: 2.27s\tremaining: 3.4s\n",
      "28:\tlearn: 0.5855460\ttotal: 2.35s\tremaining: 3.31s\n",
      "29:\tlearn: 0.5835111\ttotal: 2.42s\tremaining: 3.23s\n",
      "30:\tlearn: 0.5804591\ttotal: 2.51s\tremaining: 3.15s\n",
      "31:\tlearn: 0.5785472\ttotal: 2.58s\tremaining: 3.07s\n",
      "32:\tlearn: 0.5760194\ttotal: 2.67s\tremaining: 2.99s\n",
      "33:\tlearn: 0.5724639\ttotal: 2.75s\tremaining: 2.91s\n",
      "34:\tlearn: 0.5701055\ttotal: 2.83s\tremaining: 2.83s\n",
      "35:\tlearn: 0.5675905\ttotal: 2.92s\tremaining: 2.75s\n",
      "36:\tlearn: 0.5657789\ttotal: 2.99s\tremaining: 2.67s\n",
      "37:\tlearn: 0.5631762\ttotal: 3.08s\tremaining: 2.59s\n",
      "38:\tlearn: 0.5611407\ttotal: 3.16s\tremaining: 2.51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39:\tlearn: 0.5597103\ttotal: 3.24s\tremaining: 2.43s\n",
      "40:\tlearn: 0.5575646\ttotal: 3.32s\tremaining: 2.35s\n",
      "41:\tlearn: 0.5558663\ttotal: 3.4s\tremaining: 2.27s\n",
      "42:\tlearn: 0.5539814\ttotal: 3.49s\tremaining: 2.19s\n",
      "43:\tlearn: 0.5525219\ttotal: 3.57s\tremaining: 2.11s\n",
      "44:\tlearn: 0.5514426\ttotal: 3.64s\tremaining: 2.02s\n",
      "45:\tlearn: 0.5503770\ttotal: 3.72s\tremaining: 1.94s\n",
      "46:\tlearn: 0.5484741\ttotal: 3.8s\tremaining: 1.86s\n",
      "47:\tlearn: 0.5467357\ttotal: 3.88s\tremaining: 1.78s\n",
      "48:\tlearn: 0.5456757\ttotal: 3.96s\tremaining: 1.7s\n",
      "49:\tlearn: 0.5434613\ttotal: 4.04s\tremaining: 1.61s\n",
      "50:\tlearn: 0.5419506\ttotal: 4.12s\tremaining: 1.53s\n",
      "51:\tlearn: 0.5398597\ttotal: 4.2s\tremaining: 1.45s\n",
      "52:\tlearn: 0.5371960\ttotal: 4.28s\tremaining: 1.37s\n",
      "53:\tlearn: 0.5360964\ttotal: 4.36s\tremaining: 1.29s\n",
      "54:\tlearn: 0.5346469\ttotal: 4.44s\tremaining: 1.21s\n",
      "55:\tlearn: 0.5314940\ttotal: 4.53s\tremaining: 1.13s\n",
      "56:\tlearn: 0.5298574\ttotal: 4.61s\tremaining: 1.05s\n",
      "57:\tlearn: 0.5273869\ttotal: 4.69s\tremaining: 970ms\n",
      "58:\tlearn: 0.5260654\ttotal: 4.77s\tremaining: 889ms\n",
      "59:\tlearn: 0.5249342\ttotal: 4.84s\tremaining: 807ms\n",
      "60:\tlearn: 0.5224049\ttotal: 4.93s\tremaining: 727ms\n",
      "61:\tlearn: 0.5207661\ttotal: 5.01s\tremaining: 647ms\n",
      "62:\tlearn: 0.5186564\ttotal: 5.09s\tremaining: 566ms\n",
      "63:\tlearn: 0.5168059\ttotal: 5.17s\tremaining: 485ms\n",
      "64:\tlearn: 0.5153370\ttotal: 5.26s\tremaining: 404ms\n",
      "65:\tlearn: 0.5136686\ttotal: 5.34s\tremaining: 324ms\n",
      "66:\tlearn: 0.5118560\ttotal: 5.42s\tremaining: 243ms\n",
      "67:\tlearn: 0.5104033\ttotal: 5.5s\tremaining: 162ms\n",
      "68:\tlearn: 0.5093818\ttotal: 5.57s\tremaining: 80.8ms\n",
      "69:\tlearn: 0.5081161\ttotal: 5.65s\tremaining: 0us\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 3/7 [07:09<09:14, 138.68s/trial, best loss: -0.7742167129955947]0:\tlearn: 0.6919718\ttotal: 13.7ms\tremaining: 397ms\n",
      "1:\tlearn: 0.6910288\ttotal: 24.1ms\tremaining: 338ms\n",
      "2:\tlearn: 0.6900558\ttotal: 31ms\tremaining: 279ms\n",
      "3:\tlearn: 0.6891034\ttotal: 37.4ms\tremaining: 243ms\n",
      "4:\tlearn: 0.6882145\ttotal: 44.4ms\tremaining: 222ms\n",
      "5:\tlearn: 0.6874204\ttotal: 50.5ms\tremaining: 202ms\n",
      "6:\tlearn: 0.6865954\ttotal: 57.9ms\tremaining: 190ms\n",
      "7:\tlearn: 0.6858802\ttotal: 68.4ms\tremaining: 188ms\n",
      "8:\tlearn: 0.6851745\ttotal: 78.5ms\tremaining: 183ms\n",
      "9:\tlearn: 0.6844924\ttotal: 89.8ms\tremaining: 180ms\n",
      "10:\tlearn: 0.6837959\ttotal: 99.1ms\tremaining: 171ms\n",
      "11:\tlearn: 0.6831015\ttotal: 110ms\tremaining: 165ms\n",
      "12:\tlearn: 0.6824338\ttotal: 120ms\tremaining: 156ms\n",
      "13:\tlearn: 0.6818376\ttotal: 131ms\tremaining: 150ms\n",
      "14:\tlearn: 0.6812292\ttotal: 140ms\tremaining: 140ms\n",
      "15:\tlearn: 0.6806835\ttotal: 148ms\tremaining: 129ms\n",
      "16:\tlearn: 0.6800605\ttotal: 156ms\tremaining: 119ms\n",
      "17:\tlearn: 0.6794731\ttotal: 162ms\tremaining: 108ms\n",
      "18:\tlearn: 0.6788788\ttotal: 171ms\tremaining: 98.8ms\n",
      "19:\tlearn: 0.6782621\ttotal: 178ms\tremaining: 89.1ms\n",
      "20:\tlearn: 0.6777384\ttotal: 186ms\tremaining: 79.7ms\n",
      "21:\tlearn: 0.6772025\ttotal: 193ms\tremaining: 70.3ms\n",
      "22:\tlearn: 0.6766388\ttotal: 201ms\tremaining: 61.2ms\n",
      "23:\tlearn: 0.6760900\ttotal: 211ms\tremaining: 52.6ms\n",
      "24:\tlearn: 0.6756124\ttotal: 218ms\tremaining: 43.6ms\n",
      "25:\tlearn: 0.6751022\ttotal: 225ms\tremaining: 34.7ms\n",
      "26:\tlearn: 0.6746031\ttotal: 233ms\tremaining: 25.9ms\n",
      "27:\tlearn: 0.6741249\ttotal: 240ms\tremaining: 17.1ms\n",
      "28:\tlearn: 0.6736598\ttotal: 247ms\tremaining: 8.51ms\n",
      "29:\tlearn: 0.6731617\ttotal: 254ms\tremaining: 0us\n",
      "0:\tlearn: 0.6922231\ttotal: 6.46ms\tremaining: 187ms\n",
      "1:\tlearn: 0.6914207\ttotal: 13.3ms\tremaining: 186ms\n",
      "2:\tlearn: 0.6906253\ttotal: 19.7ms\tremaining: 178ms\n",
      "3:\tlearn: 0.6899313\ttotal: 27.7ms\tremaining: 180ms\n",
      "4:\tlearn: 0.6892770\ttotal: 37.7ms\tremaining: 188ms\n",
      "5:\tlearn: 0.6885896\ttotal: 45.1ms\tremaining: 180ms\n",
      "6:\tlearn: 0.6879658\ttotal: 52.7ms\tremaining: 173ms\n",
      "7:\tlearn: 0.6873312\ttotal: 60.3ms\tremaining: 166ms\n",
      "8:\tlearn: 0.6867464\ttotal: 68.2ms\tremaining: 159ms\n",
      "9:\tlearn: 0.6861969\ttotal: 75.5ms\tremaining: 151ms\n",
      "10:\tlearn: 0.6856630\ttotal: 83.1ms\tremaining: 144ms\n",
      "11:\tlearn: 0.6851761\ttotal: 90.5ms\tremaining: 136ms\n",
      "12:\tlearn: 0.6846126\ttotal: 97.9ms\tremaining: 128ms\n",
      "13:\tlearn: 0.6841214\ttotal: 105ms\tremaining: 120ms\n",
      "14:\tlearn: 0.6836579\ttotal: 112ms\tremaining: 112ms\n",
      "15:\tlearn: 0.6832133\ttotal: 119ms\tremaining: 104ms\n",
      "16:\tlearn: 0.6827904\ttotal: 126ms\tremaining: 96.6ms\n",
      "17:\tlearn: 0.6822933\ttotal: 134ms\tremaining: 89.3ms\n",
      "18:\tlearn: 0.6818496\ttotal: 141ms\tremaining: 81.8ms\n",
      "19:\tlearn: 0.6814410\ttotal: 149ms\tremaining: 74.5ms\n",
      "20:\tlearn: 0.6810139\ttotal: 156ms\tremaining: 66.9ms\n",
      "21:\tlearn: 0.6806050\ttotal: 164ms\tremaining: 59.5ms\n",
      "22:\tlearn: 0.6801970\ttotal: 171ms\tremaining: 52ms\n",
      "23:\tlearn: 0.6797867\ttotal: 178ms\tremaining: 44.5ms\n",
      "24:\tlearn: 0.6793876\ttotal: 185ms\tremaining: 37ms\n",
      "25:\tlearn: 0.6789998\ttotal: 192ms\tremaining: 29.6ms\n",
      "26:\tlearn: 0.6785848\ttotal: 200ms\tremaining: 22.2ms\n",
      "27:\tlearn: 0.6782351\ttotal: 207ms\tremaining: 14.8ms\n",
      "28:\tlearn: 0.6778554\ttotal: 214ms\tremaining: 7.36ms\n",
      "29:\tlearn: 0.6775036\ttotal: 227ms\tremaining: 0us\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 4/7 [07:11<04:14, 84.78s/trial, best loss: -0.7742167129955947]0:\tlearn: 0.6596698\ttotal: 2.08s\tremaining: 1m\n",
      "1:\tlearn: 0.6398779\ttotal: 4.04s\tremaining: 56.5s\n",
      "2:\tlearn: 0.6219713\ttotal: 6.04s\tremaining: 54.4s\n",
      "3:\tlearn: 0.6058425\ttotal: 8.03s\tremaining: 52.2s\n",
      "4:\tlearn: 0.5887010\ttotal: 10s\tremaining: 50.2s\n",
      "5:\tlearn: 0.5733544\ttotal: 12s\tremaining: 48.1s\n",
      "6:\tlearn: 0.5633693\ttotal: 14s\tremaining: 45.9s\n",
      "7:\tlearn: 0.5525588\ttotal: 15.9s\tremaining: 43.8s\n",
      "8:\tlearn: 0.5417693\ttotal: 17.9s\tremaining: 41.7s\n",
      "9:\tlearn: 0.5293664\ttotal: 20s\tremaining: 39.9s\n",
      "10:\tlearn: 0.5192552\ttotal: 21.9s\tremaining: 37.9s\n",
      "11:\tlearn: 0.5130436\ttotal: 23.9s\tremaining: 35.8s\n",
      "12:\tlearn: 0.5037192\ttotal: 25.9s\tremaining: 33.8s\n",
      "13:\tlearn: 0.4910213\ttotal: 27.9s\tremaining: 31.9s\n",
      "14:\tlearn: 0.4833009\ttotal: 29.9s\tremaining: 29.9s\n",
      "15:\tlearn: 0.4766011\ttotal: 31.9s\tremaining: 27.9s\n",
      "16:\tlearn: 0.4709062\ttotal: 33.9s\tremaining: 25.9s\n",
      "17:\tlearn: 0.4586524\ttotal: 36s\tremaining: 24s\n",
      "18:\tlearn: 0.4512536\ttotal: 38s\tremaining: 22s\n",
      "19:\tlearn: 0.4461429\ttotal: 40s\tremaining: 20s\n",
      "20:\tlearn: 0.4400386\ttotal: 41.9s\tremaining: 18s\n",
      "21:\tlearn: 0.4354189\ttotal: 43.9s\tremaining: 16s\n",
      "22:\tlearn: 0.4282672\ttotal: 45.9s\tremaining: 14s\n",
      "23:\tlearn: 0.4228576\ttotal: 48s\tremaining: 12s\n",
      "24:\tlearn: 0.4185408\ttotal: 50s\tremaining: 9.99s\n",
      "25:\tlearn: 0.4148471\ttotal: 51.9s\tremaining: 7.99s\n",
      "26:\tlearn: 0.4092363\ttotal: 53.9s\tremaining: 5.99s\n",
      "27:\tlearn: 0.4050673\ttotal: 55.9s\tremaining: 3.99s\n",
      "28:\tlearn: 0.4002465\ttotal: 57.8s\tremaining: 1.99s\n",
      "29:\tlearn: 0.3961199\ttotal: 59.8s\tremaining: 0us\n",
      "0:\tlearn: 0.6687297\ttotal: 1.98s\tremaining: 57.4s\n",
      "1:\tlearn: 0.6493504\ttotal: 3.94s\tremaining: 55.2s\n",
      "2:\tlearn: 0.6329611\ttotal: 5.94s\tremaining: 53.4s\n",
      "3:\tlearn: 0.6206759\ttotal: 7.9s\tremaining: 51.4s\n",
      "4:\tlearn: 0.6029811\ttotal: 9.95s\tremaining: 49.8s\n",
      "5:\tlearn: 0.5848698\ttotal: 11.9s\tremaining: 47.8s\n",
      "6:\tlearn: 0.5751517\ttotal: 13.9s\tremaining: 45.7s\n",
      "7:\tlearn: 0.5601592\ttotal: 15.9s\tremaining: 43.8s\n",
      "8:\tlearn: 0.5482087\ttotal: 17.9s\tremaining: 41.8s\n",
      "9:\tlearn: 0.5349713\ttotal: 20.1s\tremaining: 40.2s\n",
      "10:\tlearn: 0.5258713\ttotal: 22.3s\tremaining: 38.6s\n",
      "11:\tlearn: 0.5188137\ttotal: 24.5s\tremaining: 36.7s\n",
      "12:\tlearn: 0.5084913\ttotal: 26.5s\tremaining: 34.7s\n",
      "13:\tlearn: 0.4988648\ttotal: 28.7s\tremaining: 32.8s\n",
      "14:\tlearn: 0.4902022\ttotal: 30.8s\tremaining: 30.8s\n",
      "15:\tlearn: 0.4823769\ttotal: 32.8s\tremaining: 28.7s\n",
      "16:\tlearn: 0.4729855\ttotal: 34.9s\tremaining: 26.7s\n",
      "17:\tlearn: 0.4672512\ttotal: 37s\tremaining: 24.6s\n",
      "18:\tlearn: 0.4582407\ttotal: 39s\tremaining: 22.6s\n",
      "19:\tlearn: 0.4525737\ttotal: 41s\tremaining: 20.5s\n",
      "20:\tlearn: 0.4446582\ttotal: 43.1s\tremaining: 18.5s\n",
      "21:\tlearn: 0.4357021\ttotal: 45.1s\tremaining: 16.4s\n",
      "22:\tlearn: 0.4275451\ttotal: 47.1s\tremaining: 14.3s\n",
      "23:\tlearn: 0.4233356\ttotal: 49.2s\tremaining: 12.3s\n",
      "24:\tlearn: 0.4192533\ttotal: 51.2s\tremaining: 10.2s\n",
      "25:\tlearn: 0.4136501\ttotal: 53.2s\tremaining: 8.19s\n",
      "26:\tlearn: 0.4085450\ttotal: 55.2s\tremaining: 6.14s\n",
      "27:\tlearn: 0.4048534\ttotal: 57.2s\tremaining: 4.09s\n",
      "28:\tlearn: 0.3999028\ttotal: 59.2s\tremaining: 2.04s\n",
      "29:\tlearn: 0.3953716\ttotal: 1m 1s\tremaining: 0us\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 5/7 [09:14<03:16, 98.41s/trial, best loss: -0.7742167129955947]0:\tlearn: 0.6883433\ttotal: 88ms\tremaining: 2.55s\n",
      "1:\tlearn: 0.6839696\ttotal: 165ms\tremaining: 2.31s\n",
      "2:\tlearn: 0.6797276\ttotal: 249ms\tremaining: 2.24s\n",
      "3:\tlearn: 0.6767766\ttotal: 332ms\tremaining: 2.15s\n",
      "4:\tlearn: 0.6736111\ttotal: 418ms\tremaining: 2.09s\n",
      "5:\tlearn: 0.6704438\ttotal: 495ms\tremaining: 1.98s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6:\tlearn: 0.6675876\ttotal: 580ms\tremaining: 1.91s\n",
      "7:\tlearn: 0.6648765\ttotal: 662ms\tremaining: 1.82s\n",
      "8:\tlearn: 0.6625290\ttotal: 742ms\tremaining: 1.73s\n",
      "9:\tlearn: 0.6602451\ttotal: 822ms\tremaining: 1.64s\n",
      "10:\tlearn: 0.6580529\ttotal: 904ms\tremaining: 1.56s\n",
      "11:\tlearn: 0.6556273\ttotal: 986ms\tremaining: 1.48s\n",
      "12:\tlearn: 0.6535073\ttotal: 1.06s\tremaining: 1.39s\n",
      "13:\tlearn: 0.6514674\ttotal: 1.15s\tremaining: 1.31s\n",
      "14:\tlearn: 0.6494844\ttotal: 1.24s\tremaining: 1.24s\n",
      "15:\tlearn: 0.6473891\ttotal: 1.33s\tremaining: 1.16s\n",
      "16:\tlearn: 0.6454990\ttotal: 1.41s\tremaining: 1.08s\n",
      "17:\tlearn: 0.6437897\ttotal: 1.5s\tremaining: 998ms\n",
      "18:\tlearn: 0.6416595\ttotal: 1.58s\tremaining: 918ms\n",
      "19:\tlearn: 0.6400150\ttotal: 1.67s\tremaining: 833ms\n",
      "20:\tlearn: 0.6383654\ttotal: 1.74s\tremaining: 748ms\n",
      "21:\tlearn: 0.6367406\ttotal: 1.82s\tremaining: 663ms\n",
      "22:\tlearn: 0.6352386\ttotal: 1.9s\tremaining: 579ms\n",
      "23:\tlearn: 0.6337067\ttotal: 1.98s\tremaining: 495ms\n",
      "24:\tlearn: 0.6322843\ttotal: 2.06s\tremaining: 411ms\n",
      "25:\tlearn: 0.6308320\ttotal: 2.14s\tremaining: 329ms\n",
      "26:\tlearn: 0.6294132\ttotal: 2.22s\tremaining: 246ms\n",
      "27:\tlearn: 0.6278093\ttotal: 2.29s\tremaining: 164ms\n",
      "28:\tlearn: 0.6264349\ttotal: 2.37s\tremaining: 81.8ms\n",
      "29:\tlearn: 0.6249836\ttotal: 2.45s\tremaining: 0us\n",
      "0:\tlearn: 0.6892810\ttotal: 78ms\tremaining: 2.26s\n",
      "1:\tlearn: 0.6857537\ttotal: 156ms\tremaining: 2.18s\n",
      "2:\tlearn: 0.6824678\ttotal: 234ms\tremaining: 2.1s\n",
      "3:\tlearn: 0.6796626\ttotal: 307ms\tremaining: 2s\n",
      "4:\tlearn: 0.6770150\ttotal: 383ms\tremaining: 1.92s\n",
      "5:\tlearn: 0.6744693\ttotal: 461ms\tremaining: 1.84s\n",
      "6:\tlearn: 0.6724472\ttotal: 539ms\tremaining: 1.77s\n",
      "7:\tlearn: 0.6703942\ttotal: 618ms\tremaining: 1.7s\n",
      "8:\tlearn: 0.6684020\ttotal: 700ms\tremaining: 1.63s\n",
      "9:\tlearn: 0.6662421\ttotal: 785ms\tremaining: 1.57s\n",
      "10:\tlearn: 0.6641222\ttotal: 865ms\tremaining: 1.49s\n",
      "11:\tlearn: 0.6622833\ttotal: 947ms\tremaining: 1.42s\n",
      "12:\tlearn: 0.6604056\ttotal: 1.03s\tremaining: 1.34s\n",
      "13:\tlearn: 0.6584199\ttotal: 1.11s\tremaining: 1.26s\n",
      "14:\tlearn: 0.6566279\ttotal: 1.19s\tremaining: 1.19s\n",
      "15:\tlearn: 0.6550465\ttotal: 1.26s\tremaining: 1.1s\n",
      "16:\tlearn: 0.6534292\ttotal: 1.34s\tremaining: 1.02s\n",
      "17:\tlearn: 0.6519605\ttotal: 1.42s\tremaining: 945ms\n",
      "18:\tlearn: 0.6503662\ttotal: 1.49s\tremaining: 865ms\n",
      "19:\tlearn: 0.6488748\ttotal: 1.57s\tremaining: 786ms\n",
      "20:\tlearn: 0.6472494\ttotal: 1.65s\tremaining: 708ms\n",
      "21:\tlearn: 0.6459432\ttotal: 1.73s\tremaining: 630ms\n",
      "22:\tlearn: 0.6445320\ttotal: 1.81s\tremaining: 551ms\n",
      "23:\tlearn: 0.6433237\ttotal: 1.89s\tremaining: 472ms\n",
      "24:\tlearn: 0.6421738\ttotal: 1.96s\tremaining: 393ms\n",
      "25:\tlearn: 0.6407287\ttotal: 2.05s\tremaining: 315ms\n",
      "26:\tlearn: 0.6395239\ttotal: 2.13s\tremaining: 236ms\n",
      "27:\tlearn: 0.6380394\ttotal: 2.21s\tremaining: 158ms\n",
      "28:\tlearn: 0.6367495\ttotal: 2.29s\tremaining: 79ms\n",
      "29:\tlearn: 0.6355097\ttotal: 2.37s\tremaining: 0us\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 6/7 [09:20<01:07, 67.19s/trial, best loss: -0.7742167129955947]0:\tlearn: 0.6888499\ttotal: 11.9ms\tremaining: 582ms\n",
      "1:\tlearn: 0.6856494\ttotal: 23.3ms\tremaining: 560ms\n",
      "2:\tlearn: 0.6826102\ttotal: 35.2ms\tremaining: 552ms\n",
      "3:\tlearn: 0.6796042\ttotal: 47.1ms\tremaining: 542ms\n",
      "4:\tlearn: 0.6770800\ttotal: 58.9ms\tremaining: 530ms\n",
      "5:\tlearn: 0.6744574\ttotal: 71.9ms\tremaining: 527ms\n",
      "6:\tlearn: 0.6721498\ttotal: 84.2ms\tremaining: 517ms\n",
      "7:\tlearn: 0.6700462\ttotal: 96.7ms\tremaining: 508ms\n",
      "8:\tlearn: 0.6681206\ttotal: 109ms\tremaining: 497ms\n",
      "9:\tlearn: 0.6660767\ttotal: 122ms\tremaining: 488ms\n",
      "10:\tlearn: 0.6641426\ttotal: 136ms\tremaining: 481ms\n",
      "11:\tlearn: 0.6625073\ttotal: 148ms\tremaining: 467ms\n",
      "12:\tlearn: 0.6608172\ttotal: 160ms\tremaining: 455ms\n",
      "13:\tlearn: 0.6592085\ttotal: 172ms\tremaining: 443ms\n",
      "14:\tlearn: 0.6575583\ttotal: 185ms\tremaining: 431ms\n",
      "15:\tlearn: 0.6560162\ttotal: 197ms\tremaining: 418ms\n",
      "16:\tlearn: 0.6545016\ttotal: 210ms\tremaining: 407ms\n",
      "17:\tlearn: 0.6531008\ttotal: 221ms\tremaining: 394ms\n",
      "18:\tlearn: 0.6516448\ttotal: 236ms\tremaining: 385ms\n",
      "19:\tlearn: 0.6503135\ttotal: 249ms\tremaining: 374ms\n",
      "20:\tlearn: 0.6490152\ttotal: 263ms\tremaining: 363ms\n",
      "21:\tlearn: 0.6477756\ttotal: 276ms\tremaining: 352ms\n",
      "22:\tlearn: 0.6466177\ttotal: 289ms\tremaining: 340ms\n",
      "23:\tlearn: 0.6454604\ttotal: 302ms\tremaining: 328ms\n",
      "24:\tlearn: 0.6441954\ttotal: 315ms\tremaining: 315ms\n",
      "25:\tlearn: 0.6430623\ttotal: 328ms\tremaining: 303ms\n",
      "26:\tlearn: 0.6419613\ttotal: 342ms\tremaining: 291ms\n",
      "27:\tlearn: 0.6408631\ttotal: 354ms\tremaining: 278ms\n",
      "28:\tlearn: 0.6396676\ttotal: 368ms\tremaining: 266ms\n",
      "29:\tlearn: 0.6386437\ttotal: 382ms\tremaining: 254ms\n",
      "30:\tlearn: 0.6376758\ttotal: 395ms\tremaining: 242ms\n",
      "31:\tlearn: 0.6367449\ttotal: 407ms\tremaining: 229ms\n",
      "32:\tlearn: 0.6358445\ttotal: 420ms\tremaining: 216ms\n",
      "33:\tlearn: 0.6349743\ttotal: 434ms\tremaining: 204ms\n",
      "34:\tlearn: 0.6340367\ttotal: 447ms\tremaining: 192ms\n",
      "35:\tlearn: 0.6331727\ttotal: 462ms\tremaining: 180ms\n",
      "36:\tlearn: 0.6322976\ttotal: 475ms\tremaining: 167ms\n",
      "37:\tlearn: 0.6314502\ttotal: 487ms\tremaining: 154ms\n",
      "38:\tlearn: 0.6305716\ttotal: 500ms\tremaining: 141ms\n",
      "39:\tlearn: 0.6297765\ttotal: 512ms\tremaining: 128ms\n",
      "40:\tlearn: 0.6290001\ttotal: 525ms\tremaining: 115ms\n",
      "41:\tlearn: 0.6282369\ttotal: 537ms\tremaining: 102ms\n",
      "42:\tlearn: 0.6275456\ttotal: 551ms\tremaining: 89.7ms\n",
      "43:\tlearn: 0.6268681\ttotal: 564ms\tremaining: 77ms\n",
      "44:\tlearn: 0.6261388\ttotal: 577ms\tremaining: 64.1ms\n",
      "45:\tlearn: 0.6254560\ttotal: 590ms\tremaining: 51.3ms\n",
      "46:\tlearn: 0.6248332\ttotal: 604ms\tremaining: 38.5ms\n",
      "47:\tlearn: 0.6241307\ttotal: 616ms\tremaining: 25.7ms\n",
      "48:\tlearn: 0.6234689\ttotal: 628ms\tremaining: 12.8ms\n",
      "49:\tlearn: 0.6226988\ttotal: 641ms\tremaining: 0us\n",
      "0:\tlearn: 0.6899126\ttotal: 11.7ms\tremaining: 575ms\n",
      "1:\tlearn: 0.6872600\ttotal: 23.9ms\tremaining: 573ms\n",
      "2:\tlearn: 0.6848045\ttotal: 36.2ms\tremaining: 567ms\n",
      "3:\tlearn: 0.6822391\ttotal: 49.2ms\tremaining: 566ms\n",
      "4:\tlearn: 0.6802721\ttotal: 62.1ms\tremaining: 559ms\n",
      "5:\tlearn: 0.6783019\ttotal: 74ms\tremaining: 543ms\n",
      "6:\tlearn: 0.6766322\ttotal: 86.8ms\tremaining: 533ms\n",
      "7:\tlearn: 0.6748436\ttotal: 99.1ms\tremaining: 520ms\n",
      "8:\tlearn: 0.6733852\ttotal: 111ms\tremaining: 508ms\n",
      "9:\tlearn: 0.6718546\ttotal: 124ms\tremaining: 494ms\n",
      "10:\tlearn: 0.6705573\ttotal: 136ms\tremaining: 481ms\n",
      "11:\tlearn: 0.6691423\ttotal: 148ms\tremaining: 470ms\n",
      "12:\tlearn: 0.6680526\ttotal: 161ms\tremaining: 457ms\n",
      "13:\tlearn: 0.6668714\ttotal: 174ms\tremaining: 447ms\n",
      "14:\tlearn: 0.6655373\ttotal: 186ms\tremaining: 434ms\n",
      "15:\tlearn: 0.6643624\ttotal: 199ms\tremaining: 423ms\n",
      "16:\tlearn: 0.6631203\ttotal: 213ms\tremaining: 413ms\n",
      "17:\tlearn: 0.6619063\ttotal: 226ms\tremaining: 402ms\n",
      "18:\tlearn: 0.6607504\ttotal: 238ms\tremaining: 389ms\n",
      "19:\tlearn: 0.6596083\ttotal: 251ms\tremaining: 377ms\n",
      "20:\tlearn: 0.6584258\ttotal: 265ms\tremaining: 366ms\n",
      "21:\tlearn: 0.6574601\ttotal: 277ms\tremaining: 353ms\n",
      "22:\tlearn: 0.6564934\ttotal: 289ms\tremaining: 340ms\n",
      "23:\tlearn: 0.6555919\ttotal: 302ms\tremaining: 327ms\n",
      "24:\tlearn: 0.6545431\ttotal: 314ms\tremaining: 314ms\n",
      "25:\tlearn: 0.6536089\ttotal: 327ms\tremaining: 302ms\n",
      "26:\tlearn: 0.6526791\ttotal: 339ms\tremaining: 289ms\n",
      "27:\tlearn: 0.6517382\ttotal: 352ms\tremaining: 276ms\n",
      "28:\tlearn: 0.6508009\ttotal: 365ms\tremaining: 264ms\n",
      "29:\tlearn: 0.6500531\ttotal: 377ms\tremaining: 251ms\n",
      "30:\tlearn: 0.6491120\ttotal: 390ms\tremaining: 239ms\n",
      "31:\tlearn: 0.6484670\ttotal: 403ms\tremaining: 227ms\n",
      "32:\tlearn: 0.6477895\ttotal: 415ms\tremaining: 214ms\n",
      "33:\tlearn: 0.6470566\ttotal: 429ms\tremaining: 202ms\n",
      "34:\tlearn: 0.6463556\ttotal: 442ms\tremaining: 189ms\n",
      "35:\tlearn: 0.6455758\ttotal: 456ms\tremaining: 177ms\n",
      "36:\tlearn: 0.6447520\ttotal: 469ms\tremaining: 165ms\n",
      "37:\tlearn: 0.6440875\ttotal: 481ms\tremaining: 152ms\n",
      "38:\tlearn: 0.6432819\ttotal: 495ms\tremaining: 140ms\n",
      "39:\tlearn: 0.6425427\ttotal: 508ms\tremaining: 127ms\n",
      "40:\tlearn: 0.6418904\ttotal: 521ms\tremaining: 114ms\n",
      "41:\tlearn: 0.6413510\ttotal: 534ms\tremaining: 102ms\n",
      "42:\tlearn: 0.6406571\ttotal: 547ms\tremaining: 89.1ms\n",
      "43:\tlearn: 0.6400700\ttotal: 560ms\tremaining: 76.4ms\n",
      "44:\tlearn: 0.6394273\ttotal: 573ms\tremaining: 63.7ms\n",
      "45:\tlearn: 0.6388312\ttotal: 586ms\tremaining: 51ms\n",
      "46:\tlearn: 0.6383627\ttotal: 599ms\tremaining: 38.3ms\n",
      "47:\tlearn: 0.6378620\ttotal: 612ms\tremaining: 25.5ms\n",
      "48:\tlearn: 0.6373412\ttotal: 625ms\tremaining: 12.7ms\n",
      "49:\tlearn: 0.6367362\ttotal: 639ms\tremaining: 0us\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [09:23<00:00, 80.54s/trial, best loss: -0.7742167129955947]\n",
      "Best parameters: {'depth': [3], 'iterations': [4], 'learning_rate': [0.22480335459272638]}\n",
      "Best score: 0.7742167129955947\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def tune_CatB(params):\n",
    "    CatB_clf = CatBoostClassifier(**params)\n",
    "    acc = cross_val_score(CatB_clf, X_train_prep, y_train_pre_transf, scoring=\"accuracy\", cv=2).mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"iterations\": hp.choice(\"iterations\",[30, 50, 70, 90, 100]),\n",
    "    \"depth\": hp.choice(\"depth\",[3, 5, 10, 15, None]),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.05), np.log(0.5)),\n",
    "}\n",
    "\n",
    "\n",
    "trials=Trials() # Trails() must be reassign each time to reset its value\n",
    "best_search_CatB = fmin(fn=tune_CatB, space = space, algo=tpe.suggest, max_evals=n_iteration, trials=trials)\n",
    "\n",
    "best_trial_CatB = trials.best_trial\n",
    "best_params_CatB = best_trial_CatB[\"misc\"][\"vals\"]\n",
    "best_score_CatB = -best_trial_CatB[\"result\"][\"loss\"]\n",
    "\n",
    "print(\"Best parameters:\", best_params_CatB)\n",
    "print(\"Best score:\", best_score_CatB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6795148\ttotal: 2.02s\tremaining: 3m 20s\n",
      "1:\tlearn: 0.6675078\ttotal: 4.03s\tremaining: 3m 17s\n",
      "2:\tlearn: 0.6568379\ttotal: 6.04s\tremaining: 3m 15s\n",
      "3:\tlearn: 0.6456394\ttotal: 8.08s\tremaining: 3m 13s\n",
      "4:\tlearn: 0.6366760\ttotal: 10.1s\tremaining: 3m 11s\n",
      "5:\tlearn: 0.6289348\ttotal: 12.1s\tremaining: 3m 10s\n",
      "6:\tlearn: 0.6217033\ttotal: 14.2s\tremaining: 3m 8s\n",
      "7:\tlearn: 0.6146646\ttotal: 16.2s\tremaining: 3m 5s\n",
      "8:\tlearn: 0.6077409\ttotal: 18.2s\tremaining: 3m 3s\n",
      "9:\tlearn: 0.6012146\ttotal: 20.2s\tremaining: 3m 1s\n",
      "10:\tlearn: 0.5957892\ttotal: 22.2s\tremaining: 2m 59s\n",
      "11:\tlearn: 0.5900317\ttotal: 24.2s\tremaining: 2m 57s\n",
      "12:\tlearn: 0.5857767\ttotal: 26.2s\tremaining: 2m 55s\n",
      "13:\tlearn: 0.5809494\ttotal: 28.3s\tremaining: 2m 53s\n",
      "14:\tlearn: 0.5755005\ttotal: 30.3s\tremaining: 2m 51s\n",
      "15:\tlearn: 0.5692275\ttotal: 32.4s\tremaining: 2m 49s\n",
      "16:\tlearn: 0.5635649\ttotal: 34.4s\tremaining: 2m 47s\n",
      "17:\tlearn: 0.5573236\ttotal: 36.4s\tremaining: 2m 45s\n",
      "18:\tlearn: 0.5523336\ttotal: 38.4s\tremaining: 2m 43s\n",
      "19:\tlearn: 0.5473029\ttotal: 40.4s\tremaining: 2m 41s\n",
      "20:\tlearn: 0.5425194\ttotal: 42.4s\tremaining: 2m 39s\n",
      "21:\tlearn: 0.5359037\ttotal: 44.5s\tremaining: 2m 37s\n",
      "22:\tlearn: 0.5317519\ttotal: 46.5s\tremaining: 2m 35s\n",
      "23:\tlearn: 0.5272648\ttotal: 48.5s\tremaining: 2m 33s\n",
      "24:\tlearn: 0.5233074\ttotal: 50.5s\tremaining: 2m 31s\n",
      "25:\tlearn: 0.5201212\ttotal: 52.5s\tremaining: 2m 29s\n",
      "26:\tlearn: 0.5167180\ttotal: 54.5s\tremaining: 2m 27s\n",
      "27:\tlearn: 0.5120722\ttotal: 56.5s\tremaining: 2m 25s\n",
      "28:\tlearn: 0.5085416\ttotal: 58.5s\tremaining: 2m 23s\n",
      "29:\tlearn: 0.5028633\ttotal: 1m\tremaining: 2m 21s\n",
      "30:\tlearn: 0.4985672\ttotal: 1m 2s\tremaining: 2m 19s\n",
      "31:\tlearn: 0.4928027\ttotal: 1m 4s\tremaining: 2m 17s\n",
      "32:\tlearn: 0.4893846\ttotal: 1m 6s\tremaining: 2m 15s\n",
      "33:\tlearn: 0.4859822\ttotal: 1m 8s\tremaining: 2m 13s\n",
      "34:\tlearn: 0.4831717\ttotal: 1m 10s\tremaining: 2m 11s\n",
      "35:\tlearn: 0.4803805\ttotal: 1m 12s\tremaining: 2m 9s\n",
      "36:\tlearn: 0.4764952\ttotal: 1m 14s\tremaining: 2m 7s\n",
      "37:\tlearn: 0.4725607\ttotal: 1m 16s\tremaining: 2m 5s\n",
      "38:\tlearn: 0.4694781\ttotal: 1m 18s\tremaining: 2m 3s\n",
      "39:\tlearn: 0.4665063\ttotal: 1m 20s\tremaining: 2m 1s\n",
      "40:\tlearn: 0.4628710\ttotal: 1m 22s\tremaining: 1m 59s\n",
      "41:\tlearn: 0.4599908\ttotal: 1m 24s\tremaining: 1m 57s\n",
      "42:\tlearn: 0.4581171\ttotal: 1m 26s\tremaining: 1m 55s\n",
      "43:\tlearn: 0.4561109\ttotal: 1m 28s\tremaining: 1m 53s\n",
      "44:\tlearn: 0.4536946\ttotal: 1m 30s\tremaining: 1m 51s\n",
      "45:\tlearn: 0.4500872\ttotal: 1m 32s\tremaining: 1m 49s\n",
      "46:\tlearn: 0.4478866\ttotal: 1m 34s\tremaining: 1m 47s\n",
      "47:\tlearn: 0.4453274\ttotal: 1m 37s\tremaining: 1m 45s\n",
      "48:\tlearn: 0.4430771\ttotal: 1m 39s\tremaining: 1m 43s\n",
      "49:\tlearn: 0.4397734\ttotal: 1m 41s\tremaining: 1m 41s\n",
      "50:\tlearn: 0.4368271\ttotal: 1m 43s\tremaining: 1m 39s\n",
      "51:\tlearn: 0.4351343\ttotal: 1m 45s\tremaining: 1m 37s\n",
      "52:\tlearn: 0.4336118\ttotal: 1m 47s\tremaining: 1m 34s\n",
      "53:\tlearn: 0.4296002\ttotal: 1m 49s\tremaining: 1m 32s\n",
      "54:\tlearn: 0.4251030\ttotal: 1m 51s\tremaining: 1m 31s\n",
      "55:\tlearn: 0.4222556\ttotal: 1m 53s\tremaining: 1m 28s\n",
      "56:\tlearn: 0.4197279\ttotal: 1m 55s\tremaining: 1m 26s\n",
      "57:\tlearn: 0.4183014\ttotal: 1m 57s\tremaining: 1m 24s\n",
      "58:\tlearn: 0.4149906\ttotal: 1m 59s\tremaining: 1m 22s\n",
      "59:\tlearn: 0.4103848\ttotal: 2m 1s\tremaining: 1m 20s\n",
      "60:\tlearn: 0.4061026\ttotal: 2m 3s\tremaining: 1m 18s\n",
      "61:\tlearn: 0.4032886\ttotal: 2m 5s\tremaining: 1m 16s\n",
      "62:\tlearn: 0.4018458\ttotal: 2m 7s\tremaining: 1m 14s\n",
      "63:\tlearn: 0.3998899\ttotal: 2m 9s\tremaining: 1m 12s\n",
      "64:\tlearn: 0.3970474\ttotal: 2m 11s\tremaining: 1m 10s\n",
      "65:\tlearn: 0.3935369\ttotal: 2m 13s\tremaining: 1m 8s\n",
      "66:\tlearn: 0.3913350\ttotal: 2m 15s\tremaining: 1m 6s\n",
      "67:\tlearn: 0.3898992\ttotal: 2m 17s\tremaining: 1m 4s\n",
      "68:\tlearn: 0.3883117\ttotal: 2m 19s\tremaining: 1m 2s\n",
      "69:\tlearn: 0.3867125\ttotal: 2m 21s\tremaining: 1m\n",
      "70:\tlearn: 0.3830496\ttotal: 2m 23s\tremaining: 58.8s\n",
      "71:\tlearn: 0.3805949\ttotal: 2m 25s\tremaining: 56.8s\n",
      "72:\tlearn: 0.3764847\ttotal: 2m 28s\tremaining: 54.8s\n",
      "73:\tlearn: 0.3738083\ttotal: 2m 30s\tremaining: 52.8s\n",
      "74:\tlearn: 0.3715121\ttotal: 2m 32s\tremaining: 50.7s\n",
      "75:\tlearn: 0.3680680\ttotal: 2m 34s\tremaining: 48.7s\n",
      "76:\tlearn: 0.3659839\ttotal: 2m 36s\tremaining: 46.7s\n",
      "77:\tlearn: 0.3637802\ttotal: 2m 38s\tremaining: 44.6s\n",
      "78:\tlearn: 0.3622658\ttotal: 2m 40s\tremaining: 42.6s\n",
      "79:\tlearn: 0.3600433\ttotal: 2m 42s\tremaining: 40.6s\n",
      "80:\tlearn: 0.3585192\ttotal: 2m 44s\tremaining: 38.5s\n",
      "81:\tlearn: 0.3564668\ttotal: 2m 46s\tremaining: 36.5s\n",
      "82:\tlearn: 0.3542951\ttotal: 2m 48s\tremaining: 34.5s\n",
      "83:\tlearn: 0.3532311\ttotal: 2m 50s\tremaining: 32.5s\n",
      "84:\tlearn: 0.3512090\ttotal: 2m 52s\tremaining: 30.4s\n",
      "85:\tlearn: 0.3497187\ttotal: 2m 54s\tremaining: 28.4s\n",
      "86:\tlearn: 0.3482738\ttotal: 2m 56s\tremaining: 26.4s\n",
      "87:\tlearn: 0.3465443\ttotal: 2m 58s\tremaining: 24.3s\n",
      "88:\tlearn: 0.3433329\ttotal: 3m\tremaining: 22.3s\n",
      "89:\tlearn: 0.3415748\ttotal: 3m 2s\tremaining: 20.3s\n",
      "90:\tlearn: 0.3399386\ttotal: 3m 4s\tremaining: 18.3s\n",
      "91:\tlearn: 0.3375963\ttotal: 3m 6s\tremaining: 16.2s\n",
      "92:\tlearn: 0.3358973\ttotal: 3m 8s\tremaining: 14.2s\n",
      "93:\tlearn: 0.3335565\ttotal: 3m 10s\tremaining: 12.2s\n",
      "94:\tlearn: 0.3325333\ttotal: 3m 12s\tremaining: 10.1s\n",
      "95:\tlearn: 0.3295770\ttotal: 3m 14s\tremaining: 8.12s\n",
      "96:\tlearn: 0.3276346\ttotal: 3m 16s\tremaining: 6.09s\n",
      "97:\tlearn: 0.3246316\ttotal: 3m 19s\tremaining: 4.06s\n",
      "98:\tlearn: 0.3231944\ttotal: 3m 21s\tremaining: 2.03s\n",
      "99:\tlearn: 0.3208947\ttotal: 3m 23s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x23e64fdffa0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit the classifier with the best hyperparameter set\n",
    "temp_params_dict = space_eval(space, best_search_CatB)\n",
    "final_params_CatB = {\n",
    "    'iterations': temp_params_dict['iterations'],\n",
    "    'depth': temp_params_dict['depth'],\n",
    "    'learning_rate': temp_params_dict['learning_rate'],\n",
    "}\n",
    "\n",
    "CatB_clf = CatBoostClassifier(**final_params_CatB)\n",
    "CatB_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 AdaBoost with the plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 Voting of all base classifier as well as RandomForest and CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimator = [('SVM', svm_clf), ('LR', LR_clf), ('DT', Tree_clf), ('KNN', KNN_clf), \n",
    "                 ('MLP', mlp_clf), ('Rand_Forest', rnd_clf), ('CatB', CatB_clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;SVM&#x27;,\n",
       "                              SVC(C=9.704052240884993,\n",
       "                                  gamma=0.011785053924241283, kernel=&#x27;poly&#x27;)),\n",
       "                             (&#x27;LR&#x27;,\n",
       "                              LogisticRegression(C=1.9731587368372532,\n",
       "                                                 n_jobs=-1, solver=&#x27;saga&#x27;)),\n",
       "                             (&#x27;DT&#x27;,\n",
       "                              DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;,\n",
       "                                                     max_features=&#x27;log2&#x27;)),\n",
       "                             (&#x27;KNN&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;euclidean&#x27;,\n",
       "                                                   n_jobs=-1, n_neighbors=3,\n",
       "                                                   weights=&#x27;distance&#x27;)),\n",
       "                             (&#x27;MLP&#x27;,\n",
       "                              MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                                            alpha=0.0007780975361284449,\n",
       "                                            hidden_layer_sizes=(20,),\n",
       "                                            max_iter=1500, solver=&#x27;lbfgs&#x27;)),\n",
       "                             (&#x27;Rand_Forest&#x27;,\n",
       "                              RandomForestClassifier(criterion=&#x27;log_loss&#x27;,\n",
       "                                                     max_features=&#x27;log2&#x27;,\n",
       "                                                     n_jobs=-1)),\n",
       "                             (&#x27;CatB&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x0000023E64FDFFA0&gt;)],\n",
       "                 n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;SVM&#x27;,\n",
       "                              SVC(C=9.704052240884993,\n",
       "                                  gamma=0.011785053924241283, kernel=&#x27;poly&#x27;)),\n",
       "                             (&#x27;LR&#x27;,\n",
       "                              LogisticRegression(C=1.9731587368372532,\n",
       "                                                 n_jobs=-1, solver=&#x27;saga&#x27;)),\n",
       "                             (&#x27;DT&#x27;,\n",
       "                              DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;,\n",
       "                                                     max_features=&#x27;log2&#x27;)),\n",
       "                             (&#x27;KNN&#x27;,\n",
       "                              KNeighborsClassifier(metric=&#x27;euclidean&#x27;,\n",
       "                                                   n_jobs=-1, n_neighbors=3,\n",
       "                                                   weights=&#x27;distance&#x27;)),\n",
       "                             (&#x27;MLP&#x27;,\n",
       "                              MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                                            alpha=0.0007780975361284449,\n",
       "                                            hidden_layer_sizes=(20,),\n",
       "                                            max_iter=1500, solver=&#x27;lbfgs&#x27;)),\n",
       "                             (&#x27;Rand_Forest&#x27;,\n",
       "                              RandomForestClassifier(criterion=&#x27;log_loss&#x27;,\n",
       "                                                     max_features=&#x27;log2&#x27;,\n",
       "                                                     n_jobs=-1)),\n",
       "                             (&#x27;CatB&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x0000023E64FDFFA0&gt;)],\n",
       "                 n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVM</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=9.704052240884993, gamma=0.011785053924241283, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LR</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.9731587368372532, n_jobs=-1, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DT</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;log_loss&#x27;, max_features=&#x27;log2&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>KNN</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1, n_neighbors=3,\n",
       "                     weights=&#x27;distance&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>MLP</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.0007780975361284449,\n",
       "              hidden_layer_sizes=(20,), max_iter=1500, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Rand_Forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;log_loss&#x27;, max_features=&#x27;log2&#x27;, n_jobs=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>CatB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000023E64FDFFA0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('SVM',\n",
       "                              SVC(C=9.704052240884993,\n",
       "                                  gamma=0.011785053924241283, kernel='poly')),\n",
       "                             ('LR',\n",
       "                              LogisticRegression(C=1.9731587368372532,\n",
       "                                                 n_jobs=-1, solver='saga')),\n",
       "                             ('DT',\n",
       "                              DecisionTreeClassifier(criterion='log_loss',\n",
       "                                                     max_features='log2')),\n",
       "                             ('KNN',\n",
       "                              KNeighborsClassifier(metric='euclidean',\n",
       "                                                   n_jobs=-1, n_neighbors=3,\n",
       "                                                   weights='distance')),\n",
       "                             ('MLP',\n",
       "                              MLPClassifier(activation='tanh',\n",
       "                                            alpha=0.0007780975361284449,\n",
       "                                            hidden_layer_sizes=(20,),\n",
       "                                            max_iter=1500, solver='lbfgs')),\n",
       "                             ('Rand_Forest',\n",
       "                              RandomForestClassifier(criterion='log_loss',\n",
       "                                                     max_features='log2',\n",
       "                                                     n_jobs=-1)),\n",
       "                             ('CatB',\n",
       "                              <catboost.core.CatBoostClassifier object at 0x0000023E64FDFFA0>)],\n",
       "                 n_jobs=-1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=all_estimator, voting='hard', n_jobs=-1)\n",
    "\n",
    "voting_clf.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6 Stacking classifier, using best_model again as the final estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Classifier 2-B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Global_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[(df['defect_4_Type'] == 'A') & (df['defect_5_Type'] == 'A')].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"other_defect_cat\"] = df.apply(lambda x: 0 if \n",
    "                                  x['defect_1_Type'] == 'A' and \n",
    "                                  x['defect_2_Type'] == 'A' and\n",
    "                                  x['defect_3_Type'] == 'A'\n",
    "                                  else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reference', 'Lane', 'TailleZone', 'Courbure', 'CourbureVert', 'Vitesse', 'SensMarche', 'Lat_acc_tete_Max', 'Lat_acc_tete_Max_Pos', 'Lat_acc_tete_Max_Pos_Moy', 'Lat_acc_tete_Avg', 'Lat_acc_tete_P2Avg', 'Lat_acc_milieu_Max', 'Lat_acc_milieu_Max_Pos', 'Lat_acc_milieu_Max_Pos_Moy', 'Lat_acc_milieu_Avg', 'Lat_acc_milieu_P2Avg', 'Lat_acc_queue_Max', 'Lat_acc_queue_Max_Pos', 'Lat_acc_queue_Max_Pos_Moy', 'Lat_acc_queue_Avg', 'Lat_acc_queue_P2Avg', 'Vert_acc_tete_Max', 'Vert_acc_tete_Max_Pos', 'Vert_acc_tete_Max_Pos_Moy', 'Vert_acc_tete_Avg', 'Vert_acc_tete_P2Avg', 'Vert_acc_milieu_Max', 'Vert_acc_milieu_Max_Pos', 'Vert_acc_milieu_Max_Pos_Moy', 'Vert_acc_milieu_Avg', 'Vert_acc_milieu_P2Avg', 'Vert_acc_queue_Max', 'Vert_acc_queue_Max_Pos', 'Vert_acc_queue_Max_Pos_Moy', 'Vert_acc_queue_Avg', 'Vert_acc_queue_P2Avg', 'other_defect_cat']\n"
     ]
    }
   ],
   "source": [
    "# Drop all '_type' columns and AB_tete and AC_tete\n",
    "df.drop(['defect_1_Type', 'defect_2_Type', 'defect_3_Type', 'defect_4_Type', 'defect_5_Type']\n",
    "        , axis=1, inplace=True)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if there is any column that is not numeric \n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "#df_cat.head()\n",
    "\n",
    "# Add categorical columns that are number manually can convert them to categorical type\n",
    "other_cat_col = ['Reference']\n",
    "df[other_cat_col] = df[other_cat_col].astype(\"category\")\n",
    "#df[other_cat_col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_encoded = ordinal_encoder.fit_transform(df_cat)\n",
    "#print(df_cat_encoded)\n",
    "\n",
    "df[df_cat.columns.tolist()] = df_cat_encoded\n",
    "df[df_cat.columns.tolist()] = df[df_cat.columns.tolist()].astype(\"category\")\n",
    "#df[df_cat.columns.tolist()].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Lane</th>\n",
       "      <th>TailleZone</th>\n",
       "      <th>Courbure</th>\n",
       "      <th>CourbureVert</th>\n",
       "      <th>Vitesse</th>\n",
       "      <th>SensMarche</th>\n",
       "      <th>Lat_acc_tete_Max</th>\n",
       "      <th>Lat_acc_tete_Max_Pos</th>\n",
       "      <th>Lat_acc_tete_Max_Pos_Moy</th>\n",
       "      <th>...</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_milieu_Avg</th>\n",
       "      <th>Vert_acc_milieu_P2Avg</th>\n",
       "      <th>Vert_acc_queue_Max</th>\n",
       "      <th>Vert_acc_queue_Max_Pos</th>\n",
       "      <th>Vert_acc_queue_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_queue_Avg</th>\n",
       "      <th>Vert_acc_queue_P2Avg</th>\n",
       "      <th>other_defect_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.208951</td>\n",
       "      <td>0.606896</td>\n",
       "      <td>37.029094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724853</td>\n",
       "      <td>40.485842</td>\n",
       "      <td>22.184719</td>\n",
       "      <td>...</td>\n",
       "      <td>37.544277</td>\n",
       "      <td>49.289932</td>\n",
       "      <td>0.754303</td>\n",
       "      <td>0.301337</td>\n",
       "      <td>0.890809</td>\n",
       "      <td>86.361178</td>\n",
       "      <td>91.888751</td>\n",
       "      <td>0.677081</td>\n",
       "      <td>0.686660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.567851</td>\n",
       "      <td>0.798085</td>\n",
       "      <td>57.191099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>64.006048</td>\n",
       "      <td>27.548878</td>\n",
       "      <td>...</td>\n",
       "      <td>22.134893</td>\n",
       "      <td>97.297302</td>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.757654</td>\n",
       "      <td>0.822322</td>\n",
       "      <td>11.185659</td>\n",
       "      <td>72.559423</td>\n",
       "      <td>0.581428</td>\n",
       "      <td>0.835744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>0.071343</td>\n",
       "      <td>0.687940</td>\n",
       "      <td>74.292031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.561670</td>\n",
       "      <td>64.371349</td>\n",
       "      <td>80.608878</td>\n",
       "      <td>...</td>\n",
       "      <td>27.378394</td>\n",
       "      <td>71.036832</td>\n",
       "      <td>0.602301</td>\n",
       "      <td>0.364936</td>\n",
       "      <td>0.715889</td>\n",
       "      <td>29.833565</td>\n",
       "      <td>17.281313</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>0.636451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.218358</td>\n",
       "      <td>0.608949</td>\n",
       "      <td>59.237997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728388</td>\n",
       "      <td>14.884909</td>\n",
       "      <td>80.736501</td>\n",
       "      <td>...</td>\n",
       "      <td>95.706315</td>\n",
       "      <td>7.458945</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>0.876993</td>\n",
       "      <td>0.994526</td>\n",
       "      <td>50.824356</td>\n",
       "      <td>81.578388</td>\n",
       "      <td>0.712349</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.062902</td>\n",
       "      <td>0.882730</td>\n",
       "      <td>54.048309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193552</td>\n",
       "      <td>24.668405</td>\n",
       "      <td>49.470311</td>\n",
       "      <td>...</td>\n",
       "      <td>68.919184</td>\n",
       "      <td>64.241055</td>\n",
       "      <td>0.619083</td>\n",
       "      <td>0.221865</td>\n",
       "      <td>0.379381</td>\n",
       "      <td>87.778234</td>\n",
       "      <td>7.489518</td>\n",
       "      <td>0.545681</td>\n",
       "      <td>0.427628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reference Lane  TailleZone  Courbure  CourbureVert    Vitesse SensMarche  \\\n",
       "0         0  0.0          72  0.208951      0.606896  37.029094        1.0   \n",
       "1         2  0.0          55  0.567851      0.798085  57.191099        0.0   \n",
       "2         4  0.0          92  0.071343      0.687940  74.292031        1.0   \n",
       "3         0  0.0           5  0.218358      0.608949  59.237997        0.0   \n",
       "4         2  1.0          71  0.062902      0.882730  54.048309        1.0   \n",
       "\n",
       "   Lat_acc_tete_Max  Lat_acc_tete_Max_Pos  Lat_acc_tete_Max_Pos_Moy  ...  \\\n",
       "0          0.724853             40.485842                 22.184719  ...   \n",
       "1          0.115556             64.006048                 27.548878  ...   \n",
       "2          0.561670             64.371349                 80.608878  ...   \n",
       "3          0.728388             14.884909                 80.736501  ...   \n",
       "4          0.193552             24.668405                 49.470311  ...   \n",
       "\n",
       "   Vert_acc_milieu_Max_Pos  Vert_acc_milieu_Max_Pos_Moy  Vert_acc_milieu_Avg  \\\n",
       "0                37.544277                    49.289932             0.754303   \n",
       "1                22.134893                    97.297302             0.057798   \n",
       "2                27.378394                    71.036832             0.602301   \n",
       "3                95.706315                     7.458945             0.695200   \n",
       "4                68.919184                    64.241055             0.619083   \n",
       "\n",
       "   Vert_acc_milieu_P2Avg  Vert_acc_queue_Max  Vert_acc_queue_Max_Pos  \\\n",
       "0               0.301337            0.890809               86.361178   \n",
       "1               0.757654            0.822322               11.185659   \n",
       "2               0.364936            0.715889               29.833565   \n",
       "3               0.876993            0.994526               50.824356   \n",
       "4               0.221865            0.379381               87.778234   \n",
       "\n",
       "   Vert_acc_queue_Max_Pos_Moy  Vert_acc_queue_Avg  Vert_acc_queue_P2Avg  \\\n",
       "0                   91.888751            0.677081              0.686660   \n",
       "1                   72.559423            0.581428              0.835744   \n",
       "2                   17.281313            0.017870              0.636451   \n",
       "3                   81.578388            0.712349              0.053036   \n",
       "4                    7.489518            0.545681              0.427628   \n",
       "\n",
       "   other_defect_cat  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73818\n",
       "0     1115\n",
       "Name: other_defect_cat, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = df[\"other_defect_cat\"]\n",
    "X_train = df.drop(\"other_defect_cat\", axis=1)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling Counter({1: 73818, 0: 1115})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print('Before oversampling', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Counter({1: 73818, 0: 73561})\n"
     ]
    }
   ],
   "source": [
    "oversampling = True\n",
    "\n",
    "if oversampling:\n",
    "    from imblearn.over_sampling import ADASYN\n",
    "    ada = ADASYN(sampling_strategy=1, random_state = 42)# sampling_strategy = float only works for Binary \n",
    "    \n",
    "    X_train_pre_transf, y_train_pre_transf = ada.fit_resample(X_train, y_train)\n",
    "    counter = Counter(y_train_pre_transf)\n",
    "    print('After', counter)\n",
    "else:\n",
    "    X_train_pre_transf = X_train\n",
    "    y_train_pre_transf = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set = X_train_pre_transf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs = X_train_set.select_dtypes(include='category').columns.tolist()\n",
    "#print(cat_attribs)\n",
    "\n",
    "X_train_num_lst = X_train_set.drop(cat_attribs, axis=1).columns.tolist()\n",
    "X_train_cat_lst = X_train_set[cat_attribs].columns.tolist()\n",
    "\n",
    "#print(X_train_num_lst)\n",
    "#print(X_train_cat_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforamtion class to drop unwanted features\n",
    "class Attrib_drop_2_B(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d_list=[], keep_only_Lat_acc=False):\n",
    "        self.d_list = d_list\n",
    "        self.keep_only_Lat_acc = keep_only_Lat_acc\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.keep_only_Lat_acc:\n",
    "            Lat_acc_indices = []\n",
    "            for i, col in enumerate(X.columns):\n",
    "                if 'Lat_acc' in col:\n",
    "                    Lat_acc_indices.append(i)\n",
    "            return X.iloc[:,Lat_acc_indices]\n",
    "        elif self.d_list:\n",
    "            keep_indices = []\n",
    "            for i, col in enumerate(X.columns):\n",
    "                if col not in self.d_list:\n",
    "                    keep_indices.append(i)\n",
    "            return X.iloc[:,keep_indices]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the numerical features to be dropped to manually drop columns from the df\n",
    "\n",
    "drop_list_num_2_B = []\n",
    "\n",
    "\n",
    "num_pl_2_B = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attrib_transform', Attrib_transformer(stat_feature_head_to_tail='average')),\n",
    "    ('attrib_drop', Attrib_drop_2_B(keep_only_Lat_acc=False, d_list=drop_list_num_2_B)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "#For testing num_pl\n",
    "#num_prep = num_pl.fit_transform(X_train_set[X_train_num_lst])\n",
    "#print('shape after transformation: ', num_prep.shape)\n",
    "#num_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the categorical features to be dropped to manually drop columns from the df\n",
    "drop_list_cat_2_B = ['Lane']\n",
    "\n",
    "cat_pl_2_B = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('attrib_drop', Attrib_drop_2_B(d_list=drop_list_cat_2_B)),\n",
    "    ('One_Hot', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "# For testing cat_pl\n",
    "#cat_prep = cat_pl.fit_transform(X_train_set[X_train_cat_lst])\n",
    "#cat_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\9112325B\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "full_pl_2_B = ColumnTransformer([\n",
    "    (\"num\", num_pl_2_B, X_train_num_lst),\n",
    "    (\"cat\", cat_pl_2_B, X_train_cat_lst),\n",
    "])\n",
    "\n",
    "X_train_prep = full_pl_2_B.fit_transform(X_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components:  14\n"
     ]
    }
   ],
   "source": [
    "use_PCA = True\n",
    "\n",
    "if use_PCA:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_2_B = PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
    "              svd_solver='auto', tol=0.0, whiten=False)\n",
    "    \n",
    "    X_train_prep = pca_2_B.fit_transform(X_train_prep)\n",
    "    print('number of components: ', pca_2_B.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after transformation:  (147379, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.66560098, -1.2500247 , -0.9666567 , ..., -0.37340048,\n",
       "         1.22894949,  1.75804602],\n",
       "       [ 0.24865345, -1.63434635,  1.35370955, ...,  0.05854477,\n",
       "        -0.97159318, -0.14453309],\n",
       "       [-1.38182765, -0.30186142, -0.61259015, ...,  0.78980437,\n",
       "        -1.95102207, -0.15275348],\n",
       "       ...,\n",
       "       [-1.47008818,  0.78898334,  0.6842239 , ..., -0.83493562,\n",
       "        -0.07877977,  0.59237885],\n",
       "       [-1.2988194 ,  1.00523736,  1.23536663, ..., -1.1866085 ,\n",
       "        -0.90638845, -0.74243953],\n",
       "       [-1.41741232,  1.02398389,  0.03942391, ..., -1.18889566,\n",
       "        -0.47940993, -0.005473  ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape after transformation: ', X_train_prep.shape)\n",
    "X_train_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hyperopt for hyperparameter tuning\n",
    "#from hyperopt import fmin, tpe, hp, Trials, space_eval, STATUS_OK\n",
    "#from hyperopt.pyll import scope\n",
    "#from scipy import stats\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# set number of randomised trial to carry out\n",
    "n_iteration = 7\n",
    "\n",
    "#This command can be used to randomly sample parameter set from a space\n",
    "#from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "#ho_sample(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/7 [00:00<?, ?trial/s, best loss=?]0:\tlearn: 0.6841078\ttotal: 76ms\tremaining: 2.2s\n",
      "1:\tlearn: 0.6764191\ttotal: 155ms\tremaining: 2.17s\n",
      "2:\tlearn: 0.6689329\ttotal: 235ms\tremaining: 2.11s\n",
      "3:\tlearn: 0.6619221\ttotal: 314ms\tremaining: 2.04s\n",
      "4:\tlearn: 0.6559815\ttotal: 397ms\tremaining: 1.99s\n",
      "5:\tlearn: 0.6499338\ttotal: 481ms\tremaining: 1.92s\n",
      "6:\tlearn: 0.6445398\ttotal: 566ms\tremaining: 1.86s\n",
      "7:\tlearn: 0.6394628\ttotal: 650ms\tremaining: 1.79s\n",
      "8:\tlearn: 0.6344729\ttotal: 731ms\tremaining: 1.71s\n",
      "9:\tlearn: 0.6298237\ttotal: 815ms\tremaining: 1.63s\n",
      "10:\tlearn: 0.6253210\ttotal: 899ms\tremaining: 1.55s\n",
      "11:\tlearn: 0.6216956\ttotal: 981ms\tremaining: 1.47s\n",
      "12:\tlearn: 0.6175232\ttotal: 1.07s\tremaining: 1.4s\n",
      "13:\tlearn: 0.6136006\ttotal: 1.15s\tremaining: 1.31s\n",
      "14:\tlearn: 0.6092179\ttotal: 1.24s\tremaining: 1.24s\n",
      "15:\tlearn: 0.6056871\ttotal: 1.32s\tremaining: 1.15s\n",
      "16:\tlearn: 0.6017005\ttotal: 1.4s\tremaining: 1.07s\n",
      "17:\tlearn: 0.5971237\ttotal: 1.49s\tremaining: 992ms\n",
      "18:\tlearn: 0.5938814\ttotal: 1.57s\tremaining: 909ms\n",
      "19:\tlearn: 0.5905415\ttotal: 1.65s\tremaining: 826ms\n",
      "20:\tlearn: 0.5876852\ttotal: 1.73s\tremaining: 743ms\n",
      "21:\tlearn: 0.5840387\ttotal: 1.82s\tremaining: 661ms\n",
      "22:\tlearn: 0.5806883\ttotal: 1.9s\tremaining: 579ms\n",
      "23:\tlearn: 0.5770953\ttotal: 1.98s\tremaining: 496ms\n",
      "24:\tlearn: 0.5743349\ttotal: 2.07s\tremaining: 413ms\n",
      "25:\tlearn: 0.5716887\ttotal: 2.15s\tremaining: 330ms\n",
      "26:\tlearn: 0.5691599\ttotal: 2.23s\tremaining: 247ms\n",
      "27:\tlearn: 0.5653305\ttotal: 2.31s\tremaining: 165ms\n",
      "28:\tlearn: 0.5617269\ttotal: 2.4s\tremaining: 82.6ms\n",
      "29:\tlearn: 0.5578868\ttotal: 2.48s\tremaining: 0us\n",
      "0:\tlearn: 0.6845885\ttotal: 74.6ms\tremaining: 2.16s\n",
      "1:\tlearn: 0.6767472\ttotal: 154ms\tremaining: 2.16s\n",
      "2:\tlearn: 0.6697446\ttotal: 235ms\tremaining: 2.11s\n",
      "3:\tlearn: 0.6630115\ttotal: 322ms\tremaining: 2.09s\n",
      "4:\tlearn: 0.6563653\ttotal: 407ms\tremaining: 2.03s\n",
      "5:\tlearn: 0.6506583\ttotal: 488ms\tremaining: 1.95s\n",
      "6:\tlearn: 0.6446725\ttotal: 569ms\tremaining: 1.87s\n",
      "7:\tlearn: 0.6383324\ttotal: 657ms\tremaining: 1.8s\n",
      "8:\tlearn: 0.6322977\ttotal: 742ms\tremaining: 1.73s\n",
      "9:\tlearn: 0.6274802\ttotal: 825ms\tremaining: 1.65s\n",
      "10:\tlearn: 0.6226961\ttotal: 909ms\tremaining: 1.57s\n",
      "11:\tlearn: 0.6181847\ttotal: 989ms\tremaining: 1.48s\n",
      "12:\tlearn: 0.6142617\ttotal: 1.07s\tremaining: 1.4s\n",
      "13:\tlearn: 0.6104036\ttotal: 1.15s\tremaining: 1.32s\n",
      "14:\tlearn: 0.6061171\ttotal: 1.23s\tremaining: 1.23s\n",
      "15:\tlearn: 0.6030698\ttotal: 1.31s\tremaining: 1.15s\n",
      "16:\tlearn: 0.5994663\ttotal: 1.39s\tremaining: 1.06s\n",
      "17:\tlearn: 0.5959178\ttotal: 1.47s\tremaining: 982ms\n",
      "18:\tlearn: 0.5916346\ttotal: 1.56s\tremaining: 902ms\n",
      "19:\tlearn: 0.5880822\ttotal: 1.64s\tremaining: 820ms\n",
      "20:\tlearn: 0.5852725\ttotal: 1.72s\tremaining: 736ms\n",
      "21:\tlearn: 0.5805814\ttotal: 1.8s\tremaining: 655ms\n",
      "22:\tlearn: 0.5777321\ttotal: 1.88s\tremaining: 573ms\n",
      "23:\tlearn: 0.5744757\ttotal: 1.96s\tremaining: 491ms\n",
      "24:\tlearn: 0.5715858\ttotal: 2.05s\tremaining: 409ms\n",
      "25:\tlearn: 0.5679294\ttotal: 2.13s\tremaining: 328ms\n",
      "26:\tlearn: 0.5648542\ttotal: 2.21s\tremaining: 246ms\n",
      "27:\tlearn: 0.5611950\ttotal: 2.29s\tremaining: 164ms\n",
      "28:\tlearn: 0.5585311\ttotal: 2.38s\tremaining: 81.9ms\n",
      "29:\tlearn: 0.5550424\ttotal: 2.46s\tremaining: 0us\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                          | 1/7 [00:06<00:38,  6.48s/trial, best loss: -0.7060707717240146]0:\tlearn: 0.6705338\ttotal: 73.1ms\tremaining: 5.04s\n",
      "1:\tlearn: 0.6534788\ttotal: 164ms\tremaining: 5.58s\n",
      "2:\tlearn: 0.6385739\ttotal: 244ms\tremaining: 5.45s\n",
      "3:\tlearn: 0.6258228\ttotal: 326ms\tremaining: 5.38s\n",
      "4:\tlearn: 0.6152720\ttotal: 410ms\tremaining: 5.32s\n",
      "5:\tlearn: 0.6038012\ttotal: 493ms\tremaining: 5.26s\n",
      "6:\tlearn: 0.5946019\ttotal: 579ms\tremaining: 5.21s\n",
      "7:\tlearn: 0.5813962\ttotal: 664ms\tremaining: 5.14s\n",
      "8:\tlearn: 0.5731258\ttotal: 748ms\tremaining: 5.07s\n",
      "9:\tlearn: 0.5663017\ttotal: 844ms\tremaining: 5.06s\n",
      "10:\tlearn: 0.5593073\ttotal: 923ms\tremaining: 4.95s\n",
      "11:\tlearn: 0.5496763\ttotal: 1.01s\tremaining: 4.87s\n",
      "12:\tlearn: 0.5449462\ttotal: 1.09s\tremaining: 4.77s\n",
      "13:\tlearn: 0.5369244\ttotal: 1.17s\tremaining: 4.69s\n",
      "14:\tlearn: 0.5271514\ttotal: 1.26s\tremaining: 4.61s\n",
      "15:\tlearn: 0.5209083\ttotal: 1.34s\tremaining: 4.53s\n",
      "16:\tlearn: 0.5149393\ttotal: 1.42s\tremaining: 4.43s\n",
      "17:\tlearn: 0.5103707\ttotal: 1.5s\tremaining: 4.34s\n",
      "18:\tlearn: 0.5044340\ttotal: 1.58s\tremaining: 4.25s\n",
      "19:\tlearn: 0.4971876\ttotal: 1.67s\tremaining: 4.17s\n",
      "20:\tlearn: 0.4925775\ttotal: 1.75s\tremaining: 4.08s\n",
      "21:\tlearn: 0.4864280\ttotal: 1.83s\tremaining: 3.99s\n",
      "22:\tlearn: 0.4820037\ttotal: 1.91s\tremaining: 3.9s\n",
      "23:\tlearn: 0.4767780\ttotal: 1.99s\tremaining: 3.82s\n",
      "24:\tlearn: 0.4724313\ttotal: 2.07s\tremaining: 3.73s\n",
      "25:\tlearn: 0.4667476\ttotal: 2.16s\tremaining: 3.65s\n",
      "26:\tlearn: 0.4612075\ttotal: 2.24s\tremaining: 3.57s\n",
      "27:\tlearn: 0.4564971\ttotal: 2.33s\tremaining: 3.49s\n",
      "28:\tlearn: 0.4524486\ttotal: 2.41s\tremaining: 3.4s\n",
      "29:\tlearn: 0.4479807\ttotal: 2.49s\tremaining: 3.32s\n",
      "30:\tlearn: 0.4426388\ttotal: 2.57s\tremaining: 3.24s\n",
      "31:\tlearn: 0.4391534\ttotal: 2.66s\tremaining: 3.15s\n",
      "32:\tlearn: 0.4345734\ttotal: 2.74s\tremaining: 3.07s\n",
      "33:\tlearn: 0.4297033\ttotal: 2.82s\tremaining: 2.99s\n",
      "34:\tlearn: 0.4265452\ttotal: 2.9s\tremaining: 2.9s\n",
      "35:\tlearn: 0.4227005\ttotal: 2.99s\tremaining: 2.82s\n",
      "36:\tlearn: 0.4188591\ttotal: 3.07s\tremaining: 2.74s\n",
      "37:\tlearn: 0.4145555\ttotal: 3.15s\tremaining: 2.66s\n",
      "38:\tlearn: 0.4103193\ttotal: 3.24s\tremaining: 2.57s\n",
      "39:\tlearn: 0.4050621\ttotal: 3.32s\tremaining: 2.49s\n",
      "40:\tlearn: 0.4020600\ttotal: 3.41s\tremaining: 2.41s\n",
      "41:\tlearn: 0.3971810\ttotal: 3.49s\tremaining: 2.33s\n",
      "42:\tlearn: 0.3952879\ttotal: 3.57s\tremaining: 2.24s\n",
      "43:\tlearn: 0.3929983\ttotal: 3.65s\tremaining: 2.16s\n",
      "44:\tlearn: 0.3893594\ttotal: 3.73s\tremaining: 2.07s\n",
      "45:\tlearn: 0.3859403\ttotal: 3.81s\tremaining: 1.99s\n",
      "46:\tlearn: 0.3824291\ttotal: 3.9s\tremaining: 1.91s\n",
      "47:\tlearn: 0.3804411\ttotal: 3.98s\tremaining: 1.82s\n",
      "48:\tlearn: 0.3786462\ttotal: 4.05s\tremaining: 1.74s\n",
      "49:\tlearn: 0.3747879\ttotal: 4.14s\tremaining: 1.66s\n",
      "50:\tlearn: 0.3704009\ttotal: 4.22s\tremaining: 1.57s\n",
      "51:\tlearn: 0.3667595\ttotal: 4.3s\tremaining: 1.49s\n",
      "52:\tlearn: 0.3645471\ttotal: 4.38s\tremaining: 1.41s\n",
      "53:\tlearn: 0.3597719\ttotal: 4.47s\tremaining: 1.32s\n",
      "54:\tlearn: 0.3561857\ttotal: 4.55s\tremaining: 1.24s\n",
      "55:\tlearn: 0.3540533\ttotal: 4.64s\tremaining: 1.16s\n",
      "56:\tlearn: 0.3518556\ttotal: 4.72s\tremaining: 1.07s\n",
      "57:\tlearn: 0.3491065\ttotal: 4.8s\tremaining: 993ms\n",
      "58:\tlearn: 0.3435982\ttotal: 4.88s\tremaining: 911ms\n",
      "59:\tlearn: 0.3396963\ttotal: 4.97s\tremaining: 829ms\n",
      "60:\tlearn: 0.3370523\ttotal: 5.05s\tremaining: 746ms\n",
      "61:\tlearn: 0.3347922\ttotal: 5.14s\tremaining: 663ms\n",
      "62:\tlearn: 0.3311352\ttotal: 5.22s\tremaining: 580ms\n",
      "63:\tlearn: 0.3281753\ttotal: 5.31s\tremaining: 498ms\n",
      "64:\tlearn: 0.3255740\ttotal: 5.39s\tremaining: 415ms\n",
      "65:\tlearn: 0.3234348\ttotal: 5.47s\tremaining: 332ms\n",
      "66:\tlearn: 0.3203623\ttotal: 5.55s\tremaining: 249ms\n",
      "67:\tlearn: 0.3184490\ttotal: 5.64s\tremaining: 166ms\n",
      "68:\tlearn: 0.3161465\ttotal: 5.72s\tremaining: 82.9ms\n",
      "69:\tlearn: 0.3128975\ttotal: 5.8s\tremaining: 0us\n",
      "0:\tlearn: 0.6717077\ttotal: 75.2ms\tremaining: 5.19s\n",
      "1:\tlearn: 0.6539431\ttotal: 161ms\tremaining: 5.49s\n",
      "2:\tlearn: 0.6380432\ttotal: 251ms\tremaining: 5.6s\n",
      "3:\tlearn: 0.6232295\ttotal: 328ms\tremaining: 5.42s\n",
      "4:\tlearn: 0.6132565\ttotal: 408ms\tremaining: 5.3s\n",
      "5:\tlearn: 0.6034865\ttotal: 515ms\tremaining: 5.49s\n",
      "6:\tlearn: 0.5940038\ttotal: 619ms\tremaining: 5.57s\n",
      "7:\tlearn: 0.5812405\ttotal: 711ms\tremaining: 5.51s\n",
      "8:\tlearn: 0.5723049\ttotal: 797ms\tremaining: 5.4s\n",
      "9:\tlearn: 0.5651639\ttotal: 879ms\tremaining: 5.28s\n",
      "10:\tlearn: 0.5573086\ttotal: 964ms\tremaining: 5.17s\n",
      "11:\tlearn: 0.5496624\ttotal: 1.05s\tremaining: 5.07s\n",
      "12:\tlearn: 0.5428536\ttotal: 1.13s\tremaining: 4.97s\n",
      "13:\tlearn: 0.5376902\ttotal: 1.22s\tremaining: 4.86s\n",
      "14:\tlearn: 0.5285082\ttotal: 1.3s\tremaining: 4.78s\n",
      "15:\tlearn: 0.5196070\ttotal: 1.39s\tremaining: 4.69s\n",
      "16:\tlearn: 0.5134750\ttotal: 1.48s\tremaining: 4.6s\n",
      "17:\tlearn: 0.5076785\ttotal: 1.56s\tremaining: 4.5s\n",
      "18:\tlearn: 0.5033868\ttotal: 1.64s\tremaining: 4.39s\n",
      "19:\tlearn: 0.4972605\ttotal: 1.72s\tremaining: 4.3s\n",
      "20:\tlearn: 0.4913335\ttotal: 1.8s\tremaining: 4.21s\n",
      "21:\tlearn: 0.4852753\ttotal: 1.89s\tremaining: 4.12s\n",
      "22:\tlearn: 0.4806096\ttotal: 1.97s\tremaining: 4.03s\n",
      "23:\tlearn: 0.4756439\ttotal: 2.05s\tremaining: 3.94s\n",
      "24:\tlearn: 0.4715233\ttotal: 2.14s\tremaining: 3.85s\n",
      "25:\tlearn: 0.4669177\ttotal: 2.22s\tremaining: 3.75s\n",
      "26:\tlearn: 0.4610850\ttotal: 2.3s\tremaining: 3.67s\n",
      "27:\tlearn: 0.4558663\ttotal: 2.38s\tremaining: 3.58s\n",
      "28:\tlearn: 0.4515884\ttotal: 2.47s\tremaining: 3.49s\n",
      "29:\tlearn: 0.4482531\ttotal: 2.56s\tremaining: 3.41s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30:\tlearn: 0.4453101\ttotal: 2.64s\tremaining: 3.32s\n",
      "31:\tlearn: 0.4413681\ttotal: 2.72s\tremaining: 3.23s\n",
      "32:\tlearn: 0.4372255\ttotal: 2.81s\tremaining: 3.15s\n",
      "33:\tlearn: 0.4337463\ttotal: 2.89s\tremaining: 3.06s\n",
      "34:\tlearn: 0.4295590\ttotal: 2.98s\tremaining: 2.98s\n",
      "35:\tlearn: 0.4247758\ttotal: 3.06s\tremaining: 2.89s\n",
      "36:\tlearn: 0.4208672\ttotal: 3.15s\tremaining: 2.81s\n",
      "37:\tlearn: 0.4148166\ttotal: 3.24s\tremaining: 2.73s\n",
      "38:\tlearn: 0.4123610\ttotal: 3.32s\tremaining: 2.64s\n",
      "39:\tlearn: 0.4096357\ttotal: 3.4s\tremaining: 2.55s\n",
      "40:\tlearn: 0.4047315\ttotal: 3.49s\tremaining: 2.47s\n",
      "41:\tlearn: 0.4014437\ttotal: 3.58s\tremaining: 2.38s\n",
      "42:\tlearn: 0.3985414\ttotal: 3.66s\tremaining: 2.3s\n",
      "43:\tlearn: 0.3951416\ttotal: 3.74s\tremaining: 2.21s\n",
      "44:\tlearn: 0.3922537\ttotal: 3.82s\tremaining: 2.12s\n",
      "45:\tlearn: 0.3885446\ttotal: 3.9s\tremaining: 2.04s\n",
      "46:\tlearn: 0.3860368\ttotal: 3.98s\tremaining: 1.95s\n",
      "47:\tlearn: 0.3823065\ttotal: 4.07s\tremaining: 1.86s\n",
      "48:\tlearn: 0.3789459\ttotal: 4.15s\tremaining: 1.78s\n",
      "49:\tlearn: 0.3765728\ttotal: 4.23s\tremaining: 1.69s\n",
      "50:\tlearn: 0.3728986\ttotal: 4.31s\tremaining: 1.61s\n",
      "51:\tlearn: 0.3694978\ttotal: 4.4s\tremaining: 1.52s\n",
      "52:\tlearn: 0.3661200\ttotal: 4.48s\tremaining: 1.44s\n",
      "53:\tlearn: 0.3641662\ttotal: 4.56s\tremaining: 1.35s\n",
      "54:\tlearn: 0.3587751\ttotal: 4.65s\tremaining: 1.27s\n",
      "55:\tlearn: 0.3548941\ttotal: 4.73s\tremaining: 1.18s\n",
      "56:\tlearn: 0.3507756\ttotal: 4.82s\tremaining: 1.1s\n",
      "57:\tlearn: 0.3485909\ttotal: 4.89s\tremaining: 1.01s\n",
      "58:\tlearn: 0.3448165\ttotal: 4.98s\tremaining: 928ms\n",
      "59:\tlearn: 0.3390746\ttotal: 5.07s\tremaining: 846ms\n",
      "60:\tlearn: 0.3362350\ttotal: 5.16s\tremaining: 761ms\n",
      "61:\tlearn: 0.3325513\ttotal: 5.25s\tremaining: 677ms\n",
      "62:\tlearn: 0.3293851\ttotal: 5.33s\tremaining: 592ms\n",
      "63:\tlearn: 0.3266078\ttotal: 5.41s\tremaining: 508ms\n",
      "64:\tlearn: 0.3248139\ttotal: 5.5s\tremaining: 423ms\n",
      "65:\tlearn: 0.3229239\ttotal: 5.58s\tremaining: 338ms\n",
      "66:\tlearn: 0.3204659\ttotal: 5.66s\tremaining: 253ms\n",
      "67:\tlearn: 0.3186457\ttotal: 5.74s\tremaining: 169ms\n",
      "68:\tlearn: 0.3161525\ttotal: 5.82s\tremaining: 84.4ms\n",
      "69:\tlearn: 0.3144904\ttotal: 5.9s\tremaining: 0us\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                   | 2/7 [00:19<00:52, 10.53s/trial, best loss: -0.7932202194306723]0:\tlearn: 0.6766897\ttotal: 25.3ms\tremaining: 2.25s\n",
      "1:\tlearn: 0.6651197\ttotal: 34.8ms\tremaining: 1.53s\n",
      "2:\tlearn: 0.6571413\ttotal: 44.6ms\tremaining: 1.29s\n",
      "3:\tlearn: 0.6494103\ttotal: 54.1ms\tremaining: 1.16s\n",
      "4:\tlearn: 0.6428745\ttotal: 63ms\tremaining: 1.07s\n",
      "5:\tlearn: 0.6375130\ttotal: 72.2ms\tremaining: 1.01s\n",
      "6:\tlearn: 0.6317180\ttotal: 81.7ms\tremaining: 969ms\n",
      "7:\tlearn: 0.6266748\ttotal: 90.8ms\tremaining: 931ms\n",
      "8:\tlearn: 0.6218165\ttotal: 101ms\tremaining: 905ms\n",
      "9:\tlearn: 0.6175800\ttotal: 111ms\tremaining: 891ms\n",
      "10:\tlearn: 0.6137457\ttotal: 124ms\tremaining: 891ms\n",
      "11:\tlearn: 0.6097233\ttotal: 138ms\tremaining: 894ms\n",
      "12:\tlearn: 0.6062476\ttotal: 154ms\tremaining: 910ms\n",
      "13:\tlearn: 0.6025452\ttotal: 167ms\tremaining: 907ms\n",
      "14:\tlearn: 0.5993559\ttotal: 180ms\tremaining: 902ms\n",
      "15:\tlearn: 0.5963283\ttotal: 193ms\tremaining: 893ms\n",
      "16:\tlearn: 0.5941363\ttotal: 207ms\tremaining: 888ms\n",
      "17:\tlearn: 0.5912698\ttotal: 217ms\tremaining: 870ms\n",
      "18:\tlearn: 0.5888628\ttotal: 228ms\tremaining: 852ms\n",
      "19:\tlearn: 0.5863156\ttotal: 238ms\tremaining: 833ms\n",
      "20:\tlearn: 0.5843784\ttotal: 248ms\tremaining: 814ms\n",
      "21:\tlearn: 0.5818385\ttotal: 257ms\tremaining: 795ms\n",
      "22:\tlearn: 0.5783909\ttotal: 267ms\tremaining: 779ms\n",
      "23:\tlearn: 0.5760501\ttotal: 278ms\tremaining: 764ms\n",
      "24:\tlearn: 0.5740655\ttotal: 288ms\tremaining: 748ms\n",
      "25:\tlearn: 0.5719629\ttotal: 298ms\tremaining: 733ms\n",
      "26:\tlearn: 0.5698678\ttotal: 308ms\tremaining: 718ms\n",
      "27:\tlearn: 0.5678327\ttotal: 319ms\tremaining: 705ms\n",
      "28:\tlearn: 0.5656539\ttotal: 329ms\tremaining: 691ms\n",
      "29:\tlearn: 0.5629355\ttotal: 339ms\tremaining: 678ms\n",
      "30:\tlearn: 0.5609238\ttotal: 348ms\tremaining: 663ms\n",
      "31:\tlearn: 0.5591837\ttotal: 359ms\tremaining: 650ms\n",
      "32:\tlearn: 0.5568083\ttotal: 369ms\tremaining: 637ms\n",
      "33:\tlearn: 0.5551088\ttotal: 378ms\tremaining: 623ms\n",
      "34:\tlearn: 0.5528817\ttotal: 389ms\tremaining: 611ms\n",
      "35:\tlearn: 0.5512372\ttotal: 399ms\tremaining: 599ms\n",
      "36:\tlearn: 0.5495213\ttotal: 410ms\tremaining: 588ms\n",
      "37:\tlearn: 0.5476911\ttotal: 420ms\tremaining: 575ms\n",
      "38:\tlearn: 0.5456338\ttotal: 430ms\tremaining: 563ms\n",
      "39:\tlearn: 0.5441589\ttotal: 440ms\tremaining: 550ms\n",
      "40:\tlearn: 0.5423749\ttotal: 451ms\tremaining: 539ms\n",
      "41:\tlearn: 0.5407804\ttotal: 462ms\tremaining: 528ms\n",
      "42:\tlearn: 0.5390785\ttotal: 472ms\tremaining: 516ms\n",
      "43:\tlearn: 0.5377906\ttotal: 482ms\tremaining: 504ms\n",
      "44:\tlearn: 0.5358348\ttotal: 494ms\tremaining: 494ms\n",
      "45:\tlearn: 0.5341500\ttotal: 506ms\tremaining: 484ms\n",
      "46:\tlearn: 0.5323375\ttotal: 518ms\tremaining: 474ms\n",
      "47:\tlearn: 0.5309436\ttotal: 528ms\tremaining: 462ms\n",
      "48:\tlearn: 0.5292523\ttotal: 539ms\tremaining: 451ms\n",
      "49:\tlearn: 0.5277427\ttotal: 549ms\tremaining: 440ms\n",
      "50:\tlearn: 0.5256213\ttotal: 560ms\tremaining: 428ms\n",
      "51:\tlearn: 0.5236646\ttotal: 570ms\tremaining: 417ms\n",
      "52:\tlearn: 0.5219588\ttotal: 581ms\tremaining: 406ms\n",
      "53:\tlearn: 0.5204132\ttotal: 591ms\tremaining: 394ms\n",
      "54:\tlearn: 0.5184426\ttotal: 602ms\tremaining: 383ms\n",
      "55:\tlearn: 0.5168956\ttotal: 613ms\tremaining: 372ms\n",
      "56:\tlearn: 0.5147386\ttotal: 623ms\tremaining: 361ms\n",
      "57:\tlearn: 0.5133178\ttotal: 633ms\tremaining: 349ms\n",
      "58:\tlearn: 0.5119694\ttotal: 644ms\tremaining: 338ms\n",
      "59:\tlearn: 0.5101855\ttotal: 654ms\tremaining: 327ms\n",
      "60:\tlearn: 0.5093269\ttotal: 663ms\tremaining: 315ms\n",
      "61:\tlearn: 0.5077883\ttotal: 675ms\tremaining: 305ms\n",
      "62:\tlearn: 0.5063283\ttotal: 685ms\tremaining: 294ms\n",
      "63:\tlearn: 0.5051060\ttotal: 696ms\tremaining: 283ms\n",
      "64:\tlearn: 0.5038509\ttotal: 706ms\tremaining: 272ms\n",
      "65:\tlearn: 0.5023188\ttotal: 716ms\tremaining: 260ms\n",
      "66:\tlearn: 0.5010850\ttotal: 727ms\tremaining: 249ms\n",
      "67:\tlearn: 0.4995449\ttotal: 737ms\tremaining: 239ms\n",
      "68:\tlearn: 0.4981150\ttotal: 747ms\tremaining: 227ms\n",
      "69:\tlearn: 0.4971993\ttotal: 757ms\tremaining: 216ms\n",
      "70:\tlearn: 0.4959236\ttotal: 767ms\tremaining: 205ms\n",
      "71:\tlearn: 0.4948957\ttotal: 778ms\tremaining: 195ms\n",
      "72:\tlearn: 0.4938271\ttotal: 789ms\tremaining: 184ms\n",
      "73:\tlearn: 0.4924840\ttotal: 799ms\tremaining: 173ms\n",
      "74:\tlearn: 0.4909724\ttotal: 809ms\tremaining: 162ms\n",
      "75:\tlearn: 0.4897109\ttotal: 820ms\tremaining: 151ms\n",
      "76:\tlearn: 0.4878430\ttotal: 830ms\tremaining: 140ms\n",
      "77:\tlearn: 0.4863851\ttotal: 841ms\tremaining: 129ms\n",
      "78:\tlearn: 0.4847208\ttotal: 852ms\tremaining: 119ms\n",
      "79:\tlearn: 0.4836345\ttotal: 862ms\tremaining: 108ms\n",
      "80:\tlearn: 0.4822564\ttotal: 872ms\tremaining: 96.9ms\n",
      "81:\tlearn: 0.4812166\ttotal: 882ms\tremaining: 86ms\n",
      "82:\tlearn: 0.4799884\ttotal: 894ms\tremaining: 75.4ms\n",
      "83:\tlearn: 0.4786864\ttotal: 905ms\tremaining: 64.6ms\n",
      "84:\tlearn: 0.4770687\ttotal: 916ms\tremaining: 53.9ms\n",
      "85:\tlearn: 0.4763053\ttotal: 926ms\tremaining: 43.1ms\n",
      "86:\tlearn: 0.4751477\ttotal: 937ms\tremaining: 32.3ms\n",
      "87:\tlearn: 0.4738445\ttotal: 948ms\tremaining: 21.5ms\n",
      "88:\tlearn: 0.4727343\ttotal: 958ms\tremaining: 10.8ms\n",
      "89:\tlearn: 0.4718865\ttotal: 969ms\tremaining: 0us\n",
      "0:\tlearn: 0.6801146\ttotal: 16.2ms\tremaining: 1.44s\n",
      "1:\tlearn: 0.6701910\ttotal: 28.7ms\tremaining: 1.26s\n",
      "2:\tlearn: 0.6624185\ttotal: 39.1ms\tremaining: 1.13s\n",
      "3:\tlearn: 0.6541391\ttotal: 47.2ms\tremaining: 1.01s\n",
      "4:\tlearn: 0.6475322\ttotal: 55.9ms\tremaining: 950ms\n",
      "5:\tlearn: 0.6414857\ttotal: 64.6ms\tremaining: 905ms\n",
      "6:\tlearn: 0.6354197\ttotal: 74.1ms\tremaining: 879ms\n",
      "7:\tlearn: 0.6303708\ttotal: 83.1ms\tremaining: 852ms\n",
      "8:\tlearn: 0.6258900\ttotal: 92.7ms\tremaining: 834ms\n",
      "9:\tlearn: 0.6212564\ttotal: 102ms\tremaining: 819ms\n",
      "10:\tlearn: 0.6173261\ttotal: 112ms\tremaining: 803ms\n",
      "11:\tlearn: 0.6134811\ttotal: 122ms\tremaining: 791ms\n",
      "12:\tlearn: 0.6101315\ttotal: 132ms\tremaining: 781ms\n",
      "13:\tlearn: 0.6065510\ttotal: 142ms\tremaining: 771ms\n",
      "14:\tlearn: 0.6033610\ttotal: 153ms\tremaining: 765ms\n",
      "15:\tlearn: 0.5999213\ttotal: 164ms\tremaining: 757ms\n",
      "16:\tlearn: 0.5961405\ttotal: 174ms\tremaining: 746ms\n",
      "17:\tlearn: 0.5933442\ttotal: 184ms\tremaining: 735ms\n",
      "18:\tlearn: 0.5903477\ttotal: 194ms\tremaining: 724ms\n",
      "19:\tlearn: 0.5883667\ttotal: 203ms\tremaining: 710ms\n",
      "20:\tlearn: 0.5856471\ttotal: 215ms\tremaining: 707ms\n",
      "21:\tlearn: 0.5831571\ttotal: 226ms\tremaining: 698ms\n",
      "22:\tlearn: 0.5810997\ttotal: 238ms\tremaining: 693ms\n",
      "23:\tlearn: 0.5783134\ttotal: 250ms\tremaining: 686ms\n",
      "24:\tlearn: 0.5761986\ttotal: 259ms\tremaining: 675ms\n",
      "25:\tlearn: 0.5737186\ttotal: 270ms\tremaining: 664ms\n",
      "26:\tlearn: 0.5714588\ttotal: 280ms\tremaining: 652ms\n",
      "27:\tlearn: 0.5696840\ttotal: 290ms\tremaining: 641ms\n",
      "28:\tlearn: 0.5674391\ttotal: 300ms\tremaining: 631ms\n",
      "29:\tlearn: 0.5647712\ttotal: 310ms\tremaining: 621ms\n",
      "30:\tlearn: 0.5627552\ttotal: 321ms\tremaining: 610ms\n",
      "31:\tlearn: 0.5606711\ttotal: 330ms\tremaining: 599ms\n",
      "32:\tlearn: 0.5588015\ttotal: 341ms\tremaining: 589ms\n",
      "33:\tlearn: 0.5572712\ttotal: 351ms\tremaining: 577ms\n",
      "34:\tlearn: 0.5549775\ttotal: 361ms\tremaining: 567ms\n",
      "35:\tlearn: 0.5534948\ttotal: 371ms\tremaining: 556ms\n",
      "36:\tlearn: 0.5511934\ttotal: 380ms\tremaining: 545ms\n",
      "37:\tlearn: 0.5496373\ttotal: 391ms\tremaining: 535ms\n",
      "38:\tlearn: 0.5478189\ttotal: 401ms\tremaining: 524ms\n",
      "39:\tlearn: 0.5464955\ttotal: 411ms\tremaining: 513ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40:\tlearn: 0.5450542\ttotal: 420ms\tremaining: 502ms\n",
      "41:\tlearn: 0.5427928\ttotal: 432ms\tremaining: 494ms\n",
      "42:\tlearn: 0.5407263\ttotal: 442ms\tremaining: 484ms\n",
      "43:\tlearn: 0.5377556\ttotal: 454ms\tremaining: 475ms\n",
      "44:\tlearn: 0.5363221\ttotal: 464ms\tremaining: 464ms\n",
      "45:\tlearn: 0.5346553\ttotal: 473ms\tremaining: 453ms\n",
      "46:\tlearn: 0.5326621\ttotal: 484ms\tremaining: 442ms\n",
      "47:\tlearn: 0.5311102\ttotal: 493ms\tremaining: 432ms\n",
      "48:\tlearn: 0.5292438\ttotal: 504ms\tremaining: 422ms\n",
      "49:\tlearn: 0.5272287\ttotal: 514ms\tremaining: 411ms\n",
      "50:\tlearn: 0.5255568\ttotal: 524ms\tremaining: 401ms\n",
      "51:\tlearn: 0.5240075\ttotal: 534ms\tremaining: 390ms\n",
      "52:\tlearn: 0.5221849\ttotal: 544ms\tremaining: 380ms\n",
      "53:\tlearn: 0.5202285\ttotal: 555ms\tremaining: 370ms\n",
      "54:\tlearn: 0.5181579\ttotal: 566ms\tremaining: 360ms\n",
      "55:\tlearn: 0.5163895\ttotal: 576ms\tremaining: 350ms\n",
      "56:\tlearn: 0.5150128\ttotal: 586ms\tremaining: 339ms\n",
      "57:\tlearn: 0.5133853\ttotal: 597ms\tremaining: 329ms\n",
      "58:\tlearn: 0.5115470\ttotal: 607ms\tremaining: 319ms\n",
      "59:\tlearn: 0.5096916\ttotal: 618ms\tremaining: 309ms\n",
      "60:\tlearn: 0.5085033\ttotal: 627ms\tremaining: 298ms\n",
      "61:\tlearn: 0.5075064\ttotal: 638ms\tremaining: 288ms\n",
      "62:\tlearn: 0.5061999\ttotal: 649ms\tremaining: 278ms\n",
      "63:\tlearn: 0.5049821\ttotal: 659ms\tremaining: 268ms\n",
      "64:\tlearn: 0.5035929\ttotal: 670ms\tremaining: 258ms\n",
      "65:\tlearn: 0.5022710\ttotal: 680ms\tremaining: 247ms\n",
      "66:\tlearn: 0.5008374\ttotal: 690ms\tremaining: 237ms\n",
      "67:\tlearn: 0.4993961\ttotal: 701ms\tremaining: 227ms\n",
      "68:\tlearn: 0.4984668\ttotal: 711ms\tremaining: 216ms\n",
      "69:\tlearn: 0.4969878\ttotal: 721ms\tremaining: 206ms\n",
      "70:\tlearn: 0.4956418\ttotal: 731ms\tremaining: 196ms\n",
      "71:\tlearn: 0.4942933\ttotal: 742ms\tremaining: 185ms\n",
      "72:\tlearn: 0.4924879\ttotal: 753ms\tremaining: 175ms\n",
      "73:\tlearn: 0.4914278\ttotal: 763ms\tremaining: 165ms\n",
      "74:\tlearn: 0.4902344\ttotal: 773ms\tremaining: 155ms\n",
      "75:\tlearn: 0.4892304\ttotal: 784ms\tremaining: 144ms\n",
      "76:\tlearn: 0.4874821\ttotal: 794ms\tremaining: 134ms\n",
      "77:\tlearn: 0.4861525\ttotal: 804ms\tremaining: 124ms\n",
      "78:\tlearn: 0.4849453\ttotal: 814ms\tremaining: 113ms\n",
      "79:\tlearn: 0.4834727\ttotal: 826ms\tremaining: 103ms\n",
      "80:\tlearn: 0.4825139\ttotal: 836ms\tremaining: 92.8ms\n",
      "81:\tlearn: 0.4814649\ttotal: 847ms\tremaining: 82.6ms\n",
      "82:\tlearn: 0.4800862\ttotal: 858ms\tremaining: 72.4ms\n",
      "83:\tlearn: 0.4784178\ttotal: 869ms\tremaining: 62.1ms\n",
      "84:\tlearn: 0.4775426\ttotal: 879ms\tremaining: 51.7ms\n",
      "85:\tlearn: 0.4764487\ttotal: 889ms\tremaining: 41.4ms\n",
      "86:\tlearn: 0.4755047\ttotal: 899ms\tremaining: 31ms\n",
      "87:\tlearn: 0.4741627\ttotal: 910ms\tremaining: 20.7ms\n",
      "88:\tlearn: 0.4731446\ttotal: 920ms\tremaining: 10.3ms\n",
      "89:\tlearn: 0.4721547\ttotal: 933ms\tremaining: 0us\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 3/7 [00:23<00:29,  7.36s/trial, best loss: -0.7932202194306723]0:\tlearn: 0.6902604\ttotal: 6.27ms\tremaining: 307ms\n",
      "1:\tlearn: 0.6874417\ttotal: 12.9ms\tremaining: 309ms\n",
      "2:\tlearn: 0.6849705\ttotal: 26.4ms\tremaining: 413ms\n",
      "3:\tlearn: 0.6827535\ttotal: 38ms\tremaining: 437ms\n",
      "4:\tlearn: 0.6807195\ttotal: 46.8ms\tremaining: 422ms\n",
      "5:\tlearn: 0.6788096\ttotal: 55.5ms\tremaining: 407ms\n",
      "6:\tlearn: 0.6769018\ttotal: 64.1ms\tremaining: 394ms\n",
      "7:\tlearn: 0.6752913\ttotal: 72.8ms\tremaining: 382ms\n",
      "8:\tlearn: 0.6737495\ttotal: 81.5ms\tremaining: 371ms\n",
      "9:\tlearn: 0.6724077\ttotal: 90.2ms\tremaining: 361ms\n",
      "10:\tlearn: 0.6709098\ttotal: 98.6ms\tremaining: 349ms\n",
      "11:\tlearn: 0.6695916\ttotal: 107ms\tremaining: 339ms\n",
      "12:\tlearn: 0.6683271\ttotal: 114ms\tremaining: 325ms\n",
      "13:\tlearn: 0.6671048\ttotal: 122ms\tremaining: 312ms\n",
      "14:\tlearn: 0.6658192\ttotal: 128ms\tremaining: 299ms\n",
      "15:\tlearn: 0.6645018\ttotal: 135ms\tremaining: 287ms\n",
      "16:\tlearn: 0.6632905\ttotal: 142ms\tremaining: 276ms\n",
      "17:\tlearn: 0.6621153\ttotal: 149ms\tremaining: 265ms\n",
      "18:\tlearn: 0.6609954\ttotal: 155ms\tremaining: 254ms\n",
      "19:\tlearn: 0.6599174\ttotal: 162ms\tremaining: 243ms\n",
      "20:\tlearn: 0.6587813\ttotal: 170ms\tremaining: 234ms\n",
      "21:\tlearn: 0.6576056\ttotal: 176ms\tremaining: 224ms\n",
      "22:\tlearn: 0.6564123\ttotal: 183ms\tremaining: 215ms\n",
      "23:\tlearn: 0.6553358\ttotal: 190ms\tremaining: 206ms\n",
      "24:\tlearn: 0.6543255\ttotal: 197ms\tremaining: 197ms\n",
      "25:\tlearn: 0.6533380\ttotal: 204ms\tremaining: 189ms\n",
      "26:\tlearn: 0.6523778\ttotal: 211ms\tremaining: 180ms\n",
      "27:\tlearn: 0.6514098\ttotal: 219ms\tremaining: 172ms\n",
      "28:\tlearn: 0.6505212\ttotal: 227ms\tremaining: 164ms\n",
      "29:\tlearn: 0.6496572\ttotal: 234ms\tremaining: 156ms\n",
      "30:\tlearn: 0.6488085\ttotal: 241ms\tremaining: 148ms\n",
      "31:\tlearn: 0.6479648\ttotal: 248ms\tremaining: 139ms\n",
      "32:\tlearn: 0.6471228\ttotal: 255ms\tremaining: 131ms\n",
      "33:\tlearn: 0.6462633\ttotal: 263ms\tremaining: 124ms\n",
      "34:\tlearn: 0.6454884\ttotal: 270ms\tremaining: 116ms\n",
      "35:\tlearn: 0.6446253\ttotal: 278ms\tremaining: 108ms\n",
      "36:\tlearn: 0.6439240\ttotal: 285ms\tremaining: 100ms\n",
      "37:\tlearn: 0.6430312\ttotal: 292ms\tremaining: 92.2ms\n",
      "38:\tlearn: 0.6422545\ttotal: 299ms\tremaining: 84.4ms\n",
      "39:\tlearn: 0.6414698\ttotal: 306ms\tremaining: 76.6ms\n",
      "40:\tlearn: 0.6407160\ttotal: 314ms\tremaining: 68.9ms\n",
      "41:\tlearn: 0.6399715\ttotal: 321ms\tremaining: 61.1ms\n",
      "42:\tlearn: 0.6393188\ttotal: 328ms\tremaining: 53.4ms\n",
      "43:\tlearn: 0.6385897\ttotal: 335ms\tremaining: 45.7ms\n",
      "44:\tlearn: 0.6378380\ttotal: 343ms\tremaining: 38.1ms\n",
      "45:\tlearn: 0.6371206\ttotal: 350ms\tremaining: 30.4ms\n",
      "46:\tlearn: 0.6364315\ttotal: 357ms\tremaining: 22.8ms\n",
      "47:\tlearn: 0.6357601\ttotal: 364ms\tremaining: 15.2ms\n",
      "48:\tlearn: 0.6350614\ttotal: 371ms\tremaining: 7.56ms\n",
      "49:\tlearn: 0.6343679\ttotal: 378ms\tremaining: 0us\n",
      "0:\tlearn: 0.6909767\ttotal: 8.22ms\tremaining: 403ms\n",
      "1:\tlearn: 0.6888034\ttotal: 16.5ms\tremaining: 397ms\n",
      "2:\tlearn: 0.6868205\ttotal: 23.2ms\tremaining: 363ms\n",
      "3:\tlearn: 0.6850331\ttotal: 30.4ms\tremaining: 350ms\n",
      "4:\tlearn: 0.6834673\ttotal: 37.2ms\tremaining: 334ms\n",
      "5:\tlearn: 0.6819625\ttotal: 44.2ms\tremaining: 324ms\n",
      "6:\tlearn: 0.6803930\ttotal: 51.1ms\tremaining: 314ms\n",
      "7:\tlearn: 0.6788660\ttotal: 58.1ms\tremaining: 305ms\n",
      "8:\tlearn: 0.6773899\ttotal: 65.3ms\tremaining: 298ms\n",
      "9:\tlearn: 0.6761170\ttotal: 72.2ms\tremaining: 289ms\n",
      "10:\tlearn: 0.6748429\ttotal: 79.6ms\tremaining: 282ms\n",
      "11:\tlearn: 0.6734907\ttotal: 86.8ms\tremaining: 275ms\n",
      "12:\tlearn: 0.6722341\ttotal: 94.1ms\tremaining: 268ms\n",
      "13:\tlearn: 0.6709330\ttotal: 101ms\tremaining: 260ms\n",
      "14:\tlearn: 0.6696141\ttotal: 109ms\tremaining: 253ms\n",
      "15:\tlearn: 0.6684429\ttotal: 116ms\tremaining: 247ms\n",
      "16:\tlearn: 0.6673314\ttotal: 123ms\tremaining: 238ms\n",
      "17:\tlearn: 0.6663250\ttotal: 130ms\tremaining: 231ms\n",
      "18:\tlearn: 0.6652746\ttotal: 137ms\tremaining: 224ms\n",
      "19:\tlearn: 0.6642600\ttotal: 144ms\tremaining: 216ms\n",
      "20:\tlearn: 0.6632670\ttotal: 151ms\tremaining: 209ms\n",
      "21:\tlearn: 0.6622643\ttotal: 158ms\tremaining: 201ms\n",
      "22:\tlearn: 0.6611824\ttotal: 166ms\tremaining: 194ms\n",
      "23:\tlearn: 0.6601489\ttotal: 173ms\tremaining: 187ms\n",
      "24:\tlearn: 0.6590375\ttotal: 180ms\tremaining: 180ms\n",
      "25:\tlearn: 0.6579659\ttotal: 187ms\tremaining: 173ms\n",
      "26:\tlearn: 0.6570746\ttotal: 195ms\tremaining: 166ms\n",
      "27:\tlearn: 0.6560089\ttotal: 202ms\tremaining: 158ms\n",
      "28:\tlearn: 0.6551325\ttotal: 209ms\tremaining: 151ms\n",
      "29:\tlearn: 0.6542740\ttotal: 217ms\tremaining: 144ms\n",
      "30:\tlearn: 0.6534114\ttotal: 225ms\tremaining: 138ms\n",
      "31:\tlearn: 0.6525540\ttotal: 234ms\tremaining: 132ms\n",
      "32:\tlearn: 0.6517736\ttotal: 244ms\tremaining: 126ms\n",
      "33:\tlearn: 0.6509206\ttotal: 253ms\tremaining: 119ms\n",
      "34:\tlearn: 0.6500526\ttotal: 263ms\tremaining: 113ms\n",
      "35:\tlearn: 0.6492012\ttotal: 274ms\tremaining: 106ms\n",
      "36:\tlearn: 0.6484190\ttotal: 281ms\tremaining: 98.6ms\n",
      "37:\tlearn: 0.6474838\ttotal: 288ms\tremaining: 91ms\n",
      "38:\tlearn: 0.6467390\ttotal: 295ms\tremaining: 83.3ms\n",
      "39:\tlearn: 0.6460186\ttotal: 302ms\tremaining: 75.5ms\n",
      "40:\tlearn: 0.6452531\ttotal: 310ms\tremaining: 67.9ms\n",
      "41:\tlearn: 0.6444611\ttotal: 317ms\tremaining: 60.3ms\n",
      "42:\tlearn: 0.6437313\ttotal: 324ms\tremaining: 52.7ms\n",
      "43:\tlearn: 0.6430133\ttotal: 331ms\tremaining: 45.1ms\n",
      "44:\tlearn: 0.6423442\ttotal: 338ms\tremaining: 37.6ms\n",
      "45:\tlearn: 0.6416142\ttotal: 346ms\tremaining: 30.1ms\n",
      "46:\tlearn: 0.6409168\ttotal: 353ms\tremaining: 22.5ms\n",
      "47:\tlearn: 0.6402169\ttotal: 371ms\tremaining: 15.5ms\n",
      "48:\tlearn: 0.6395680\ttotal: 381ms\tremaining: 7.78ms\n",
      "49:\tlearn: 0.6388611\ttotal: 390ms\tremaining: 0us\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 4/7 [00:26<00:16,  5.54s/trial, best loss: -0.7932202194306723]0:\tlearn: 0.6858705\ttotal: 14.6ms\tremaining: 1.3s\n",
      "1:\tlearn: 0.6797953\ttotal: 29.3ms\tremaining: 1.29s\n",
      "2:\tlearn: 0.6744468\ttotal: 44.5ms\tremaining: 1.29s\n",
      "3:\tlearn: 0.6697098\ttotal: 60ms\tremaining: 1.29s\n",
      "4:\tlearn: 0.6654875\ttotal: 75.5ms\tremaining: 1.28s\n",
      "5:\tlearn: 0.6616116\ttotal: 91.1ms\tremaining: 1.27s\n",
      "6:\tlearn: 0.6580067\ttotal: 106ms\tremaining: 1.26s\n",
      "7:\tlearn: 0.6545843\ttotal: 122ms\tremaining: 1.25s\n",
      "8:\tlearn: 0.6515392\ttotal: 137ms\tremaining: 1.24s\n",
      "9:\tlearn: 0.6487373\ttotal: 153ms\tremaining: 1.22s\n",
      "10:\tlearn: 0.6459011\ttotal: 168ms\tremaining: 1.21s\n",
      "11:\tlearn: 0.6431098\ttotal: 186ms\tremaining: 1.21s\n",
      "12:\tlearn: 0.6404423\ttotal: 202ms\tremaining: 1.19s\n",
      "13:\tlearn: 0.6378665\ttotal: 217ms\tremaining: 1.18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:\tlearn: 0.6355745\ttotal: 234ms\tremaining: 1.17s\n",
      "15:\tlearn: 0.6334183\ttotal: 250ms\tremaining: 1.16s\n",
      "16:\tlearn: 0.6309823\ttotal: 266ms\tremaining: 1.14s\n",
      "17:\tlearn: 0.6287691\ttotal: 282ms\tremaining: 1.13s\n",
      "18:\tlearn: 0.6265071\ttotal: 298ms\tremaining: 1.11s\n",
      "19:\tlearn: 0.6245241\ttotal: 314ms\tremaining: 1.1s\n",
      "20:\tlearn: 0.6225253\ttotal: 331ms\tremaining: 1.09s\n",
      "21:\tlearn: 0.6203743\ttotal: 347ms\tremaining: 1.07s\n",
      "22:\tlearn: 0.6184804\ttotal: 363ms\tremaining: 1.06s\n",
      "23:\tlearn: 0.6163647\ttotal: 379ms\tremaining: 1.04s\n",
      "24:\tlearn: 0.6143295\ttotal: 396ms\tremaining: 1.03s\n",
      "25:\tlearn: 0.6124141\ttotal: 412ms\tremaining: 1.01s\n",
      "26:\tlearn: 0.6105288\ttotal: 429ms\tremaining: 1s\n",
      "27:\tlearn: 0.6088208\ttotal: 446ms\tremaining: 988ms\n",
      "28:\tlearn: 0.6069779\ttotal: 465ms\tremaining: 977ms\n",
      "29:\tlearn: 0.6051780\ttotal: 482ms\tremaining: 964ms\n",
      "30:\tlearn: 0.6036553\ttotal: 497ms\tremaining: 947ms\n",
      "31:\tlearn: 0.6022734\ttotal: 513ms\tremaining: 930ms\n",
      "32:\tlearn: 0.6005813\ttotal: 529ms\tremaining: 915ms\n",
      "33:\tlearn: 0.5992259\ttotal: 545ms\tremaining: 898ms\n",
      "34:\tlearn: 0.5977950\ttotal: 562ms\tremaining: 883ms\n",
      "35:\tlearn: 0.5964202\ttotal: 578ms\tremaining: 868ms\n",
      "36:\tlearn: 0.5949148\ttotal: 595ms\tremaining: 853ms\n",
      "37:\tlearn: 0.5936881\ttotal: 613ms\tremaining: 838ms\n",
      "38:\tlearn: 0.5924711\ttotal: 629ms\tremaining: 822ms\n",
      "39:\tlearn: 0.5908349\ttotal: 658ms\tremaining: 822ms\n",
      "40:\tlearn: 0.5895801\ttotal: 717ms\tremaining: 857ms\n",
      "41:\tlearn: 0.5882603\ttotal: 777ms\tremaining: 888ms\n",
      "42:\tlearn: 0.5868495\ttotal: 809ms\tremaining: 884ms\n",
      "43:\tlearn: 0.5855669\ttotal: 828ms\tremaining: 865ms\n",
      "44:\tlearn: 0.5843171\ttotal: 847ms\tremaining: 847ms\n",
      "45:\tlearn: 0.5832048\ttotal: 864ms\tremaining: 826ms\n",
      "46:\tlearn: 0.5818677\ttotal: 884ms\tremaining: 809ms\n",
      "47:\tlearn: 0.5805556\ttotal: 901ms\tremaining: 789ms\n",
      "48:\tlearn: 0.5796273\ttotal: 918ms\tremaining: 768ms\n",
      "49:\tlearn: 0.5784036\ttotal: 934ms\tremaining: 747ms\n",
      "50:\tlearn: 0.5772315\ttotal: 952ms\tremaining: 728ms\n",
      "51:\tlearn: 0.5759932\ttotal: 968ms\tremaining: 708ms\n",
      "52:\tlearn: 0.5749344\ttotal: 984ms\tremaining: 687ms\n",
      "53:\tlearn: 0.5733936\ttotal: 1s\tremaining: 668ms\n",
      "54:\tlearn: 0.5723286\ttotal: 1.02s\tremaining: 648ms\n",
      "55:\tlearn: 0.5710391\ttotal: 1.03s\tremaining: 628ms\n",
      "56:\tlearn: 0.5701914\ttotal: 1.05s\tremaining: 609ms\n",
      "57:\tlearn: 0.5691975\ttotal: 1.07s\tremaining: 589ms\n",
      "58:\tlearn: 0.5680372\ttotal: 1.08s\tremaining: 570ms\n",
      "59:\tlearn: 0.5665852\ttotal: 1.1s\tremaining: 552ms\n",
      "60:\tlearn: 0.5656879\ttotal: 1.12s\tremaining: 532ms\n",
      "61:\tlearn: 0.5642670\ttotal: 1.14s\tremaining: 513ms\n",
      "62:\tlearn: 0.5632369\ttotal: 1.15s\tremaining: 494ms\n",
      "63:\tlearn: 0.5621812\ttotal: 1.17s\tremaining: 476ms\n",
      "64:\tlearn: 0.5614009\ttotal: 1.19s\tremaining: 456ms\n",
      "65:\tlearn: 0.5604608\ttotal: 1.2s\tremaining: 437ms\n",
      "66:\tlearn: 0.5593666\ttotal: 1.22s\tremaining: 419ms\n",
      "67:\tlearn: 0.5580498\ttotal: 1.24s\tremaining: 401ms\n",
      "68:\tlearn: 0.5570628\ttotal: 1.25s\tremaining: 382ms\n",
      "69:\tlearn: 0.5561770\ttotal: 1.27s\tremaining: 363ms\n",
      "70:\tlearn: 0.5549488\ttotal: 1.29s\tremaining: 345ms\n",
      "71:\tlearn: 0.5539566\ttotal: 1.3s\tremaining: 326ms\n",
      "72:\tlearn: 0.5528996\ttotal: 1.32s\tremaining: 308ms\n",
      "73:\tlearn: 0.5520601\ttotal: 1.34s\tremaining: 290ms\n",
      "74:\tlearn: 0.5513359\ttotal: 1.35s\tremaining: 271ms\n",
      "75:\tlearn: 0.5503899\ttotal: 1.37s\tremaining: 253ms\n",
      "76:\tlearn: 0.5497018\ttotal: 1.39s\tremaining: 234ms\n",
      "77:\tlearn: 0.5486021\ttotal: 1.41s\tremaining: 216ms\n",
      "78:\tlearn: 0.5478017\ttotal: 1.42s\tremaining: 198ms\n",
      "79:\tlearn: 0.5469249\ttotal: 1.44s\tremaining: 180ms\n",
      "80:\tlearn: 0.5462332\ttotal: 1.46s\tremaining: 162ms\n",
      "81:\tlearn: 0.5455639\ttotal: 1.47s\tremaining: 144ms\n",
      "82:\tlearn: 0.5449320\ttotal: 1.49s\tremaining: 126ms\n",
      "83:\tlearn: 0.5439050\ttotal: 1.51s\tremaining: 108ms\n",
      "84:\tlearn: 0.5429319\ttotal: 1.52s\tremaining: 89.6ms\n",
      "85:\tlearn: 0.5422340\ttotal: 1.54s\tremaining: 71.7ms\n",
      "86:\tlearn: 0.5414937\ttotal: 1.56s\tremaining: 53.7ms\n",
      "87:\tlearn: 0.5402951\ttotal: 1.57s\tremaining: 35.8ms\n",
      "88:\tlearn: 0.5395975\ttotal: 1.59s\tremaining: 17.9ms\n",
      "89:\tlearn: 0.5389404\ttotal: 1.61s\tremaining: 0us\n",
      "0:\tlearn: 0.6873760\ttotal: 14.8ms\tremaining: 1.31s\n",
      "1:\tlearn: 0.6823884\ttotal: 30.3ms\tremaining: 1.33s\n",
      "2:\tlearn: 0.6778161\ttotal: 45.8ms\tremaining: 1.33s\n",
      "3:\tlearn: 0.6737738\ttotal: 61.4ms\tremaining: 1.32s\n",
      "4:\tlearn: 0.6693974\ttotal: 77.5ms\tremaining: 1.32s\n",
      "5:\tlearn: 0.6655323\ttotal: 91.4ms\tremaining: 1.28s\n",
      "6:\tlearn: 0.6621852\ttotal: 104ms\tremaining: 1.23s\n",
      "7:\tlearn: 0.6588377\ttotal: 116ms\tremaining: 1.19s\n",
      "8:\tlearn: 0.6556101\ttotal: 130ms\tremaining: 1.17s\n",
      "9:\tlearn: 0.6523051\ttotal: 144ms\tremaining: 1.15s\n",
      "10:\tlearn: 0.6493526\ttotal: 160ms\tremaining: 1.15s\n",
      "11:\tlearn: 0.6463484\ttotal: 177ms\tremaining: 1.15s\n",
      "12:\tlearn: 0.6436285\ttotal: 190ms\tremaining: 1.12s\n",
      "13:\tlearn: 0.6410887\ttotal: 202ms\tremaining: 1.09s\n",
      "14:\tlearn: 0.6387050\ttotal: 215ms\tremaining: 1.07s\n",
      "15:\tlearn: 0.6366007\ttotal: 228ms\tremaining: 1.05s\n",
      "16:\tlearn: 0.6339623\ttotal: 241ms\tremaining: 1.03s\n",
      "17:\tlearn: 0.6317407\ttotal: 254ms\tremaining: 1.01s\n",
      "18:\tlearn: 0.6294642\ttotal: 266ms\tremaining: 994ms\n",
      "19:\tlearn: 0.6270822\ttotal: 280ms\tremaining: 979ms\n",
      "20:\tlearn: 0.6249788\ttotal: 295ms\tremaining: 971ms\n",
      "21:\tlearn: 0.6231088\ttotal: 312ms\tremaining: 963ms\n",
      "22:\tlearn: 0.6213408\ttotal: 328ms\tremaining: 956ms\n",
      "23:\tlearn: 0.6193794\ttotal: 345ms\tremaining: 950ms\n",
      "24:\tlearn: 0.6176015\ttotal: 358ms\tremaining: 932ms\n",
      "25:\tlearn: 0.6158852\ttotal: 371ms\tremaining: 913ms\n",
      "26:\tlearn: 0.6142058\ttotal: 383ms\tremaining: 894ms\n",
      "27:\tlearn: 0.6125547\ttotal: 396ms\tremaining: 876ms\n",
      "28:\tlearn: 0.6107293\ttotal: 409ms\tremaining: 859ms\n",
      "29:\tlearn: 0.6092223\ttotal: 420ms\tremaining: 841ms\n",
      "30:\tlearn: 0.6077749\ttotal: 432ms\tremaining: 822ms\n",
      "31:\tlearn: 0.6061229\ttotal: 445ms\tremaining: 807ms\n",
      "32:\tlearn: 0.6046857\ttotal: 459ms\tremaining: 792ms\n",
      "33:\tlearn: 0.6031219\ttotal: 472ms\tremaining: 778ms\n",
      "34:\tlearn: 0.6011611\ttotal: 486ms\tremaining: 764ms\n",
      "35:\tlearn: 0.5997230\ttotal: 498ms\tremaining: 747ms\n",
      "36:\tlearn: 0.5979842\ttotal: 512ms\tremaining: 733ms\n",
      "37:\tlearn: 0.5964340\ttotal: 526ms\tremaining: 720ms\n",
      "38:\tlearn: 0.5951160\ttotal: 539ms\tremaining: 705ms\n",
      "39:\tlearn: 0.5935809\ttotal: 552ms\tremaining: 690ms\n",
      "40:\tlearn: 0.5924076\ttotal: 564ms\tremaining: 674ms\n",
      "41:\tlearn: 0.5910087\ttotal: 577ms\tremaining: 659ms\n",
      "42:\tlearn: 0.5897982\ttotal: 590ms\tremaining: 644ms\n",
      "43:\tlearn: 0.5884595\ttotal: 602ms\tremaining: 630ms\n",
      "44:\tlearn: 0.5870322\ttotal: 615ms\tremaining: 615ms\n",
      "45:\tlearn: 0.5852431\ttotal: 628ms\tremaining: 601ms\n",
      "46:\tlearn: 0.5839447\ttotal: 641ms\tremaining: 586ms\n",
      "47:\tlearn: 0.5826682\ttotal: 655ms\tremaining: 573ms\n",
      "48:\tlearn: 0.5814853\ttotal: 668ms\tremaining: 559ms\n",
      "49:\tlearn: 0.5801980\ttotal: 680ms\tremaining: 544ms\n",
      "50:\tlearn: 0.5791715\ttotal: 692ms\tremaining: 529ms\n",
      "51:\tlearn: 0.5779325\ttotal: 705ms\tremaining: 515ms\n",
      "52:\tlearn: 0.5766978\ttotal: 718ms\tremaining: 501ms\n",
      "53:\tlearn: 0.5753735\ttotal: 731ms\tremaining: 487ms\n",
      "54:\tlearn: 0.5741906\ttotal: 744ms\tremaining: 473ms\n",
      "55:\tlearn: 0.5724106\ttotal: 762ms\tremaining: 463ms\n",
      "56:\tlearn: 0.5711829\ttotal: 779ms\tremaining: 451ms\n",
      "57:\tlearn: 0.5701341\ttotal: 795ms\tremaining: 439ms\n",
      "58:\tlearn: 0.5690522\ttotal: 807ms\tremaining: 424ms\n",
      "59:\tlearn: 0.5681834\ttotal: 822ms\tremaining: 411ms\n",
      "60:\tlearn: 0.5673956\ttotal: 837ms\tremaining: 398ms\n",
      "61:\tlearn: 0.5663060\ttotal: 853ms\tremaining: 385ms\n",
      "62:\tlearn: 0.5651679\ttotal: 873ms\tremaining: 374ms\n",
      "63:\tlearn: 0.5640535\ttotal: 895ms\tremaining: 363ms\n",
      "64:\tlearn: 0.5630040\ttotal: 923ms\tremaining: 355ms\n",
      "65:\tlearn: 0.5619992\ttotal: 945ms\tremaining: 344ms\n",
      "66:\tlearn: 0.5608813\ttotal: 973ms\tremaining: 334ms\n",
      "67:\tlearn: 0.5598572\ttotal: 994ms\tremaining: 321ms\n",
      "68:\tlearn: 0.5589662\ttotal: 1.01s\tremaining: 308ms\n",
      "69:\tlearn: 0.5575764\ttotal: 1.03s\tremaining: 294ms\n",
      "70:\tlearn: 0.5566650\ttotal: 1.04s\tremaining: 280ms\n",
      "71:\tlearn: 0.5555209\ttotal: 1.06s\tremaining: 266ms\n",
      "72:\tlearn: 0.5546250\ttotal: 1.08s\tremaining: 251ms\n",
      "73:\tlearn: 0.5534106\ttotal: 1.1s\tremaining: 237ms\n",
      "74:\tlearn: 0.5520614\ttotal: 1.11s\tremaining: 223ms\n",
      "75:\tlearn: 0.5509993\ttotal: 1.13s\tremaining: 209ms\n",
      "76:\tlearn: 0.5501128\ttotal: 1.15s\tremaining: 194ms\n",
      "77:\tlearn: 0.5489969\ttotal: 1.17s\tremaining: 180ms\n",
      "78:\tlearn: 0.5481741\ttotal: 1.18s\tremaining: 165ms\n",
      "79:\tlearn: 0.5472392\ttotal: 1.2s\tremaining: 150ms\n",
      "80:\tlearn: 0.5465572\ttotal: 1.22s\tremaining: 135ms\n",
      "81:\tlearn: 0.5457150\ttotal: 1.23s\tremaining: 120ms\n",
      "82:\tlearn: 0.5446423\ttotal: 1.25s\tremaining: 105ms\n",
      "83:\tlearn: 0.5439889\ttotal: 1.27s\tremaining: 90.5ms\n",
      "84:\tlearn: 0.5428334\ttotal: 1.28s\tremaining: 75.5ms\n",
      "85:\tlearn: 0.5421766\ttotal: 1.3s\tremaining: 60.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86:\tlearn: 0.5410793\ttotal: 1.32s\tremaining: 45.4ms\n",
      "87:\tlearn: 0.5404874\ttotal: 1.33s\tremaining: 30.3ms\n",
      "88:\tlearn: 0.5396835\ttotal: 1.35s\tremaining: 15.2ms\n",
      "89:\tlearn: 0.5385697\ttotal: 1.37s\tremaining: 0us\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 5/7 [00:31<00:11,  5.53s/trial, best loss: -0.7932202194306723]0:\tlearn: 0.6640798\ttotal: 87.6ms\tremaining: 8.67s\n",
      "1:\tlearn: 0.6437785\ttotal: 177ms\tremaining: 8.67s\n",
      "2:\tlearn: 0.6273040\ttotal: 264ms\tremaining: 8.54s\n",
      "3:\tlearn: 0.6121236\ttotal: 362ms\tremaining: 8.68s\n",
      "4:\tlearn: 0.5970934\ttotal: 458ms\tremaining: 8.71s\n",
      "5:\tlearn: 0.5832821\ttotal: 544ms\tremaining: 8.53s\n",
      "6:\tlearn: 0.5737254\ttotal: 636ms\tremaining: 8.45s\n",
      "7:\tlearn: 0.5606575\ttotal: 744ms\tremaining: 8.55s\n",
      "8:\tlearn: 0.5482843\ttotal: 856ms\tremaining: 8.65s\n",
      "9:\tlearn: 0.5361829\ttotal: 955ms\tremaining: 8.6s\n",
      "10:\tlearn: 0.5276463\ttotal: 1.05s\tremaining: 8.5s\n",
      "11:\tlearn: 0.5189118\ttotal: 1.15s\tremaining: 8.42s\n",
      "12:\tlearn: 0.5133848\ttotal: 1.23s\tremaining: 8.26s\n",
      "13:\tlearn: 0.5022909\ttotal: 1.34s\tremaining: 8.23s\n",
      "14:\tlearn: 0.4946331\ttotal: 1.43s\tremaining: 8.12s\n",
      "15:\tlearn: 0.4844662\ttotal: 1.53s\tremaining: 8.03s\n",
      "16:\tlearn: 0.4791660\ttotal: 1.62s\tremaining: 7.91s\n",
      "17:\tlearn: 0.4706302\ttotal: 1.71s\tremaining: 7.8s\n",
      "18:\tlearn: 0.4649741\ttotal: 1.81s\tremaining: 7.71s\n",
      "19:\tlearn: 0.4564878\ttotal: 1.9s\tremaining: 7.61s\n",
      "20:\tlearn: 0.4513070\ttotal: 2s\tremaining: 7.53s\n",
      "21:\tlearn: 0.4439256\ttotal: 2.1s\tremaining: 7.45s\n",
      "22:\tlearn: 0.4396515\ttotal: 2.19s\tremaining: 7.35s\n",
      "23:\tlearn: 0.4343484\ttotal: 2.29s\tremaining: 7.26s\n",
      "24:\tlearn: 0.4302554\ttotal: 2.39s\tremaining: 7.17s\n",
      "25:\tlearn: 0.4244266\ttotal: 2.49s\tremaining: 7.08s\n",
      "26:\tlearn: 0.4180505\ttotal: 2.58s\tremaining: 6.96s\n",
      "27:\tlearn: 0.4144379\ttotal: 2.68s\tremaining: 6.88s\n",
      "28:\tlearn: 0.4117863\ttotal: 2.77s\tremaining: 6.77s\n",
      "29:\tlearn: 0.4088822\ttotal: 2.86s\tremaining: 6.67s\n",
      "30:\tlearn: 0.4025734\ttotal: 2.96s\tremaining: 6.59s\n",
      "31:\tlearn: 0.3980693\ttotal: 3.1s\tremaining: 6.58s\n",
      "32:\tlearn: 0.3920385\ttotal: 3.2s\tremaining: 6.49s\n",
      "33:\tlearn: 0.3852417\ttotal: 3.29s\tremaining: 6.39s\n",
      "34:\tlearn: 0.3813611\ttotal: 3.38s\tremaining: 6.27s\n",
      "35:\tlearn: 0.3758630\ttotal: 3.46s\tremaining: 6.16s\n",
      "36:\tlearn: 0.3728550\ttotal: 3.56s\tremaining: 6.06s\n",
      "37:\tlearn: 0.3679115\ttotal: 3.65s\tremaining: 5.96s\n",
      "38:\tlearn: 0.3618982\ttotal: 3.74s\tremaining: 5.85s\n",
      "39:\tlearn: 0.3559771\ttotal: 3.83s\tremaining: 5.74s\n",
      "40:\tlearn: 0.3526758\ttotal: 3.91s\tremaining: 5.63s\n",
      "41:\tlearn: 0.3501332\ttotal: 3.99s\tremaining: 5.51s\n",
      "42:\tlearn: 0.3457953\ttotal: 4.09s\tremaining: 5.43s\n",
      "43:\tlearn: 0.3424262\ttotal: 4.22s\tremaining: 5.37s\n",
      "44:\tlearn: 0.3369486\ttotal: 4.32s\tremaining: 5.28s\n",
      "45:\tlearn: 0.3329797\ttotal: 4.41s\tremaining: 5.17s\n",
      "46:\tlearn: 0.3297718\ttotal: 4.5s\tremaining: 5.08s\n",
      "47:\tlearn: 0.3274893\ttotal: 4.59s\tremaining: 4.97s\n",
      "48:\tlearn: 0.3242502\ttotal: 4.69s\tremaining: 4.88s\n",
      "49:\tlearn: 0.3216771\ttotal: 4.79s\tremaining: 4.79s\n",
      "50:\tlearn: 0.3196803\ttotal: 4.88s\tremaining: 4.68s\n",
      "51:\tlearn: 0.3147359\ttotal: 4.98s\tremaining: 4.6s\n",
      "52:\tlearn: 0.3103459\ttotal: 5.08s\tremaining: 4.5s\n",
      "53:\tlearn: 0.3058812\ttotal: 5.17s\tremaining: 4.4s\n",
      "54:\tlearn: 0.3026159\ttotal: 5.27s\tremaining: 4.31s\n",
      "55:\tlearn: 0.2992594\ttotal: 5.36s\tremaining: 4.21s\n",
      "56:\tlearn: 0.2963608\ttotal: 5.48s\tremaining: 4.13s\n",
      "57:\tlearn: 0.2933767\ttotal: 5.57s\tremaining: 4.04s\n",
      "58:\tlearn: 0.2903052\ttotal: 5.67s\tremaining: 3.94s\n",
      "59:\tlearn: 0.2875006\ttotal: 5.77s\tremaining: 3.85s\n",
      "60:\tlearn: 0.2840665\ttotal: 5.87s\tremaining: 3.75s\n",
      "61:\tlearn: 0.2813531\ttotal: 5.96s\tremaining: 3.65s\n",
      "62:\tlearn: 0.2782996\ttotal: 6.06s\tremaining: 3.56s\n",
      "63:\tlearn: 0.2755979\ttotal: 6.15s\tremaining: 3.46s\n",
      "64:\tlearn: 0.2737499\ttotal: 6.25s\tremaining: 3.36s\n",
      "65:\tlearn: 0.2718044\ttotal: 6.34s\tremaining: 3.27s\n",
      "66:\tlearn: 0.2684701\ttotal: 6.44s\tremaining: 3.17s\n",
      "67:\tlearn: 0.2656076\ttotal: 6.53s\tremaining: 3.08s\n",
      "68:\tlearn: 0.2632213\ttotal: 6.63s\tremaining: 2.98s\n",
      "69:\tlearn: 0.2603565\ttotal: 6.73s\tremaining: 2.88s\n",
      "70:\tlearn: 0.2570551\ttotal: 6.83s\tremaining: 2.79s\n",
      "71:\tlearn: 0.2553461\ttotal: 6.92s\tremaining: 2.69s\n",
      "72:\tlearn: 0.2535786\ttotal: 7.01s\tremaining: 2.59s\n",
      "73:\tlearn: 0.2514884\ttotal: 7.1s\tremaining: 2.49s\n",
      "74:\tlearn: 0.2489199\ttotal: 7.2s\tremaining: 2.4s\n",
      "75:\tlearn: 0.2475419\ttotal: 7.29s\tremaining: 2.3s\n",
      "76:\tlearn: 0.2459152\ttotal: 7.38s\tremaining: 2.21s\n",
      "77:\tlearn: 0.2445566\ttotal: 7.48s\tremaining: 2.11s\n",
      "78:\tlearn: 0.2432759\ttotal: 7.58s\tremaining: 2.01s\n",
      "79:\tlearn: 0.2413666\ttotal: 7.67s\tremaining: 1.92s\n",
      "80:\tlearn: 0.2392522\ttotal: 7.76s\tremaining: 1.82s\n",
      "81:\tlearn: 0.2371921\ttotal: 7.87s\tremaining: 1.73s\n",
      "82:\tlearn: 0.2356180\ttotal: 7.96s\tremaining: 1.63s\n",
      "83:\tlearn: 0.2341359\ttotal: 8.05s\tremaining: 1.53s\n",
      "84:\tlearn: 0.2320920\ttotal: 8.15s\tremaining: 1.44s\n",
      "85:\tlearn: 0.2294160\ttotal: 8.26s\tremaining: 1.34s\n",
      "86:\tlearn: 0.2269968\ttotal: 8.36s\tremaining: 1.25s\n",
      "87:\tlearn: 0.2254800\ttotal: 8.45s\tremaining: 1.15s\n",
      "88:\tlearn: 0.2242761\ttotal: 8.54s\tremaining: 1.05s\n",
      "89:\tlearn: 0.2222432\ttotal: 8.64s\tremaining: 960ms\n",
      "90:\tlearn: 0.2201912\ttotal: 8.74s\tremaining: 864ms\n",
      "91:\tlearn: 0.2188848\ttotal: 8.85s\tremaining: 769ms\n",
      "92:\tlearn: 0.2169755\ttotal: 8.95s\tremaining: 674ms\n",
      "93:\tlearn: 0.2145685\ttotal: 9.05s\tremaining: 577ms\n",
      "94:\tlearn: 0.2129531\ttotal: 9.14s\tremaining: 481ms\n",
      "95:\tlearn: 0.2105484\ttotal: 9.24s\tremaining: 385ms\n",
      "96:\tlearn: 0.2087341\ttotal: 9.34s\tremaining: 289ms\n",
      "97:\tlearn: 0.2072139\ttotal: 9.44s\tremaining: 193ms\n",
      "98:\tlearn: 0.2052288\ttotal: 9.54s\tremaining: 96.3ms\n",
      "99:\tlearn: 0.2030863\ttotal: 9.63s\tremaining: 0us\n",
      "0:\tlearn: 0.6655752\ttotal: 80.4ms\tremaining: 7.96s\n",
      "1:\tlearn: 0.6432948\ttotal: 168ms\tremaining: 8.22s\n",
      "2:\tlearn: 0.6251725\ttotal: 251ms\tremaining: 8.11s\n",
      "3:\tlearn: 0.6097965\ttotal: 338ms\tremaining: 8.12s\n",
      "4:\tlearn: 0.5958269\ttotal: 462ms\tremaining: 8.77s\n",
      "5:\tlearn: 0.5838839\ttotal: 574ms\tremaining: 8.99s\n",
      "6:\tlearn: 0.5717717\ttotal: 674ms\tremaining: 8.95s\n",
      "7:\tlearn: 0.5592438\ttotal: 773ms\tremaining: 8.89s\n",
      "8:\tlearn: 0.5488009\ttotal: 875ms\tremaining: 8.85s\n",
      "9:\tlearn: 0.5399678\ttotal: 981ms\tremaining: 8.83s\n",
      "10:\tlearn: 0.5300434\ttotal: 1.08s\tremaining: 8.72s\n",
      "11:\tlearn: 0.5212289\ttotal: 1.2s\tremaining: 8.8s\n",
      "12:\tlearn: 0.5156845\ttotal: 1.31s\tremaining: 8.8s\n",
      "13:\tlearn: 0.5106067\ttotal: 1.44s\tremaining: 8.85s\n",
      "14:\tlearn: 0.4999937\ttotal: 1.57s\tremaining: 8.9s\n",
      "15:\tlearn: 0.4884155\ttotal: 1.7s\tremaining: 8.94s\n",
      "16:\tlearn: 0.4809092\ttotal: 1.83s\tremaining: 8.94s\n",
      "17:\tlearn: 0.4755427\ttotal: 1.96s\tremaining: 8.93s\n",
      "18:\tlearn: 0.4663786\ttotal: 2.07s\tremaining: 8.84s\n",
      "19:\tlearn: 0.4559804\ttotal: 2.18s\tremaining: 8.72s\n",
      "20:\tlearn: 0.4481774\ttotal: 2.28s\tremaining: 8.58s\n",
      "21:\tlearn: 0.4413606\ttotal: 2.38s\tremaining: 8.46s\n",
      "22:\tlearn: 0.4367245\ttotal: 2.48s\tremaining: 8.3s\n",
      "23:\tlearn: 0.4327112\ttotal: 2.58s\tremaining: 8.16s\n",
      "24:\tlearn: 0.4274805\ttotal: 2.67s\tremaining: 8.03s\n",
      "25:\tlearn: 0.4212308\ttotal: 2.77s\tremaining: 7.89s\n",
      "26:\tlearn: 0.4162497\ttotal: 2.87s\tremaining: 7.75s\n",
      "27:\tlearn: 0.4103054\ttotal: 2.96s\tremaining: 7.62s\n",
      "28:\tlearn: 0.4070438\ttotal: 3.06s\tremaining: 7.5s\n",
      "29:\tlearn: 0.4024687\ttotal: 3.16s\tremaining: 7.37s\n",
      "30:\tlearn: 0.3961296\ttotal: 3.26s\tremaining: 7.26s\n",
      "31:\tlearn: 0.3912959\ttotal: 3.36s\tremaining: 7.15s\n",
      "32:\tlearn: 0.3879164\ttotal: 3.46s\tremaining: 7.02s\n",
      "33:\tlearn: 0.3803982\ttotal: 3.56s\tremaining: 6.91s\n",
      "34:\tlearn: 0.3764293\ttotal: 3.65s\tremaining: 6.78s\n",
      "35:\tlearn: 0.3723065\ttotal: 3.75s\tremaining: 6.66s\n",
      "36:\tlearn: 0.3683605\ttotal: 3.85s\tremaining: 6.55s\n",
      "37:\tlearn: 0.3658954\ttotal: 3.94s\tremaining: 6.43s\n",
      "38:\tlearn: 0.3627263\ttotal: 4.04s\tremaining: 6.31s\n",
      "39:\tlearn: 0.3597166\ttotal: 4.13s\tremaining: 6.2s\n",
      "40:\tlearn: 0.3561585\ttotal: 4.22s\tremaining: 6.08s\n",
      "41:\tlearn: 0.3534279\ttotal: 4.32s\tremaining: 5.96s\n",
      "42:\tlearn: 0.3488598\ttotal: 4.42s\tremaining: 5.86s\n",
      "43:\tlearn: 0.3461740\ttotal: 4.51s\tremaining: 5.74s\n",
      "44:\tlearn: 0.3430374\ttotal: 4.61s\tremaining: 5.63s\n",
      "45:\tlearn: 0.3384819\ttotal: 4.7s\tremaining: 5.51s\n",
      "46:\tlearn: 0.3349638\ttotal: 4.8s\tremaining: 5.41s\n",
      "47:\tlearn: 0.3309247\ttotal: 4.89s\tremaining: 5.3s\n",
      "48:\tlearn: 0.3279210\ttotal: 4.99s\tremaining: 5.19s\n",
      "49:\tlearn: 0.3244637\ttotal: 5.1s\tremaining: 5.1s\n",
      "50:\tlearn: 0.3216600\ttotal: 5.19s\tremaining: 4.99s\n",
      "51:\tlearn: 0.3174063\ttotal: 5.29s\tremaining: 4.88s\n",
      "52:\tlearn: 0.3145286\ttotal: 5.39s\tremaining: 4.78s\n",
      "53:\tlearn: 0.3100722\ttotal: 5.49s\tremaining: 4.68s\n",
      "54:\tlearn: 0.3073827\ttotal: 5.59s\tremaining: 4.58s\n",
      "55:\tlearn: 0.3047144\ttotal: 5.69s\tremaining: 4.47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56:\tlearn: 0.3020469\ttotal: 5.78s\tremaining: 4.36s\n",
      "57:\tlearn: 0.2993893\ttotal: 5.88s\tremaining: 4.26s\n",
      "58:\tlearn: 0.2966240\ttotal: 5.99s\tremaining: 4.16s\n",
      "59:\tlearn: 0.2949016\ttotal: 6.07s\tremaining: 4.05s\n",
      "60:\tlearn: 0.2927367\ttotal: 6.18s\tremaining: 3.95s\n",
      "61:\tlearn: 0.2882680\ttotal: 6.28s\tremaining: 3.85s\n",
      "62:\tlearn: 0.2856037\ttotal: 6.38s\tremaining: 3.75s\n",
      "63:\tlearn: 0.2823637\ttotal: 6.47s\tremaining: 3.64s\n",
      "64:\tlearn: 0.2803861\ttotal: 6.59s\tremaining: 3.55s\n",
      "65:\tlearn: 0.2768470\ttotal: 6.7s\tremaining: 3.45s\n",
      "66:\tlearn: 0.2733321\ttotal: 6.8s\tremaining: 3.35s\n",
      "67:\tlearn: 0.2716592\ttotal: 6.9s\tremaining: 3.25s\n",
      "68:\tlearn: 0.2687671\ttotal: 7s\tremaining: 3.14s\n",
      "69:\tlearn: 0.2664906\ttotal: 7.13s\tremaining: 3.05s\n",
      "70:\tlearn: 0.2641989\ttotal: 7.22s\tremaining: 2.95s\n",
      "71:\tlearn: 0.2623348\ttotal: 7.31s\tremaining: 2.84s\n",
      "72:\tlearn: 0.2587832\ttotal: 7.4s\tremaining: 2.74s\n",
      "73:\tlearn: 0.2569465\ttotal: 7.48s\tremaining: 2.63s\n",
      "74:\tlearn: 0.2537920\ttotal: 7.59s\tremaining: 2.53s\n",
      "75:\tlearn: 0.2509023\ttotal: 7.69s\tremaining: 2.43s\n",
      "76:\tlearn: 0.2493997\ttotal: 7.8s\tremaining: 2.33s\n",
      "77:\tlearn: 0.2479047\ttotal: 7.91s\tremaining: 2.23s\n",
      "78:\tlearn: 0.2457127\ttotal: 8.01s\tremaining: 2.13s\n",
      "79:\tlearn: 0.2433223\ttotal: 8.13s\tremaining: 2.03s\n",
      "80:\tlearn: 0.2404762\ttotal: 8.23s\tremaining: 1.93s\n",
      "81:\tlearn: 0.2390180\ttotal: 8.32s\tremaining: 1.83s\n",
      "82:\tlearn: 0.2363201\ttotal: 8.42s\tremaining: 1.72s\n",
      "83:\tlearn: 0.2344070\ttotal: 8.52s\tremaining: 1.62s\n",
      "84:\tlearn: 0.2327001\ttotal: 8.62s\tremaining: 1.52s\n",
      "85:\tlearn: 0.2313931\ttotal: 8.72s\tremaining: 1.42s\n",
      "86:\tlearn: 0.2297560\ttotal: 8.82s\tremaining: 1.32s\n",
      "87:\tlearn: 0.2286611\ttotal: 8.91s\tremaining: 1.22s\n",
      "88:\tlearn: 0.2274965\ttotal: 9.01s\tremaining: 1.11s\n",
      "89:\tlearn: 0.2251943\ttotal: 9.11s\tremaining: 1.01s\n",
      "90:\tlearn: 0.2237688\ttotal: 9.2s\tremaining: 910ms\n",
      "91:\tlearn: 0.2219925\ttotal: 9.31s\tremaining: 809ms\n",
      "92:\tlearn: 0.2202668\ttotal: 9.4s\tremaining: 708ms\n",
      "93:\tlearn: 0.2186059\ttotal: 9.5s\tremaining: 607ms\n",
      "94:\tlearn: 0.2169620\ttotal: 9.6s\tremaining: 505ms\n",
      "95:\tlearn: 0.2156538\ttotal: 9.7s\tremaining: 404ms\n",
      "96:\tlearn: 0.2142855\ttotal: 9.79s\tremaining: 303ms\n",
      "97:\tlearn: 0.2134123\ttotal: 9.88s\tremaining: 202ms\n",
      "98:\tlearn: 0.2117707\ttotal: 9.98s\tremaining: 101ms\n",
      "99:\tlearn: 0.2100281\ttotal: 10.1s\tremaining: 0us\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 6/7 [00:53<00:11, 11.21s/trial, best loss: -0.8156928989271204]0:\tlearn: 0.6645294\ttotal: 2.23s\tremaining: 1m 4s\n",
      "1:\tlearn: 0.6404325\ttotal: 4.42s\tremaining: 1m 1s\n",
      "2:\tlearn: 0.6181397\ttotal: 6.61s\tremaining: 59.5s\n",
      "3:\tlearn: 0.5985142\ttotal: 8.84s\tremaining: 57.5s\n",
      "4:\tlearn: 0.5808752\ttotal: 10.9s\tremaining: 54.7s\n",
      "5:\tlearn: 0.5638027\ttotal: 13s\tremaining: 52s\n",
      "6:\tlearn: 0.5484115\ttotal: 15.1s\tremaining: 49.5s\n",
      "7:\tlearn: 0.5331784\ttotal: 17.2s\tremaining: 47.4s\n",
      "8:\tlearn: 0.5220422\ttotal: 19.3s\tremaining: 45.1s\n",
      "9:\tlearn: 0.5099277\ttotal: 21.4s\tremaining: 42.8s\n",
      "10:\tlearn: 0.4964917\ttotal: 23.7s\tremaining: 40.9s\n",
      "11:\tlearn: 0.4849908\ttotal: 25.9s\tremaining: 38.8s\n",
      "12:\tlearn: 0.4728214\ttotal: 28s\tremaining: 36.6s\n",
      "13:\tlearn: 0.4621416\ttotal: 30.3s\tremaining: 34.6s\n",
      "14:\tlearn: 0.4521416\ttotal: 32.5s\tremaining: 32.5s\n",
      "15:\tlearn: 0.4417259\ttotal: 34.7s\tremaining: 30.4s\n",
      "16:\tlearn: 0.4311454\ttotal: 36.9s\tremaining: 28.2s\n",
      "17:\tlearn: 0.4206443\ttotal: 39.2s\tremaining: 26.1s\n",
      "18:\tlearn: 0.4110344\ttotal: 41.9s\tremaining: 24.2s\n",
      "19:\tlearn: 0.4031561\ttotal: 44.3s\tremaining: 22.2s\n",
      "20:\tlearn: 0.3905533\ttotal: 46.7s\tremaining: 20s\n",
      "21:\tlearn: 0.3833905\ttotal: 49s\tremaining: 17.8s\n",
      "22:\tlearn: 0.3760885\ttotal: 51.6s\tremaining: 15.7s\n",
      "23:\tlearn: 0.3679914\ttotal: 54.2s\tremaining: 13.5s\n",
      "24:\tlearn: 0.3622197\ttotal: 56.5s\tremaining: 11.3s\n",
      "25:\tlearn: 0.3543567\ttotal: 58.7s\tremaining: 9.03s\n",
      "26:\tlearn: 0.3462691\ttotal: 1m 1s\tremaining: 6.78s\n",
      "27:\tlearn: 0.3392649\ttotal: 1m 3s\tremaining: 4.52s\n",
      "28:\tlearn: 0.3343540\ttotal: 1m 5s\tremaining: 2.26s\n",
      "29:\tlearn: 0.3266898\ttotal: 1m 7s\tremaining: 0us\n",
      "0:\tlearn: 0.6639052\ttotal: 2.09s\tremaining: 1m\n",
      "1:\tlearn: 0.6363269\ttotal: 4.2s\tremaining: 58.7s\n",
      "2:\tlearn: 0.6152369\ttotal: 6.27s\tremaining: 56.4s\n",
      "3:\tlearn: 0.5920464\ttotal: 8.4s\tremaining: 54.6s\n",
      "4:\tlearn: 0.5741065\ttotal: 10.5s\tremaining: 52.7s\n",
      "5:\tlearn: 0.5568435\ttotal: 12.8s\tremaining: 51s\n",
      "6:\tlearn: 0.5386083\ttotal: 14.9s\tremaining: 48.9s\n",
      "7:\tlearn: 0.5246625\ttotal: 17s\tremaining: 46.7s\n",
      "8:\tlearn: 0.5096094\ttotal: 19s\tremaining: 44.4s\n",
      "9:\tlearn: 0.4962473\ttotal: 21.1s\tremaining: 42.2s\n",
      "10:\tlearn: 0.4845690\ttotal: 23.2s\tremaining: 40s\n",
      "11:\tlearn: 0.4702492\ttotal: 25.3s\tremaining: 37.9s\n",
      "12:\tlearn: 0.4572317\ttotal: 27.4s\tremaining: 35.8s\n",
      "13:\tlearn: 0.4451598\ttotal: 29.5s\tremaining: 33.7s\n",
      "14:\tlearn: 0.4358982\ttotal: 31.6s\tremaining: 31.6s\n",
      "15:\tlearn: 0.4248274\ttotal: 33.7s\tremaining: 29.5s\n",
      "16:\tlearn: 0.4139870\ttotal: 35.9s\tremaining: 27.5s\n",
      "17:\tlearn: 0.4056209\ttotal: 38s\tremaining: 25.3s\n",
      "18:\tlearn: 0.3971176\ttotal: 40.1s\tremaining: 23.2s\n",
      "19:\tlearn: 0.3894711\ttotal: 42.2s\tremaining: 21.1s\n",
      "20:\tlearn: 0.3824196\ttotal: 44.5s\tremaining: 19.1s\n",
      "21:\tlearn: 0.3745390\ttotal: 46.6s\tremaining: 16.9s\n",
      "22:\tlearn: 0.3659404\ttotal: 48.7s\tremaining: 14.8s\n",
      "23:\tlearn: 0.3583812\ttotal: 50.8s\tremaining: 12.7s\n",
      "24:\tlearn: 0.3521210\ttotal: 52.9s\tremaining: 10.6s\n",
      "25:\tlearn: 0.3444028\ttotal: 55s\tremaining: 8.46s\n",
      "26:\tlearn: 0.3370813\ttotal: 57.1s\tremaining: 6.34s\n",
      "27:\tlearn: 0.3297176\ttotal: 59.2s\tremaining: 4.23s\n",
      "28:\tlearn: 0.3233744\ttotal: 1m 1s\tremaining: 2.11s\n",
      "29:\tlearn: 0.3139825\ttotal: 1m 3s\tremaining: 0us\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [03:07<00:00, 26.72s/trial, best loss: -0.8156928989271204]\n",
      "Best parameters: {'depth': [2], 'iterations': [4], 'learning_rate': [0.33625315247234416]}\n",
      "Best score: 0.8156928989271204\n"
     ]
    }
   ],
   "source": [
    "#from catboost import CatBoostClassifier\n",
    "\n",
    "def tune_CatB_2_B(params):\n",
    "    CatB_clf_2_B = CatBoostClassifier(**params)\n",
    "    acc = cross_val_score(CatB_clf_2_B, X_train_prep, y_train_pre_transf, scoring=\"accuracy\", cv=2).mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    \"iterations\": hp.choice(\"iterations\",[30, 50, 70, 90, 100]),\n",
    "    \"depth\": hp.choice(\"depth\",[3, 5, 10, 15, None]),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.05), np.log(0.5)),\n",
    "}\n",
    "\n",
    "\n",
    "trials=Trials() # Trails() must be reassign each time to reset its value\n",
    "best_search_CatB_2_B = fmin(fn=tune_CatB_2_B, space = space, algo=tpe.suggest, max_evals=n_iteration, trials=trials)\n",
    "\n",
    "best_trial_CatB_2_B = trials.best_trial\n",
    "best_params_CatB_2_B = best_trial_CatB_2_B[\"misc\"][\"vals\"]\n",
    "best_score_CatB_2_B = -best_trial_CatB_2_B[\"result\"][\"loss\"]\n",
    "\n",
    "print(\"Best parameters:\", best_params_CatB_2_B)\n",
    "print(\"Best score:\", best_score_CatB_2_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6656499\ttotal: 107ms\tremaining: 10.6s\n",
      "1:\tlearn: 0.6449559\ttotal: 225ms\tremaining: 11s\n",
      "2:\tlearn: 0.6281660\ttotal: 338ms\tremaining: 10.9s\n",
      "3:\tlearn: 0.6145985\ttotal: 439ms\tremaining: 10.5s\n",
      "4:\tlearn: 0.6024813\ttotal: 542ms\tremaining: 10.3s\n",
      "5:\tlearn: 0.5880640\ttotal: 652ms\tremaining: 10.2s\n",
      "6:\tlearn: 0.5783946\ttotal: 754ms\tremaining: 10s\n",
      "7:\tlearn: 0.5699321\ttotal: 859ms\tremaining: 9.88s\n",
      "8:\tlearn: 0.5586816\ttotal: 978ms\tremaining: 9.89s\n",
      "9:\tlearn: 0.5509038\ttotal: 1.08s\tremaining: 9.72s\n",
      "10:\tlearn: 0.5440595\ttotal: 1.18s\tremaining: 9.58s\n",
      "11:\tlearn: 0.5368247\ttotal: 1.3s\tremaining: 9.52s\n",
      "12:\tlearn: 0.5297826\ttotal: 1.41s\tremaining: 9.41s\n",
      "13:\tlearn: 0.5220956\ttotal: 1.51s\tremaining: 9.29s\n",
      "14:\tlearn: 0.5150810\ttotal: 1.63s\tremaining: 9.23s\n",
      "15:\tlearn: 0.5092911\ttotal: 1.74s\tremaining: 9.15s\n",
      "16:\tlearn: 0.5030645\ttotal: 1.86s\tremaining: 9.08s\n",
      "17:\tlearn: 0.4981419\ttotal: 1.97s\tremaining: 8.99s\n",
      "18:\tlearn: 0.4919116\ttotal: 2.09s\tremaining: 8.91s\n",
      "19:\tlearn: 0.4879620\ttotal: 2.21s\tremaining: 8.85s\n",
      "20:\tlearn: 0.4821666\ttotal: 2.34s\tremaining: 8.81s\n",
      "21:\tlearn: 0.4775876\ttotal: 2.46s\tremaining: 8.71s\n",
      "22:\tlearn: 0.4730612\ttotal: 2.56s\tremaining: 8.59s\n",
      "23:\tlearn: 0.4664421\ttotal: 2.67s\tremaining: 8.46s\n",
      "24:\tlearn: 0.4623402\ttotal: 2.78s\tremaining: 8.33s\n",
      "25:\tlearn: 0.4549020\ttotal: 2.89s\tremaining: 8.22s\n",
      "26:\tlearn: 0.4499399\ttotal: 3s\tremaining: 8.1s\n",
      "27:\tlearn: 0.4444091\ttotal: 3.12s\tremaining: 8.03s\n",
      "28:\tlearn: 0.4378247\ttotal: 3.25s\tremaining: 7.95s\n",
      "29:\tlearn: 0.4341165\ttotal: 3.36s\tremaining: 7.83s\n",
      "30:\tlearn: 0.4308772\ttotal: 3.47s\tremaining: 7.73s\n",
      "31:\tlearn: 0.4276622\ttotal: 3.59s\tremaining: 7.64s\n",
      "32:\tlearn: 0.4222988\ttotal: 3.71s\tremaining: 7.54s\n",
      "33:\tlearn: 0.4195770\ttotal: 3.81s\tremaining: 7.41s\n",
      "34:\tlearn: 0.4116941\ttotal: 3.93s\tremaining: 7.3s\n",
      "35:\tlearn: 0.4084249\ttotal: 4.04s\tremaining: 7.18s\n",
      "36:\tlearn: 0.4037213\ttotal: 4.15s\tremaining: 7.07s\n",
      "37:\tlearn: 0.4009725\ttotal: 4.26s\tremaining: 6.95s\n",
      "38:\tlearn: 0.3958523\ttotal: 4.37s\tremaining: 6.83s\n",
      "39:\tlearn: 0.3910326\ttotal: 4.48s\tremaining: 6.72s\n",
      "40:\tlearn: 0.3877366\ttotal: 4.58s\tremaining: 6.6s\n",
      "41:\tlearn: 0.3839181\ttotal: 4.69s\tremaining: 6.48s\n",
      "42:\tlearn: 0.3792898\ttotal: 4.8s\tremaining: 6.37s\n",
      "43:\tlearn: 0.3714559\ttotal: 4.92s\tremaining: 6.26s\n",
      "44:\tlearn: 0.3677754\ttotal: 5.03s\tremaining: 6.15s\n",
      "45:\tlearn: 0.3631111\ttotal: 5.15s\tremaining: 6.04s\n",
      "46:\tlearn: 0.3604666\ttotal: 5.25s\tremaining: 5.93s\n",
      "47:\tlearn: 0.3573750\ttotal: 5.37s\tremaining: 5.81s\n",
      "48:\tlearn: 0.3524964\ttotal: 5.48s\tremaining: 5.7s\n",
      "49:\tlearn: 0.3489689\ttotal: 5.58s\tremaining: 5.58s\n",
      "50:\tlearn: 0.3458680\ttotal: 5.69s\tremaining: 5.47s\n",
      "51:\tlearn: 0.3424909\ttotal: 5.8s\tremaining: 5.36s\n",
      "52:\tlearn: 0.3377504\ttotal: 5.92s\tremaining: 5.25s\n",
      "53:\tlearn: 0.3349251\ttotal: 6.02s\tremaining: 5.13s\n",
      "54:\tlearn: 0.3333568\ttotal: 6.13s\tremaining: 5.02s\n",
      "55:\tlearn: 0.3311296\ttotal: 6.24s\tremaining: 4.91s\n",
      "56:\tlearn: 0.3286122\ttotal: 6.35s\tremaining: 4.79s\n",
      "57:\tlearn: 0.3261358\ttotal: 6.48s\tremaining: 4.69s\n",
      "58:\tlearn: 0.3220682\ttotal: 6.61s\tremaining: 4.59s\n",
      "59:\tlearn: 0.3199818\ttotal: 6.75s\tremaining: 4.5s\n",
      "60:\tlearn: 0.3174252\ttotal: 6.87s\tremaining: 4.39s\n",
      "61:\tlearn: 0.3137929\ttotal: 6.99s\tremaining: 4.28s\n",
      "62:\tlearn: 0.3103883\ttotal: 7.11s\tremaining: 4.17s\n",
      "63:\tlearn: 0.3068205\ttotal: 7.23s\tremaining: 4.07s\n",
      "64:\tlearn: 0.3043301\ttotal: 7.35s\tremaining: 3.96s\n",
      "65:\tlearn: 0.3013856\ttotal: 7.46s\tremaining: 3.84s\n",
      "66:\tlearn: 0.2989138\ttotal: 7.57s\tremaining: 3.73s\n",
      "67:\tlearn: 0.2971331\ttotal: 7.67s\tremaining: 3.61s\n",
      "68:\tlearn: 0.2927424\ttotal: 7.79s\tremaining: 3.5s\n",
      "69:\tlearn: 0.2913681\ttotal: 7.9s\tremaining: 3.38s\n",
      "70:\tlearn: 0.2883564\ttotal: 8.01s\tremaining: 3.27s\n",
      "71:\tlearn: 0.2850805\ttotal: 8.12s\tremaining: 3.16s\n",
      "72:\tlearn: 0.2821312\ttotal: 8.23s\tremaining: 3.04s\n",
      "73:\tlearn: 0.2794015\ttotal: 8.34s\tremaining: 2.93s\n",
      "74:\tlearn: 0.2763179\ttotal: 8.45s\tremaining: 2.82s\n",
      "75:\tlearn: 0.2736204\ttotal: 8.56s\tremaining: 2.7s\n",
      "76:\tlearn: 0.2717741\ttotal: 8.66s\tremaining: 2.59s\n",
      "77:\tlearn: 0.2697902\ttotal: 8.78s\tremaining: 2.48s\n",
      "78:\tlearn: 0.2683760\ttotal: 8.89s\tremaining: 2.36s\n",
      "79:\tlearn: 0.2665646\ttotal: 9s\tremaining: 2.25s\n",
      "80:\tlearn: 0.2637861\ttotal: 9.11s\tremaining: 2.14s\n",
      "81:\tlearn: 0.2613851\ttotal: 9.22s\tremaining: 2.02s\n",
      "82:\tlearn: 0.2598767\ttotal: 9.32s\tremaining: 1.91s\n",
      "83:\tlearn: 0.2580773\ttotal: 9.43s\tremaining: 1.8s\n",
      "84:\tlearn: 0.2558739\ttotal: 9.54s\tremaining: 1.68s\n",
      "85:\tlearn: 0.2532648\ttotal: 9.65s\tremaining: 1.57s\n",
      "86:\tlearn: 0.2522136\ttotal: 9.75s\tremaining: 1.46s\n",
      "87:\tlearn: 0.2501975\ttotal: 9.86s\tremaining: 1.34s\n",
      "88:\tlearn: 0.2487944\ttotal: 9.97s\tremaining: 1.23s\n",
      "89:\tlearn: 0.2470524\ttotal: 10.1s\tremaining: 1.12s\n",
      "90:\tlearn: 0.2453969\ttotal: 10.2s\tremaining: 1.01s\n",
      "91:\tlearn: 0.2438243\ttotal: 10.3s\tremaining: 895ms\n",
      "92:\tlearn: 0.2417065\ttotal: 10.4s\tremaining: 783ms\n",
      "93:\tlearn: 0.2406651\ttotal: 10.5s\tremaining: 671ms\n",
      "94:\tlearn: 0.2391101\ttotal: 10.6s\tremaining: 559ms\n",
      "95:\tlearn: 0.2381809\ttotal: 10.7s\tremaining: 447ms\n",
      "96:\tlearn: 0.2360462\ttotal: 10.8s\tremaining: 335ms\n",
      "97:\tlearn: 0.2349322\ttotal: 10.9s\tremaining: 223ms\n",
      "98:\tlearn: 0.2333464\ttotal: 11s\tremaining: 112ms\n",
      "99:\tlearn: 0.2318541\ttotal: 11.1s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x23e0222d480>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit the classifier with the best hyperparameter set\n",
    "temp_params_dict = space_eval(space, best_search_CatB_2_B)\n",
    "final_params_CatB_2_B = {\n",
    "    'iterations': temp_params_dict['iterations'],\n",
    "    'depth': temp_params_dict['depth'],\n",
    "    'learning_rate': temp_params_dict['learning_rate'],\n",
    "}\n",
    "\n",
    "CatB_clf_2_B = CatBoostClassifier(**final_params_CatB_2_B)\n",
    "CatB_clf_2_B.fit(X_train_prep, y_train_pre_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evalution using Final_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Final_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test_set = Final_test_set_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are potentially 3 possible class labels \n",
    "# 0 = zones without 4 and 5, 1 = zones with only 4 and/or 5, 2 = zones with 4, 5, and other defects\n",
    "Final_test_set[\"long_cat\"] = Final_test_set.apply(lambda x: \n",
    "                                                  0 if \n",
    "                                                  x['defect_4_Type'] == 'A' and x['defect_5_Type'] == 'A'\n",
    "                                                  else 1 if\n",
    "                                                  (x['defect_4_Type'] != 'A' or x['defect_5_Type'] != 'A') and\n",
    "                                                  x['defect_1_Type'] == 'A' and \n",
    "                                                  x['defect_2_Type'] == 'A' and\n",
    "                                                  x['defect_3_Type'] == 'A'\n",
    "                                                  else 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defect_4_Type</th>\n",
       "      <th>defect_5_Type</th>\n",
       "      <th>long_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      defect_4_Type defect_5_Type  long_cat\n",
       "19980             D             D         2\n",
       "19981             C             C         2\n",
       "19982             C             D         2\n",
       "19983             D             A         2\n",
       "19984             A             A         0\n",
       "19985             D             B         2\n",
       "19986             C             C         2\n",
       "19987             D             A         2\n",
       "19988             A             C         2\n",
       "19989             D             B         2\n",
       "19990             A             C         2\n",
       "19991             B             C         2\n",
       "19992             B             C         2\n",
       "19993             A             C         2\n",
       "19994             C             D         2\n",
       "19995             C             B         2\n",
       "19996             A             D         2\n",
       "19997             A             C         2\n",
       "19998             C             B         2\n",
       "19999             C             A         2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_set[['defect_4_Type', 'defect_5_Type', \"long_cat\"]].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reference', 'Lane', 'TailleZone', 'Courbure', 'CourbureVert', 'Vitesse', 'SensMarche', 'Lat_acc_tete_Max', 'Lat_acc_tete_Max_Pos', 'Lat_acc_tete_Max_Pos_Moy', 'Lat_acc_tete_Avg', 'Lat_acc_tete_P2Avg', 'Lat_acc_milieu_Max', 'Lat_acc_milieu_Max_Pos', 'Lat_acc_milieu_Max_Pos_Moy', 'Lat_acc_milieu_Avg', 'Lat_acc_milieu_P2Avg', 'Lat_acc_queue_Max', 'Lat_acc_queue_Max_Pos', 'Lat_acc_queue_Max_Pos_Moy', 'Lat_acc_queue_Avg', 'Lat_acc_queue_P2Avg', 'Vert_acc_tete_Max', 'Vert_acc_tete_Max_Pos', 'Vert_acc_tete_Max_Pos_Moy', 'Vert_acc_tete_Avg', 'Vert_acc_tete_P2Avg', 'Vert_acc_milieu_Max', 'Vert_acc_milieu_Max_Pos', 'Vert_acc_milieu_Max_Pos_Moy', 'Vert_acc_milieu_Avg', 'Vert_acc_milieu_P2Avg', 'Vert_acc_queue_Max', 'Vert_acc_queue_Max_Pos', 'Vert_acc_queue_Max_Pos_Moy', 'Vert_acc_queue_Avg', 'Vert_acc_queue_P2Avg', 'long_cat']\n"
     ]
    }
   ],
   "source": [
    "Final_test_set.drop(['defect_1_Type', 'defect_2_Type', 'defect_3_Type', 'defect_4_Type', 'defect_5_Type']\n",
    "        , axis=1, inplace=True)\n",
    "print(Final_test_set.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Lane</th>\n",
       "      <th>TailleZone</th>\n",
       "      <th>Courbure</th>\n",
       "      <th>CourbureVert</th>\n",
       "      <th>Vitesse</th>\n",
       "      <th>SensMarche</th>\n",
       "      <th>Lat_acc_tete_Max</th>\n",
       "      <th>Lat_acc_tete_Max_Pos</th>\n",
       "      <th>Lat_acc_tete_Max_Pos_Moy</th>\n",
       "      <th>...</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_milieu_Avg</th>\n",
       "      <th>Vert_acc_milieu_P2Avg</th>\n",
       "      <th>Vert_acc_queue_Max</th>\n",
       "      <th>Vert_acc_queue_Max_Pos</th>\n",
       "      <th>Vert_acc_queue_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_queue_Avg</th>\n",
       "      <th>Vert_acc_queue_P2Avg</th>\n",
       "      <th>long_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>V1</td>\n",
       "      <td>57</td>\n",
       "      <td>0.361080</td>\n",
       "      <td>0.667772</td>\n",
       "      <td>42.784620</td>\n",
       "      <td>Backward</td>\n",
       "      <td>0.199304</td>\n",
       "      <td>86.101466</td>\n",
       "      <td>53.291262</td>\n",
       "      <td>...</td>\n",
       "      <td>34.174285</td>\n",
       "      <td>69.285416</td>\n",
       "      <td>0.623076</td>\n",
       "      <td>0.133698</td>\n",
       "      <td>0.947329</td>\n",
       "      <td>49.204398</td>\n",
       "      <td>88.263318</td>\n",
       "      <td>0.829025</td>\n",
       "      <td>0.562602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>V2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>0.226607</td>\n",
       "      <td>78.875969</td>\n",
       "      <td>Forward</td>\n",
       "      <td>0.374129</td>\n",
       "      <td>20.266859</td>\n",
       "      <td>4.396197</td>\n",
       "      <td>...</td>\n",
       "      <td>49.711809</td>\n",
       "      <td>5.246095</td>\n",
       "      <td>0.627604</td>\n",
       "      <td>0.754721</td>\n",
       "      <td>0.869965</td>\n",
       "      <td>27.284191</td>\n",
       "      <td>40.892264</td>\n",
       "      <td>0.267240</td>\n",
       "      <td>0.412599</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>V1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.317336</td>\n",
       "      <td>0.619888</td>\n",
       "      <td>64.251439</td>\n",
       "      <td>Forward</td>\n",
       "      <td>0.993883</td>\n",
       "      <td>73.085978</td>\n",
       "      <td>98.165762</td>\n",
       "      <td>...</td>\n",
       "      <td>40.904775</td>\n",
       "      <td>96.426845</td>\n",
       "      <td>0.885212</td>\n",
       "      <td>0.118836</td>\n",
       "      <td>0.191347</td>\n",
       "      <td>72.548121</td>\n",
       "      <td>1.640065</td>\n",
       "      <td>0.875166</td>\n",
       "      <td>0.223688</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>V1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.200474</td>\n",
       "      <td>0.338707</td>\n",
       "      <td>62.406262</td>\n",
       "      <td>Backward</td>\n",
       "      <td>0.625484</td>\n",
       "      <td>81.790114</td>\n",
       "      <td>51.490684</td>\n",
       "      <td>...</td>\n",
       "      <td>82.637023</td>\n",
       "      <td>65.575102</td>\n",
       "      <td>0.086776</td>\n",
       "      <td>0.563042</td>\n",
       "      <td>0.382124</td>\n",
       "      <td>86.988303</td>\n",
       "      <td>66.646427</td>\n",
       "      <td>0.265282</td>\n",
       "      <td>0.696533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>V2</td>\n",
       "      <td>57</td>\n",
       "      <td>0.981999</td>\n",
       "      <td>0.951780</td>\n",
       "      <td>79.947468</td>\n",
       "      <td>Backward</td>\n",
       "      <td>0.164679</td>\n",
       "      <td>51.436558</td>\n",
       "      <td>29.406334</td>\n",
       "      <td>...</td>\n",
       "      <td>65.758134</td>\n",
       "      <td>70.281101</td>\n",
       "      <td>0.760610</td>\n",
       "      <td>0.192885</td>\n",
       "      <td>0.566601</td>\n",
       "      <td>43.287932</td>\n",
       "      <td>26.527650</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.470470</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reference Lane  TailleZone  Courbure  CourbureVert    Vitesse SensMarche  \\\n",
       "0          2   V1          57  0.361080      0.667772  42.784620   Backward   \n",
       "1          9   V2          70  0.034940      0.226607  78.875969    Forward   \n",
       "2          5   V1          38  0.317336      0.619888  64.251439    Forward   \n",
       "3          1   V1          34  0.200474      0.338707  62.406262   Backward   \n",
       "4          0   V2          57  0.981999      0.951780  79.947468   Backward   \n",
       "\n",
       "   Lat_acc_tete_Max  Lat_acc_tete_Max_Pos  Lat_acc_tete_Max_Pos_Moy  ...  \\\n",
       "0          0.199304             86.101466                 53.291262  ...   \n",
       "1          0.374129             20.266859                  4.396197  ...   \n",
       "2          0.993883             73.085978                 98.165762  ...   \n",
       "3          0.625484             81.790114                 51.490684  ...   \n",
       "4          0.164679             51.436558                 29.406334  ...   \n",
       "\n",
       "   Vert_acc_milieu_Max_Pos  Vert_acc_milieu_Max_Pos_Moy  Vert_acc_milieu_Avg  \\\n",
       "0                34.174285                    69.285416             0.623076   \n",
       "1                49.711809                     5.246095             0.627604   \n",
       "2                40.904775                    96.426845             0.885212   \n",
       "3                82.637023                    65.575102             0.086776   \n",
       "4                65.758134                    70.281101             0.760610   \n",
       "\n",
       "   Vert_acc_milieu_P2Avg  Vert_acc_queue_Max  Vert_acc_queue_Max_Pos  \\\n",
       "0               0.133698            0.947329               49.204398   \n",
       "1               0.754721            0.869965               27.284191   \n",
       "2               0.118836            0.191347               72.548121   \n",
       "3               0.563042            0.382124               86.988303   \n",
       "4               0.192885            0.566601               43.287932   \n",
       "\n",
       "   Vert_acc_queue_Max_Pos_Moy  Vert_acc_queue_Avg  Vert_acc_queue_P2Avg  \\\n",
       "0                   88.263318            0.829025              0.562602   \n",
       "1                   40.892264            0.267240              0.412599   \n",
       "2                    1.640065            0.875166              0.223688   \n",
       "3                   66.646427            0.265282              0.696533   \n",
       "4                   26.527650            0.346010              0.470470   \n",
       "\n",
       "   long_cat  \n",
       "0         2  \n",
       "1         2  \n",
       "2         2  \n",
       "3         2  \n",
       "4         2  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make prediction with classifier 2-A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if there is any column that is not numeric \n",
    "Final_test_set_cat = Final_test_set.select_dtypes(exclude=[np.number])\n",
    "#Final_test_set_cat.head()\n",
    "\n",
    "# Add categorical columns that are number manually can convert them to categorical type\n",
    "Final_test_set[other_cat_col] = Final_test_set[other_cat_col].astype(\"category\")\n",
    "#df[other_cat_col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test_set_cat_encoded = ordinal_encoder.fit_transform(Final_test_set_cat)\n",
    "#print(df_cat_encoded)\n",
    "\n",
    "Final_test_set[Final_test_set_cat.columns.tolist()] = Final_test_set_cat_encoded\n",
    "Final_test_set[df_cat.columns.tolist()] = Final_test_set[Final_test_set_cat.columns.tolist()].astype(\"category\")\n",
    "#df[df_cat.columns.tolist()].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test_2_A = Final_test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test_2_A[\"long_cat\"] = Final_test_2_A.apply(lambda x:\n",
    "                                                  0 if\n",
    "                                                  x[\"long_cat\"] == 0\n",
    "                                                  else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18734\n",
       "0     1266\n",
       "Name: long_cat, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_2_A[\"long_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Final_test_2_A = Final_test_2_A.drop(\"long_cat\", axis=1)\n",
    "y_Final_test_2_A = Final_test_2_A[\"long_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components:  13\n",
      "shape after transformation:  (20000, 13)\n"
     ]
    }
   ],
   "source": [
    "#Transform the X_test as the train set has been transformed\n",
    "X_Final_test_2_A_prep = full_pl.transform(X_Final_test_2_A)\n",
    "#print('shape before PCA: ', X_train_prep.shape)\n",
    "\n",
    "if use_PCA:\n",
    "    X_Final_test_2_A_prep = pca.transform(X_Final_test_2_A_prep)\n",
    "    print('number of components: ', pca.n_components_)\n",
    "\n",
    "print('shape after transformation: ', X_Final_test_2_A_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Final_test_2_A_pred = voting_clf.predict(X_Final_test_2_A_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test_set[\"2_A_label\"] = y_Final_test_2_A_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_cat</th>\n",
       "      <th>2_A_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_cat  2_A_label\n",
       "0         2          1\n",
       "1         2          1\n",
       "2         2          1\n",
       "3         2          1\n",
       "4         2          1\n",
       "5         2          1\n",
       "6         2          1\n",
       "7         2          1\n",
       "8         2          1\n",
       "9         2          1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_set[[\"long_cat\", \"2_A_label\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare a set for 2-B by only keeping the rows that 2-A predict as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of rows with 2_A_label = 1\n",
    "labe_1_by_2_A_ind = Final_test_set[Final_test_set[\"2_A_label\"] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Lane</th>\n",
       "      <th>TailleZone</th>\n",
       "      <th>Courbure</th>\n",
       "      <th>CourbureVert</th>\n",
       "      <th>Vitesse</th>\n",
       "      <th>SensMarche</th>\n",
       "      <th>Lat_acc_tete_Max</th>\n",
       "      <th>Lat_acc_tete_Max_Pos</th>\n",
       "      <th>Lat_acc_tete_Max_Pos_Moy</th>\n",
       "      <th>...</th>\n",
       "      <th>Vert_acc_milieu_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_milieu_Avg</th>\n",
       "      <th>Vert_acc_milieu_P2Avg</th>\n",
       "      <th>Vert_acc_queue_Max</th>\n",
       "      <th>Vert_acc_queue_Max_Pos</th>\n",
       "      <th>Vert_acc_queue_Max_Pos_Moy</th>\n",
       "      <th>Vert_acc_queue_Avg</th>\n",
       "      <th>Vert_acc_queue_P2Avg</th>\n",
       "      <th>long_cat</th>\n",
       "      <th>2_A_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.361080</td>\n",
       "      <td>0.667772</td>\n",
       "      <td>42.784620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199304</td>\n",
       "      <td>86.101466</td>\n",
       "      <td>53.291262</td>\n",
       "      <td>...</td>\n",
       "      <td>69.285416</td>\n",
       "      <td>0.623076</td>\n",
       "      <td>0.133698</td>\n",
       "      <td>0.947329</td>\n",
       "      <td>49.204398</td>\n",
       "      <td>88.263318</td>\n",
       "      <td>0.829025</td>\n",
       "      <td>0.562602</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>0.226607</td>\n",
       "      <td>78.875969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374129</td>\n",
       "      <td>20.266859</td>\n",
       "      <td>4.396197</td>\n",
       "      <td>...</td>\n",
       "      <td>5.246095</td>\n",
       "      <td>0.627604</td>\n",
       "      <td>0.754721</td>\n",
       "      <td>0.869965</td>\n",
       "      <td>27.284191</td>\n",
       "      <td>40.892264</td>\n",
       "      <td>0.267240</td>\n",
       "      <td>0.412599</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.317336</td>\n",
       "      <td>0.619888</td>\n",
       "      <td>64.251439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993883</td>\n",
       "      <td>73.085978</td>\n",
       "      <td>98.165762</td>\n",
       "      <td>...</td>\n",
       "      <td>96.426845</td>\n",
       "      <td>0.885212</td>\n",
       "      <td>0.118836</td>\n",
       "      <td>0.191347</td>\n",
       "      <td>72.548121</td>\n",
       "      <td>1.640065</td>\n",
       "      <td>0.875166</td>\n",
       "      <td>0.223688</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.200474</td>\n",
       "      <td>0.338707</td>\n",
       "      <td>62.406262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625484</td>\n",
       "      <td>81.790114</td>\n",
       "      <td>51.490684</td>\n",
       "      <td>...</td>\n",
       "      <td>65.575102</td>\n",
       "      <td>0.086776</td>\n",
       "      <td>0.563042</td>\n",
       "      <td>0.382124</td>\n",
       "      <td>86.988303</td>\n",
       "      <td>66.646427</td>\n",
       "      <td>0.265282</td>\n",
       "      <td>0.696533</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.981999</td>\n",
       "      <td>0.951780</td>\n",
       "      <td>79.947468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164679</td>\n",
       "      <td>51.436558</td>\n",
       "      <td>29.406334</td>\n",
       "      <td>...</td>\n",
       "      <td>70.281101</td>\n",
       "      <td>0.760610</td>\n",
       "      <td>0.192885</td>\n",
       "      <td>0.566601</td>\n",
       "      <td>43.287932</td>\n",
       "      <td>26.527650</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.470470</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>0.340242</td>\n",
       "      <td>91.292008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162891</td>\n",
       "      <td>39.667452</td>\n",
       "      <td>83.503912</td>\n",
       "      <td>...</td>\n",
       "      <td>59.280922</td>\n",
       "      <td>0.345038</td>\n",
       "      <td>0.358576</td>\n",
       "      <td>0.676241</td>\n",
       "      <td>1.121272</td>\n",
       "      <td>97.582646</td>\n",
       "      <td>0.990036</td>\n",
       "      <td>0.937724</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0.221809</td>\n",
       "      <td>0.350122</td>\n",
       "      <td>1.176228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.773083</td>\n",
       "      <td>9.487551</td>\n",
       "      <td>74.823904</td>\n",
       "      <td>...</td>\n",
       "      <td>96.158863</td>\n",
       "      <td>0.980125</td>\n",
       "      <td>0.379650</td>\n",
       "      <td>0.887111</td>\n",
       "      <td>0.648284</td>\n",
       "      <td>25.688579</td>\n",
       "      <td>0.419368</td>\n",
       "      <td>0.267067</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.781347</td>\n",
       "      <td>0.534775</td>\n",
       "      <td>20.448426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678179</td>\n",
       "      <td>36.859531</td>\n",
       "      <td>48.950564</td>\n",
       "      <td>...</td>\n",
       "      <td>22.351253</td>\n",
       "      <td>0.988655</td>\n",
       "      <td>0.552214</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>99.585715</td>\n",
       "      <td>27.450900</td>\n",
       "      <td>0.768363</td>\n",
       "      <td>0.894815</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.963978</td>\n",
       "      <td>0.420489</td>\n",
       "      <td>75.922683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842887</td>\n",
       "      <td>59.764095</td>\n",
       "      <td>49.930566</td>\n",
       "      <td>...</td>\n",
       "      <td>34.424101</td>\n",
       "      <td>0.239184</td>\n",
       "      <td>0.808981</td>\n",
       "      <td>0.281436</td>\n",
       "      <td>56.201193</td>\n",
       "      <td>70.498061</td>\n",
       "      <td>0.861603</td>\n",
       "      <td>0.946083</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.336808</td>\n",
       "      <td>0.177003</td>\n",
       "      <td>2.583254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768602</td>\n",
       "      <td>8.540256</td>\n",
       "      <td>1.243483</td>\n",
       "      <td>...</td>\n",
       "      <td>15.222537</td>\n",
       "      <td>0.092987</td>\n",
       "      <td>0.778047</td>\n",
       "      <td>0.152267</td>\n",
       "      <td>84.862791</td>\n",
       "      <td>44.862440</td>\n",
       "      <td>0.454219</td>\n",
       "      <td>0.757580</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reference Lane  TailleZone  Courbure  CourbureVert    Vitesse SensMarche  \\\n",
       "0         2  0.0          57  0.361080      0.667772  42.784620        0.0   \n",
       "1         9  1.0          70  0.034940      0.226607  78.875969        1.0   \n",
       "2         5  0.0          38  0.317336      0.619888  64.251439        1.0   \n",
       "3         1  0.0          34  0.200474      0.338707  62.406262        0.0   \n",
       "4         0  1.0          57  0.981999      0.951780  79.947468        0.0   \n",
       "5         9  0.0          55  0.124518      0.340242  91.292008        0.0   \n",
       "6         7  1.0          75  0.221809      0.350122   1.176228        0.0   \n",
       "7         7  1.0          17  0.781347      0.534775  20.448426        0.0   \n",
       "8         2  0.0          56  0.963978      0.420489  75.922683        0.0   \n",
       "9         3  0.0          14  0.336808      0.177003   2.583254        0.0   \n",
       "\n",
       "   Lat_acc_tete_Max  Lat_acc_tete_Max_Pos  Lat_acc_tete_Max_Pos_Moy  ...  \\\n",
       "0          0.199304             86.101466                 53.291262  ...   \n",
       "1          0.374129             20.266859                  4.396197  ...   \n",
       "2          0.993883             73.085978                 98.165762  ...   \n",
       "3          0.625484             81.790114                 51.490684  ...   \n",
       "4          0.164679             51.436558                 29.406334  ...   \n",
       "5          0.162891             39.667452                 83.503912  ...   \n",
       "6          0.773083              9.487551                 74.823904  ...   \n",
       "7          0.678179             36.859531                 48.950564  ...   \n",
       "8          0.842887             59.764095                 49.930566  ...   \n",
       "9          0.768602              8.540256                  1.243483  ...   \n",
       "\n",
       "   Vert_acc_milieu_Max_Pos_Moy  Vert_acc_milieu_Avg  Vert_acc_milieu_P2Avg  \\\n",
       "0                    69.285416             0.623076               0.133698   \n",
       "1                     5.246095             0.627604               0.754721   \n",
       "2                    96.426845             0.885212               0.118836   \n",
       "3                    65.575102             0.086776               0.563042   \n",
       "4                    70.281101             0.760610               0.192885   \n",
       "5                    59.280922             0.345038               0.358576   \n",
       "6                    96.158863             0.980125               0.379650   \n",
       "7                    22.351253             0.988655               0.552214   \n",
       "8                    34.424101             0.239184               0.808981   \n",
       "9                    15.222537             0.092987               0.778047   \n",
       "\n",
       "   Vert_acc_queue_Max  Vert_acc_queue_Max_Pos  Vert_acc_queue_Max_Pos_Moy  \\\n",
       "0            0.947329               49.204398                   88.263318   \n",
       "1            0.869965               27.284191                   40.892264   \n",
       "2            0.191347               72.548121                    1.640065   \n",
       "3            0.382124               86.988303                   66.646427   \n",
       "4            0.566601               43.287932                   26.527650   \n",
       "5            0.676241                1.121272                   97.582646   \n",
       "6            0.887111                0.648284                   25.688579   \n",
       "7            0.999397               99.585715                   27.450900   \n",
       "8            0.281436               56.201193                   70.498061   \n",
       "9            0.152267               84.862791                   44.862440   \n",
       "\n",
       "   Vert_acc_queue_Avg  Vert_acc_queue_P2Avg  long_cat  2_A_label  \n",
       "0            0.829025              0.562602         2          1  \n",
       "1            0.267240              0.412599         2          1  \n",
       "2            0.875166              0.223688         2          1  \n",
       "3            0.265282              0.696533         2          1  \n",
       "4            0.346010              0.470470         2          1  \n",
       "5            0.990036              0.937724         2          1  \n",
       "6            0.419368              0.267067         2          1  \n",
       "7            0.768363              0.894815         2          1  \n",
       "8            0.861603              0.946083         2          1  \n",
       "9            0.454219              0.757580         2          1  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_set.iloc[labe_1_by_2_A_ind].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14831\n",
       "Name: 2_A_label, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_2_B = Final_test_set.iloc[labe_1_by_2_A_ind,:]\n",
    "\n",
    "Final_test_2_B[\"2_A_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make prediction with classifier 2-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\9112325B\\AppData\\Local\\Temp\\ipykernel_7116\\2566539846.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Final_test_2_B[\"other_cat\"] = Final_test_2_B.apply(lambda x:\n"
     ]
    }
   ],
   "source": [
    "# Using this code, zones with long only = 0, and zones with only long and other and **zones without long = 1 \n",
    "Final_test_2_B[\"other_cat\"] = Final_test_2_B.apply(lambda x:\n",
    "                                                   0 if\n",
    "                                                   x[\"long_cat\"] == 1 or  x[\"long_cat\"] == 0\n",
    "                                                   else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_cat</th>\n",
       "      <th>2_A_label</th>\n",
       "      <th>other_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19977</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19978</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       long_cat  2_A_label  other_cat\n",
       "19972         2          1          1\n",
       "19973         2          1          1\n",
       "19974         2          1          1\n",
       "19975         2          1          1\n",
       "19977         2          1          1\n",
       "19978         2          1          1\n",
       "19980         2          1          1\n",
       "19982         2          1          1\n",
       "19983         2          1          1\n",
       "19984         0          1          0\n",
       "19985         2          1          1\n",
       "19986         2          1          1\n",
       "19988         2          1          1\n",
       "19989         2          1          1\n",
       "19990         2          1          1\n",
       "19991         2          1          1\n",
       "19992         2          1          1\n",
       "19995         2          1          1\n",
       "19996         2          1          1\n",
       "19997         2          1          1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_2_B[[\"long_cat\",\"2_A_label\",\"other_cat\"]].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Final_test_2_B = Final_test_2_B.drop([\"other_cat\", \"long_cat\", \"2_A_label\"], axis=1)\n",
    "y_Final_test_2_B = Final_test_2_B[\"other_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components:  14\n",
      "shape after transformation:  (14831, 14)\n"
     ]
    }
   ],
   "source": [
    "#Transform the X_test as the train set has been transformed\n",
    "X_Final_test_2_B_prep = full_pl_2_B.transform(X_Final_test_2_B)\n",
    "#print('shape before PCA: ', X_train_prep.shape)\n",
    "\n",
    "if use_PCA:\n",
    "    X_Final_test_2_B_prep = pca_2_B.transform(X_Final_test_2_B_prep)\n",
    "    print('number of components: ', pca_2_B.n_components_)\n",
    "\n",
    "print('shape after transformation: ', X_Final_test_2_B_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Final_test_2_B_pred = CatB_clf_2_B.predict(X_Final_test_2_B_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Final_test_2_B_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Final_test_2_B_pred_2 = y_Final_test_2_B_pred.copy()\n",
    "y_Final_test_2_B_pred_2[y_Final_test_2_B_pred_2 == 1] = 2\n",
    "y_Final_test_2_B_pred_2[y_Final_test_2_B_pred_2 == 0] = 1 \n",
    "y_Final_test_2_B_pred_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Integrate the prediction back to Final_test_set and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final_test_set[[\"2_B_label\"]] = 0\n",
    "Final_test_set.iloc[labe_1_by_2_A_ind, -1] = y_Final_test_2_B_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_cat</th>\n",
       "      <th>2_A_label</th>\n",
       "      <th>2_B_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19985</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19986</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19988</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19989</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       long_cat  2_A_label  2_B_label\n",
       "19980         2          1          2\n",
       "19981         2          0          0\n",
       "19982         2          1          2\n",
       "19983         2          1          2\n",
       "19984         0          1          2\n",
       "19985         2          1          2\n",
       "19986         2          1          2\n",
       "19987         2          0          0\n",
       "19988         2          1          2\n",
       "19989         2          1          2\n",
       "19990         2          1          2\n",
       "19991         2          1          2\n",
       "19992         2          1          2\n",
       "19993         2          0          0\n",
       "19994         2          0          0\n",
       "19995         2          1          2\n",
       "19996         2          1          2\n",
       "19997         2          1          2\n",
       "19998         2          0          0\n",
       "19999         2          0          0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_set[[\"long_cat\", \"2_A_label\", \"2_B_label\"]].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_evaluate_plot(y_test, y_pred, n_class = 2):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Define class names\n",
    "    if n_class == 2:\n",
    "        classes = ['Class 0', 'Class 1']\n",
    "    elif n_class == 3:\n",
    "        classes = ['Class 0', 'Class 1', 'Class 2']\n",
    "    else:\n",
    "        sys.exit(\"n_class can only be 2 or 3\")\n",
    "    \n",
    "    # Define plot parameters\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\", xticklabels=classes, yticklabels=classes, annot_kws={\"fontsize\":16})\n",
    "    \n",
    "    # Set plot labels\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"====================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-A performance evaluation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.26      0.10      1266\n",
      "           1       0.94      0.74      0.83     18734\n",
      "\n",
      "    accuracy                           0.71     20000\n",
      "   macro avg       0.50      0.50      0.46     20000\n",
      "weighted avg       0.88      0.71      0.78     20000\n",
      "\n",
      "====================================================================================\n",
      "2-B performance evaluation\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAHFCAYAAAA+FskAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbxklEQVR4nO3de1xP9x8H8Nfp9u2ivrqoRAhpUuausGlzJ7GbS9bYEpvbWq7NkF1KtsnIbZjM0Gxkrs0lbKZIybUxEzGlkJB0Pb8/+nW2r4rK+fr2zev5eJzHo87nc855f79bevf+XL6CKIoiiIiIiGo4HU0HQERERFQZTFqIiIhIKzBpISIiIq3ApIWIiIi0ApMWIiIi0gpMWoiIiEgrMGkhIiIircCkhYiIiLQCkxYiIiLSCkxaqFY7deoU3n33XTg4OMDQ0BB16tRBu3btMH/+fNy+fVutzz5x4gS6d+8OpVIJQRCwcOFC2Z8hCAKCgoJkv++TREREQBAECIKAgwcPlmkXRRHNmzeHIAjw8PCo1jOWLl2KiIiIKl1z8ODBCmMiIu2np+kAiNRl5cqVGDduHJycnDB16lQ4OzujoKAAx48fx/LlyxEbG4uoqCi1Pf+9995DTk4OIiMjYW5ujiZNmsj+jNjYWDRs2FD2+1aWqakpVq9eXSYxOXToEP7++2+YmppW+95Lly6FlZUVRo0aVelr2rVrh9jYWDg7O1f7uURUczFpoVopNjYWH3zwAXr16oWtW7dCoVBIbb169cLkyZMRHR2t1hjOnDkDPz8/9OvXT23PcHNzU9u9K2Po0KFYv349lixZAjMzM+n86tWr4e7ujrt37z6TOAoKCiAIAszMzDT+nhCR+nB4iGql4OBgCIKAb7/9ViVhKWVgYAAvLy/p++LiYsyfPx8vvPACFAoFrK2t8c477+DatWsq13l4eMDFxQXx8fF46aWXYGxsjKZNm2LevHkoLi4G8O/QSWFhIZYtWyYNowBAUFCQ9PV/lV5z+fJl6VxMTAw8PDxgaWkJIyMjNGrUCG+88QYePHgg9SlveOjMmTMYNGgQzM3NYWhoiDZt2mDt2rUqfUqHUTZu3IiZM2fCzs4OZmZm6NmzJ86fP1+5NxnA8OHDAQAbN26UzmVnZ2Pz5s147733yr1m7ty56Ny5MywsLGBmZoZ27dph9erV+O9ntzZp0gRnz57FoUOHpPevtFJVGvu6deswefJkNGjQAAqFAhcvXiwzPHTz5k3Y29ujS5cuKCgokO5/7tw5mJiYwMfHp9KvlYg0j0kL1TpFRUWIiYlB+/btYW9vX6lrPvjgA0yfPh29evXCtm3b8NlnnyE6OhpdunTBzZs3Vfqmp6djxIgRePvtt7Ft2zb069cPgYGB+OGHHwAAAwYMQGxsLADgzTffRGxsrPR9ZV2+fBkDBgyAgYEBvvvuO0RHR2PevHkwMTFBfn5+hdedP38eXbp0wdmzZ7Fo0SJs2bIFzs7OGDVqFObPn1+m/8cff4wrV65g1apV+Pbbb/HXX39h4MCBKCoqqlScZmZmePPNN/Hdd99J5zZu3AgdHR0MHTq0wtc2duxYbNq0CVu2bMHrr7+OiRMn4rPPPpP6REVFoWnTpmjbtq30/j06lBcYGIjU1FQsX74c27dvh7W1dZlnWVlZITIyEvHx8Zg+fToA4MGDB3jrrbfQqFEjLF++vFKvk4hqCJGolklPTxcBiMOGDatU/+TkZBGAOG7cOJXzR48eFQGIH3/8sXSue/fuIgDx6NGjKn2dnZ3FPn36qJwDII4fP17l3Jw5c8TyfuzWrFkjAhBTUlJEURTFn3/+WQQgJiUlPTZ2AOKcOXOk74cNGyYqFAoxNTVVpV+/fv1EY2Nj8c6dO6IoiuKBAwdEAGL//v1V+m3atEkEIMbGxj72uaXxxsfHS/c6c+aMKIqi2LFjR3HUqFGiKIpiq1atxO7du1d4n6KiIrGgoED89NNPRUtLS7G4uFhqq+ja0ue9/PLLFbYdOHBA5XxoaKgIQIyKihJHjhwpGhkZiadOnXrsaySimoeVFnruHThwAADKTPjs1KkTWrZsif3796uct7W1RadOnVTOtW7dGleuXJEtpjZt2sDAwABjxozB2rVrcenSpUpdFxMTgx49epSpMI0aNQoPHjwoU/H57xAZUPI6AFTptXTv3h3NmjXDd999h9OnTyM+Pr7CoaHSGHv27AmlUgldXV3o6+tj9uzZuHXrFjIyMir93DfeeKPSfadOnYoBAwZg+PDhWLt2LRYvXgxXV9dKX09ENQOTFqp1rKysYGxsjJSUlEr1v3XrFgCgfv36Zdrs7Oyk9lKWlpZl+ikUCuTm5lYj2vI1a9YM+/btg7W1NcaPH49mzZqhWbNm+Oabbx573a1btyp8HaXt//Xoaymd/1OV1yIIAt5991388MMPWL58OVq0aIGXXnqp3L7Hjh1D7969AZSs7vrjjz8QHx+PmTNnVvm55b3Ox8U4atQoPHz4ELa2tpzLQqSlmLRQraOrq4sePXogISGhzETa8pT+4k5LSyvTdv36dVhZWckWm6GhIQAgLy9P5fyj82YA4KWXXsL27duRnZ2NuLg4uLu7w9/fH5GRkRXe39LSssLXAUDW1/Jfo0aNws2bN7F8+XK8++67FfaLjIyEvr4+duzYgSFDhqBLly7o0KFDtZ5Z3oTmiqSlpWH8+PFo06YNbt26hSlTplTrmUSkWUxaqFYKDAyEKIrw8/Mrd+JqQUEBtm/fDgB49dVXAUCaSFsqPj4eycnJ6NGjh2xxla6AOXXqlMr50ljKo6uri86dO2PJkiUAgMTExAr79ujRAzExMVKSUur777+HsbGx2pYDN2jQAFOnTsXAgQMxcuTICvsJggA9PT3o6upK53Jzc7Fu3boyfeWqXhUVFWH48OEQBAG7d+9GSEgIFi9ejC1btjz1vYno2eI+LVQrubu7Y9myZRg3bhzat2+PDz74AK1atUJBQQFOnDiBb7/9Fi4uLhg4cCCcnJwwZswYLF68GDo6OujXrx8uX76MWbNmwd7eHh999JFscfXv3x8WFhbw9fXFp59+Cj09PURERODq1asq/ZYvX46YmBgMGDAAjRo1wsOHD6UVOj179qzw/nPmzMGOHTvwyiuvYPbs2bCwsMD69euxc+dOzJ8/H0qlUrbX8qh58+Y9sc+AAQOwYMECeHt7Y8yYMbh16xa++uqrcpelu7q6IjIyEj/++COaNm0KQ0PDas1DmTNnDn7//Xfs2bMHtra2mDx5Mg4dOgRfX1+0bdsWDg4OVb4nEWkGkxaqtfz8/NCpUyeEhYUhNDQU6enp0NfXR4sWLeDt7Y0JEyZIfZctW4ZmzZph9erVWLJkCZRKJfr27YuQkJBy57BUl5mZGaKjo+Hv74+3334bdevWxejRo9GvXz+MHj1a6temTRvs2bMHc+bMQXp6OurUqQMXFxds27ZNmhNSHicnJxw5cgQff/wxxo8fj9zcXLRs2RJr1qyp0s6y6vLqq6/iu+++Q2hoKAYOHIgGDRrAz88P1tbW8PX1Vek7d+5cpKWlwc/PD/fu3UPjxo1V9rGpjL179yIkJASzZs1SqZhFRESgbdu2GDp0KA4fPgwDAwM5Xh4RqZkgiv/Z0YmIiIiohuKcFiIiItIKTFqIiIhIKzBpISIiIq3ApIWIiIi0ApMWIiIi0gpMWoiIiEgrMGkhIiIirVBLN5e7oOkAiGqk+wXXn9yJ6DlTR99D7c8wajRclvvkpm6U5T7aipUWIiIi0gq1tNJCRERUcwgCawRyYNJCRESkZgIHNmTBpIWIiEjNWGmRB99FIiIi0gqstBAREakZKy3yYNJCRESkZoIgaDqEWoGpHxEREWkFVlqIiIjUjjUCOTBpISIiUjPOaZEH30UiIiLSCqy0EBERqRkrLfJg0kJERKRm3BFXHnwXiYiISCuw0kJERKRmHB6SB5MWIiIiNWPSIg8mLURERGrGpEUefBeJiIhIK7DSQkREpGYC+NlDcmDSQkREpGYcHpIH30UiIqJa6rfffsPAgQNhZ2cHQRCwdetWqa2goADTp0+Hq6srTExMYGdnh3feeQfXr19XuUdeXh4mTpwIKysrmJiYwMvLC9euXVPpk5WVBR8fHyiVSiiVSvj4+ODOnTsqfVJTUzFw4ECYmJjAysoKkyZNQn5+fpVeD5MWIiIiNRMEHVmOqsrJycGLL76I8PDwMm0PHjxAYmIiZs2ahcTERGzZsgUXLlyAl5eXSj9/f39ERUUhMjIShw8fxv379+Hp6YmioiKpj7e3N5KSkhAdHY3o6GgkJSXBx8dHai8qKsKAAQOQk5ODw4cPIzIyEps3b8bkyZOr9HoEURTFKr4HWuCCpgMgqpHuF1x/ciei50wdfQ+1P8PWebos90k/F1rtawVBQFRUFAYPHlxhn/j4eHTq1AlXrlxBo0aNkJ2djXr16mHdunUYOnQoAOD69euwt7fHrl270KdPHyQnJ8PZ2RlxcXHo3LkzACAuLg7u7u74888/4eTkhN27d8PT0xNXr16FnZ0dACAyMhKjRo1CRkYGzMzMKvUaWGkhIiIiAEB2djYEQUDdunUBAAkJCSgoKEDv3r2lPnZ2dnBxccGRI0cAALGxsVAqlVLCAgBubm5QKpUqfVxcXKSEBQD69OmDvLw8JCQkVDo+TsQlIiJSO3lqBHl5ecjLy1M5p1AooFAonvreDx8+xIwZM+Dt7S1VPtLT02FgYABzc3OVvjY2NkhPT5f6WFtbl7mftbW1Sh8bGxuVdnNzcxgYGEh9KoOVFiIiIjWTa05LSEiINNm19AgJCXnq+AoKCjBs2DAUFxdj6dKlT+wviiIE4d9l3P/9+mn6PAmTFiIiIi0RGBiI7OxslSMwMPCp7llQUIAhQ4YgJSUFe/fuVZlfYmtri/z8fGRlZalck5GRIVVObG1tcePGjTL3zczMVOnzaEUlKysLBQUFZSowj8OkhYiISM3kqrQoFAqYmZmpHE8zNFSasPz111/Yt28fLC0tVdrbt28PfX197N27VzqXlpaGM2fOoEuXLgAAd3d3ZGdn49ixY1Kfo0ePIjs7W6XPmTNnkJaWJvXZs2cPFAoF2rdvX+l4OaeFiIhIzQQN1Qju37+PixcvSt+npKQgKSkJFhYWsLOzw5tvvonExETs2LEDRUVFUjXEwsICBgYGUCqV8PX1xeTJk2FpaQkLCwtMmTIFrq6u6NmzJwCgZcuW6Nu3L/z8/LBixQoAwJgxY+Dp6QknJycAQO/eveHs7AwfHx98+eWXuH37NqZMmQI/P79KrxwCuOSZ6LnCJc9EZT2LJc8NXefKcp9rp+dUqf/BgwfxyiuvlDk/cuRIBAUFwcHBodzrDhw4AA8PDwAlE3SnTp2KDRs2IDc3Fz169MDSpUthb28v9b99+zYmTZqEbdu2AQC8vLwQHh4urUICSjaXGzduHGJiYmBkZARvb2989dVXVaoUMWkheo4waSEqqzYnLbUNh4eIiIjUrCorZKhiTFqIiIjUjB+YKA++i0RERKQVWGkhIiJSM02tHqptmLQQERGpGYeH5MF3kYiIiLQCKy1ERERqxkqLPJi0EBERqRnntMiD7yIRERFpBVZaiIiI1I3DQ7Jg0kJERKRmnNMiDyYtREREasZt/OXB1I+IiIi0AistREREasbVQ/Jg0kJERKRmnNMiD76LREREpBVYaSEiIlI3TsSVBZMWIiIideO4hiz4NhIREZFWYKWFiIhI3Tg8JAsmLUREROrGpEUWHB4iIiIircBKCxERkbqxRCALJi1ERERqJnJ4SBZMWoiIiNSNOYssWLAiIiIircBKCxERkbrpsNQiByYtRERE6sY5LbLg8BARERFpBVZaiIiI1I2FFlkwaSEiIlI3zmmRBYeHiIiISCuw0kJERKRunIgrCyYtRERE6sacRRYcHiIiIiKtwEoLERGRunEiriyYtBAREakbcxZZMGkhIiJSM37Kszw0mrTk5ORgw4YNOHLkCNLT0yEIAmxsbNC1a1cMHz4cJiYmmgyPiIiIahCNTcQ9d+4cWrRogWnTpiErKwuNGjVCw4YNkZWVhalTp8LJyQnnzp3TVHhERETy0RHkOZ5zGqu0jB8/Hi+//DLWrl0LAwMDlbb8/HyMGjUK48ePx4EDBzQUIRERkUyYb8hCY0nL0aNHcfz48TIJCwAYGBjg448/RqdOnTQQGREREdVEGhseMjc3x19//VVh+8WLF2Fubv4MIyIiIlITQZDneM5prNLi5+eHkSNH4pNPPkGvXr1gY2MDQRCQnp6OvXv3Ijg4GP7+/poKj4iISD6cjyILjSUtQUFBMDIywoIFCzBt2jQI/88gRVGEra0tZsyYgWnTpmkqPCIiIqphBFEURU0HkZKSgvT0dACAra0tHBwcnvKOF54+KKJa6H7BdU2HQFTj1NH3UPszmr/2vSz3uRj1jiz30VY1YnM5BwcHGRIVIiKiGorzUWTBD0wkIiKqpX777TcMHDgQdnZ2EAQBW7duVWkXRRFBQUGws7ODkZERPDw8cPbsWZU+eXl5mDhxIqysrGBiYgIvLy9cu3ZNpU9WVhZ8fHygVCqhVCrh4+ODO3fuqPRJTU3FwIEDYWJiAisrK0yaNAn5+flVej1MWoiIiNRNQ6uHcnJy8OKLLyI8PLzc9vnz52PBggUIDw9HfHw8bG1t0atXL9y7d0/q4+/vj6ioKERGRuLw4cO4f/8+PD09UVRUJPXx9vZGUlISoqOjER0djaSkJPj4+EjtRUVFGDBgAHJycnD48GFERkZi8+bNmDx5cpVeT42Y0yI/zmkhKg/ntBCV9UzmtLz1gyz3ufjT29W+VhAEREVFYfDgwQBKqix2dnbw9/fH9OnTAZRUVWxsbBAaGoqxY8ciOzsb9erVw7p16zB06FAAwPXr12Fvb49du3ahT58+SE5OhrOzM+Li4tC5c2cAQFxcHNzd3fHnn3/CyckJu3fvhqenJ65evQo7OzsAQGRkJEaNGoWMjAyYmZlV6jXUiDktpN3CwtZh+fJNAIAPP3wb48YNVWl3chpYqfvMm+eP117rIXt8RFXxz7WbOBqXjLOnL+Ps6cu49Pd1FBUV44OJXhg9dkC519y8mY24P87h7JmSay6cv4aCgkIMer0rZn9a8cTJK5dvYP/eRBw/dh4XL/yDO9n3YWJsCEenhvD0coPnIHfo6JQtiN9Iz8L+vQk4Fvcnzv95Fbdv3YPCUB9Nm9VHrz4d8Naw7jAw0JftPSEZyDSnJS8vD3l5eSrnFAoFFApFle9Vugimd+/eKvfq3r07jhw5grFjxyIhIQEFBQUqfezs7ODi4oIjR46gT58+iI2NhVKplBIWAHBzc4NSqcSRI0fg5OSE2NhYuLi4SAkLAPTp0wd5eXlISEjAK6+8UqmYNZ60REdHo06dOujWrRsAYMmSJVi5ciWcnZ2xZMkSbjBXw/3991WsXr3lsX3atWtZYdvdu/dx8eJVAMCLLzrJGhtRdWz8YT82/hBTpWv27I7H16E/VemaoqJivO45W/rexsYcTk72SE+7jYT4C0iIv4Bfdx/HgsXjoFCoJiDvjgjFjRtZAABLSzO0cGqImzezcfpkCk6fTMHObXFYusofdevWqVJMVPOFhIRg7ty5KufmzJmDoKCgKt+rdNWujY2NynkbGxtcuXJF6mNgYFDmd7GNjY10fXp6Oqytrcvc39raWqXPo88xNzeHgYGB1KcyNJ60TJ06FaGhoQCA06dPY/LkyQgICEBMTAwCAgKwZs0aDUdIFRFFEbNnL4G+vh7at3dGXNypcvtt3Di/wnuEha3DxYtX0bp1CzRt2lBdoRJVWl3zOnipuytauTqglUtjbN38B/bvTXzsNSYmRujs3hIurk3QytUBR2OT8eOGx39umiiKMDUzxpDhHvAa3AUN7etJbXuijyPokwjEHTmHpYt+wUdT31S51kChj2EjXsXgN7rBsUUD6fyxuGTMnLYa5/+8iuC56zE/bGw13gFSC5kWDwUGBiIgIEDlXHWqLP8lPFIFEkWxzLlHPdqnvP7V6fMkGk9aUlJS4OzsDADYvHkzPD09ERwcjMTERPTv31/D0dHj/PzzHhw/fhZTpozC33+nVvl6URSxfftBAMCgQZUrDRKp26NDQL/uPv7Eawa93hWDXu8qff/nuSf/POjq6mDb7s9hpjQp09a7bwdc/+cmFodFYVvUH/hw8usqw0RrN86AspzrOrm1xNTAoQicugoH9p/AnTv3WW2pIUSZdsSt7lBQeWxtbQGUVEHq168vnc/IyJCqIra2tsjPz0dWVpZKtSUjIwNdunSR+ty4caPM/TMzM1Xuc/ToUZX2rKwsFBQUlKnAPI7GVw8ZGBjgwYMHAIB9+/ZJ42YWFha4e/euJkOjx7h9OxtffbUWzZvbY9SoQdW6x/HjZ/HPPxnQ19dD//4vyRwhUc0mCEK5CUspty4lf8zdvfsAWbfvq7SVl7A8el1xsYirqZkyREq1lYODA2xtbbF3717pXH5+Pg4dOiQlJO3bt4e+vr5Kn7S0NJw5c0bq4+7ujuzsbBw7dkzqc/ToUWRnZ6v0OXPmDNLS0qQ+e/bsgUKhQPv27Ssds8YrLd26dUNAQAC6du2KY8eO4ccffwQAXLhwAQ0bcrigpgoOXoU7d+5h8eJA6OtX73+jbdsOAgC6dWsHCwuljNERab/8vALpa4Vh5SfV5uUXSl8bKjgZt8bQ0OZy9+/fx8WLF6XvU1JSkJSUBAsLCzRq1Aj+/v4IDg6Go6MjHB0dERwcDGNjY3h7ewMAlEolfH19MXnyZFhaWsLCwgJTpkyBq6srevbsCQBo2bIl+vbtCz8/P6xYsQIAMGbMGHh6esLJqWSuYu/eveHs7AwfHx98+eWXuH37NqZMmQI/P79KrxwCakDSEh4ejnHjxuHnn3/GsmXL0KBByfjs7t270bdvXw1HR+WJjT2J7dsPwsvLA506uVbrHvn5BYiOPgyAQ0NE5dn7awIAoJmjHerUMar8ddElw1lmZsZwaFb/Cb3pmdHQhrjHjx9XWZlTOh9m5MiRiIiIwLRp05Cbm4tx48YhKysLnTt3xp49e2BqaipdExYWBj09PQwZMgS5ubno0aMHIiIioKurK/VZv349Jk2aJI2WeHl5qewNo6uri507d2LcuHHo2rUrjIyM4O3tja+++qpKr0fjSUujRo2wY8eOMufDwsI0EA09SV5ePubMWQJTUxNMn/5ete8TE3MMd+/mwNTUBK++2knGCIm038W//sFPkYcAACPf7VPp6zIzs7FqxU4AgPc7PaGnp/uEK6i28/DwwOO2YxMEAUFBQY9dfWRoaIjFixdj8eLFFfaxsLDADz88fi+ain7fV4XG57QkJibi9OnT0ve//PILBg8ejI8//rjK2/uS+i1d+iOuXEnDRx/5wMqq+svRt20rWVnRt29XKBQGcoVHpPXu3X2AaR+tQEFBIbq+5IIBXm6Vuq6goBAzJn+L7Ds5cHrBHqN8K5/s0DOgI8hzPOc0nrSMHTsWFy6U7GB76dIlDBs2DMbGxvjpp58wbdo0DUdH/1W6J0urVs0wfHi/at8nK+sufvutpPQ9ePCrcoVHpPXy8wswedIyXLl8A82a2+HzeZWrZoqiiDkzI5CUeBFW9ZT46pv3qz3XjNREQ9v41zYaT1ouXLiANm3aAAB++uknvPzyy9iwYQMiIiKwefPmJ16fl5eHu3fvqhx5eazQqENQ0DIUFRUjKGhcubt0VtauXb+joKAQDRpYo317ZxkjJNJehYVFmDFlJRKOX4BdA0ss+fbDx64u+q/5wZH4dVc8lEoTLPn2Q9g1sFJztESaofFUXBRFFBcXAyhZ8uzp6QkAsLe3x82bN594ffm7A05AUNBE+YN9ziUnX4IgAB988FmZtnv3Spatr1y5GevX74CtrRU2by5/XlLp3ixeXq9UaVMhotpKFEXM/WQtDsWchFU9JZau/Aj1rOtW6tol32zFpo0HYWyswKLlE9HcscGTL6Jnj//UyULjSUuHDh3w+eefo2fPnjh06BCWLVsGoGRZVmU2nCl/d8Cqb3RGlVNUVIybN+9U2P7gQS4ePMitcJ5KamoaTpz4EwDg5eWhhgiJtE/oFxuxa8dRKOuaYOlKf9g3qvfkiwB8/92v+G7lbigU+ggLHw8XVwc1R0rVxvkostB40rJw4UKMGDECW7duxcyZM9G8eXMAwM8//yxtSvM45e8OyImd6nD8eGSFbTNmhCEqKqbcD0z8r19+KZmAy237iUos+WYrfoo8BBMTQ4Qvn4Rmze2efBGALT/9hm8WbIGeni7mfT0GHTrxs7tqNCYtstB40tK6dWuV1UOlvvzyS5U14FQ7cNt+on/9sHZvSaXEUB8Ll4yHs0uTSl2399cEhHy2ATo6Aj4Nfhcve7RWb6BENYTGk5aKGBoaajoEktmJE3/iypU0bttPNVpS4kUETFoqfZ/7IA8AsGZVNDas2y+d3/DTJ7CtbwEASE+7De+3PpfaHj4sWQywe8dRHIxJks4vWDQObdqVVJMzM+5g4Vcliw1MjA0R/s3WCmOaHzYWVlb/7ho9a8Z3KC4WYVLHED9uPIAfN5b/4YzTPh6GF1o2qszLJjUTWWiRhcaTlqKiIoSFhWHTpk1ITU0tszfL7du3NRQZye2XX2IAcNt+qtkKC4uQfSenzPmHufl4mPvvv0+lCwhKvy7vmvz8QuT/Z1v9wsIi6euCgkJp06/bt+/h9u17Fcb03y39S68FgJz7D3HyxN8VXnf/Xm6FbfSMcXhIFoL4uK3ynoHZs2dj1apVCAgIwKxZszBz5kxcvnwZW7duxezZszFp0qRq3PWC7HES1Qb3C65rOgSiGqeOvofan9F0zM+y3OfSt2/Kch9tpfF9WtavX4+VK1diypQp0NPTw/Dhw7Fq1SrMnj0bcXFxmg6PiIjo6XFzOVloPGlJT0+Hq2vJh+7VqVMH2dnZAABPT0/s3LlTk6ERERHJg9v4y0LjSUvDhg2RlpYGAGjevDn27NkDAIiPjy9nKTMRERE9rzSetLz22mvYv79kRv6HH36IWbNmwdHREe+88w7ee6/6nyJMRERUY+jIdDznNL56aN68edLXb775Jho2bIgjR46gefPm8PLy0mBkREREMuF8FFloPGl5lJubG9zcKvdR7ERERPT80EjSsm3btkr3ZbWFiIi0HifRykIjScvgwYMr1U8QBBQVFT25IxERUQ0mcnhIFhpJWv67kyQREVGtx0m0suDbSERERFpBY0lLTEwMnJ2dcffu3TJt2dnZaNWqFX777TcNREZERCQzbi4nC40lLQsXLoSfnx/MzMzKtCmVSowdOxZhYWEaiIyIiEhm3MZfFhpLWk6ePIm+fftW2N67d28kJCQ8w4iIiIioJtPYPi03btyAvr5+he16enrIzMx8hhERERGpCYd2ZKGxSkuDBg1w+vTpCttPnTqF+vXrP8OIiIiI1ESQ6XjOaSxp6d+/P2bPno2HDx+WacvNzcWcOXPg6empgciIiIioJhJEURQ18eAbN26gXbt20NXVxYQJE+Dk5ARBEJCcnIwlS5agqKgIiYmJsLGxqcbdL8geL1FtcL/guqZDIKpx6uh7qP0ZTQJ3ynKfyyEDZLmPttLYnBYbGxscOXIEH3zwAQIDA1GaOwmCgD59+mDp0qXVTFiIiIhqGM5pkYVGPzCxcePG2LVrF7KysnDx4kWIoghHR0eYm5trMiwiIiKqgWrEpzybm5ujY8eOmg6DiIhIPbjHiixqRNJCRERUq/FDc2TBpIWIiEjdWGmRBXM/IiIi0gqstBAREakbVw/JgkkLERGRujFpkQWHh4iIiEgrsNJCRESkZiIn4sqCSQsREZG6cVxDFnwbiYiISCuw0kJERKRuHB6SBZMWIiIidePqIVlweIiIiIi0AistRERE6sZKiyyYtBAREakbcxZZMGkhIiJSM5GVFllwTgsRERFpBSYtRERE6iYI8hxVUFhYiE8++QQODg4wMjJC06ZN8emnn6K4uFjqI4oigoKCYGdnByMjI3h4eODs2bMq98nLy8PEiRNhZWUFExMTeHl54dq1ayp9srKy4OPjA6VSCaVSCR8fH9y5c6fab1dFmLQQERGpm44gz1EFoaGhWL58OcLDw5GcnIz58+fjyy+/xOLFi6U+8+fPx4IFCxAeHo74+HjY2tqiV69euHfvntTH398fUVFRiIyMxOHDh3H//n14enqiqKhI6uPt7Y2kpCRER0cjOjoaSUlJ8PHxefr37RGCKIqi7HfVuAuaDoCoRrpfcF3TIRDVOHX0PdT+jEbfHJLlPqkfdq90X09PT9jY2GD16tXSuTfeeAPGxsZYt24dRFGEnZ0d/P39MX36dAAlVRUbGxuEhoZi7NixyM7ORr169bBu3ToMHToUAHD9+nXY29tj165d6NOnD5KTk+Hs7Iy4uDh07twZABAXFwd3d3f8+eefcHJykuW1A6y0EBERqZ8g01EF3bp1w/79+3HhQskf8idPnsThw4fRv39/AEBKSgrS09PRu3dv6RqFQoHu3bvjyJEjAICEhAQUFBSo9LGzs4OLi4vUJzY2FkqlUkpYAMDNzQ1KpVLqIxeuHiIiIlIzHZlKBHl5ecjLy1M5p1AooFAoyvSdPn06srOz8cILL0BXVxdFRUX44osvMHz4cABAeno6AMDGxkblOhsbG1y5ckXqY2BgAHNz8zJ9Sq9PT0+HtbV1medbW1tLfeTCSgsREZGWCAkJkSa7lh4hISHl9v3xxx/xww8/YMOGDUhMTMTatWvx1VdfYe3atSr9hEcm+IqiWObcox7tU17/ytynqlhpISIiUjO5fncHBgYiICBA5Vx5VRYAmDp1KmbMmIFhw4YBAFxdXXHlyhWEhIRg5MiRsLW1BVBSKalfv750XUZGhlR9sbW1RX5+PrKyslSqLRkZGejSpYvU58aNG2Wen5mZWaaK87RYaSEiIlIzuVY8KxQKmJmZqRwVJS0PHjyAziPjUrq6utKSZwcHB9ja2mLv3r1Se35+Pg4dOiQlJO3bt4e+vr5Kn7S0NJw5c0bq4+7ujuzsbBw7dkzqc/ToUWRnZ0t95MJKCxERkZrJPUxSGQMHDsQXX3yBRo0aoVWrVjhx4gQWLFiA9957T4rJ398fwcHBcHR0hKOjI4KDg2FsbAxvb28AgFKphK+vLyZPngxLS0tYWFhgypQpcHV1Rc+ePQEALVu2RN++feHn54cVK1YAAMaMGQNPT09ZVw4BTFqIiIhqpcWLF2PWrFkYN24cMjIyYGdnh7Fjx2L27NlSn2nTpiE3Nxfjxo1DVlYWOnfujD179sDU1FTqExYWBj09PQwZMgS5ubno0aMHIiIioKurK/VZv349Jk2aJK0y8vLyQnh4uOyvifu0ED1HuE8LUVnPYp+W5st/k+U+F99/WZb7aCtWWoiIiNRMA6NDtRIn4hIREZFWYKWFiIhIzQSWCGTBpIWIiEjNODwkD+Z+REREpBVYaSEiIlIzHVZaZFGppGXRokWVvuGkSZOqHQwREVFtxOEheVQqaQkLC6vUzQRBYNJCREREalGppCUlJUXdcRAREdVarLTIo9oTcfPz83H+/HkUFhbKGQ8REVGtIwiCLMfzrspJy4MHD+Dr6wtjY2O0atUKqampAErmssybN0/2AImIiLSdoCPP8byr8lsQGBiIkydP4uDBgzA0NJTO9+zZEz/++KOswRERERGVqvKS561bt+LHH3+Em5ubSqnK2dkZf//9t6zBERER1QYc2ZFHlZOWzMxMWFtblzmfk5PD8TYiIqJy8NejPKo8PNSxY0fs3LlT+r40UVm5ciXc3d3li4yIiIjoP6pcaQkJCUHfvn1x7tw5FBYW4ptvvsHZs2cRGxuLQ4cOqSNGIiIircZKizyqXGnp0qUL/vjjDzx48ADNmjXDnj17YGNjg9jYWLRv314dMRIREWk1HUGe43lXrc8ecnV1xdq1a+WOhYiIiKhC1UpaioqKEBUVheTkZAiCgJYtW2LQoEHQ0+PnLxIRET2Kw0PyqHKWcebMGQwaNAjp6elwcnICAFy4cAH16tXDtm3b4OrqKnuQRERE2oxJizyqPKdl9OjRaNWqFa5du4bExEQkJibi6tWraN26NcaMGaOOGImIiIiqXmk5efIkjh8/DnNzc+mcubk5vvjiC3Ts2FHW4IiIiGoDgbNoZVHlSouTkxNu3LhR5nxGRgaaN28uS1BERES1iSDIczzvKlVpuXv3rvR1cHAwJk2ahKCgILi5uQEA4uLi8OmnnyI0NFQ9URIREWkxJhzyqFTSUrduXZUt+kVRxJAhQ6RzoigCAAYOHIiioiI1hElERETPu0olLQcOHFB3HERERLUWKy3yqFTS0r17d3XHQUREVGtxHq48qr0b3IMHD5Camor8/HyV861bt37qoIiIiIgeVeWkJTMzE++++y52795dbjvntBAREani8JA8qrzk2d/fH1lZWYiLi4ORkRGio6Oxdu1aODo6Ytu2beqIkYiISKsJOvIcz7sqV1piYmLwyy+/oGPHjtDR0UHjxo3Rq1cvmJmZISQkBAMGDFBHnERERPScq3LelpOTA2trawCAhYUFMjMzAZR88nNiYqK80REREdUC3FxOHtXaEff8+fMAgDZt2mDFihX4559/sHz5ctSvX1/2AImIiLSdIAiyHM+7Kg8P+fv7Iy0tDQAwZ84c9OnTB+vXr4eBgQEiIiLkjo+IiIgIQDWSlhEjRkhft23bFpcvX8aff/6JRo0awcrKStbgiIiIagMWSeRR7X1aShkbG6Ndu3ZyxEJERFQrMWmRR6WSloCAgErfcMGCBdUOhoiIqDZi0iKPSiUtJ06cqNTNOEmIiIiI1KVWfmDiw6Lbmg6BqEaq12yFpkMgqnFyUz3U/gx+9pA8nnpOCxERET0ekxZ5cFNgIiIi0gqstBAREamZjiBqOoRagUkLERGRmnF4SB4cHiIiIiKtUK2kZd26dejatSvs7Oxw5coVAMDChQvxyy+/yBocERFRbaAj0/G8q/J7sGzZMgQEBKB///64c+cOioqKAAB169bFwoUL5Y6PiIhI6+kIoizH867KScvixYuxcuVKzJw5E7q6utL5Dh064PTp07IGR0RERFSqyklLSkoK2rZtW+a8QqFATk6OLEERERHVJjqCPEdV/fPPP3j77bdhaWkJY2NjtGnTBgkJCVK7KIoICgqCnZ0djIyM4OHhgbNnz6rcIy8vDxMnToSVlRVMTEzg5eWFa9euqfTJysqCj48PlEollEolfHx8cOfOneq8VY9V5aTFwcEBSUlJZc7v3r0bzs7OcsRERERUq2hiTktWVha6du0KfX197N69G+fOncPXX3+NunXrSn3mz5+PBQsWIDw8HPHx8bC1tUWvXr1w7949qY+/vz+ioqIQGRmJw4cP4/79+/D09JSmhwCAt7c3kpKSEB0djejoaCQlJcHHx6eKET9ZlZc8T506FePHj8fDhw8hiiKOHTuGjRs3IiQkBKtWrZI9QCIiIm2niSXPoaGhsLe3x5o1a6RzTZo0kb4WRRELFy7EzJkz8frrrwMA1q5dCxsbG2zYsAFjx45FdnY2Vq9ejXXr1qFnz54AgB9++AH29vbYt28f+vTpg+TkZERHRyMuLg6dO3cGAKxcuRLu7u44f/48nJycZHtNVa60vPvuu5gzZw6mTZuGBw8ewNvbG8uXL8c333yDYcOGyRYYERERqcrLy8Pdu3dVjry8vHL7btu2DR06dMBbb70Fa2trtG3bFitXrpTaU1JSkJ6ejt69e0vnFAoFunfvjiNHjgAAEhISUFBQoNLHzs4OLi4uUp/Y2FgolUopYQEANzc3KJVKqY9cqrWCys/PD1euXEFGRgbS09Nx9epV+Pr6yhoYERFRbSEIoixHSEiING+k9AgJCSn3mZcuXcKyZcvg6OiIX3/9Fe+//z4mTZqE77//HgCQnp4OALCxsVG5zsbGRmpLT0+HgYEBzM3NH9vH2tq6zPOtra2lPnJ5qh1xrays5IqDiIio1pJreCgwMBABAQEq5xQKRbl9i4uL0aFDBwQHBwMA2rZti7Nnz2LZsmV45513pH6CoBqcKIplzj3q0T7l9a/MfaqqykmLg4PDY4O4dOnSUwVERERE5VMoFBUmKY+qX79+mQUyLVu2xObNmwEAtra2AEoqJfXr15f6ZGRkSNUXW1tb5OfnIysrS6XakpGRgS5dukh9bty4Ueb5mZmZZao4T6vKSYu/v7/K9wUFBThx4gSio6MxdepUueIiIiKqNTSxm23Xrl1x/vx5lXMXLlxA48aNAZQUIWxtbbF3715pK5P8/HwcOnQIoaGhAID27dtDX18fe/fuxZAhQwAAaWlpOHPmDObPnw8AcHd3R3Z2No4dO4ZOnToBAI4ePYrs7GwpsZFLlZOWDz/8sNzzS5YswfHjx586ICIiotpGE7vZfvTRR+jSpQuCg4MxZMgQHDt2DN9++y2+/fZbACVDOv7+/ggODoajoyMcHR0RHBwMY2NjeHt7AwCUSiV8fX0xefJkWFpawsLCAlOmTIGrq6u0mqhly5bo27cv/Pz8sGLFCgDAmDFj4OnpKevKIUDG5K9fv35SyYmIiIg0q2PHjoiKisLGjRvh4uKCzz77DAsXLsSIESOkPtOmTYO/vz/GjRuHDh064J9//sGePXtgamoq9QkLC8PgwYMxZMgQdO3aFcbGxti+fbvKrvjr16+Hq6srevfujd69e6N169ZYt26d7K9JEEVRlvRv/vz5WLp0KS5fvizH7Z7Kw6I4TYdAVCOZO3yj6RCIapzc1I1qf8bbhw7Jcp8funeX5T7aqsrDQ23btlWZiCuKItLT05GZmYmlS5fKGhwREVFtwE9olkeVk5bBgwerfK+jo4N69erBw8MDL7zwglxxEREREamoUtJSWFiIJk2aoE+fPtJSKSIiIno8TWzjXxtVqWKlp6eHDz74oMItg4mIiKgsHUGU5XjeVXmYrXPnzjhx4oQ6YiEiIqqVdAR5juddlee0jBs3DpMnT8a1a9fQvn17mJiYqLS3bt1atuCIiIiISlU6aXnvvfewcOFCDB06FAAwadIkqU0QBOkzBoqKiuSPkoiISItx9ZA8Kp20rF27FvPmzUNKSoo64yEiIqp1OB9FHpVOWkr3oCv9zAIiIiKiZ6lKc1rk/ohpIiKi5wEn0cqjSklLixYtnpi43L59+6kCIiIiqm2YtMijSknL3LlzoVQq1RULERERUYWqlLQMGzYM1tbW6oqFiIioVuLqIXlUOmnhfBYiIqLq4eoheVQ6+StdPURERESkCZWutBQXF6szDiIiolqLE3HlUeVt/ImIiKhqOKdFHkxaiIiI1IyVFnkw+SMiIiKtwEoLERGRmglcPSQLJi1ERERqxuEheXB4iIiIiLQCKy1ERERqxgqBPJi0EBERqRl3xJUHkz8iIiLSCqy0EBERqRkn4sqDSQsREZGaMWmRB4eHiIiISCuw0kJERKRmupoOoJZg0kJERKRmXD0kDyYtREREasY5LfLgnBYiIiLSCqy0EBERqRkrLfJg0kJERKRmukxaZMHhISIiItIKrLQQERGpGYeH5MGkhYiISM245FkeHB4iIiIircBKCxERkZpxeEgeTFqIiIjUjNv4y4PDQ0RERKQVWGkhIiJSMw4PyYNJCxERkZpx9ZA8mLQQERGpGXfElQfntBAREZFWYKWFiIhIzTinRR5MWoiIiNSMSYs8ODxERET0HAgJCYEgCPD395fOiaKIoKAg2NnZwcjICB4eHjh79qzKdXl5eZg4cSKsrKxgYmICLy8vXLt2TaVPVlYWfHx8oFQqoVQq4ePjgzt37sj+Gpi0EBERqZmOIM9RXfHx8fj222/RunVrlfPz58/HggULEB4ejvj4eNja2qJXr164d++e1Mff3x9RUVGIjIzE4cOHcf/+fXh6eqKoqEjq4+3tjaSkJERHRyM6OhpJSUnw8fGpfsAVqLFJy40bN/Dpp59qOgwiIqKnpiuIshzVcf/+fYwYMQIrV66Eubm5dF4URSxcuBAzZ87E66+/DhcXF6xduxYPHjzAhg0bAADZ2dlYvXo1vv76a/Ts2RNt27bFDz/8gNOnT2Pfvn0AgOTkZERHR2PVqlVwd3eHu7s7Vq5ciR07duD8+fNP/+b9R41NWtLT0zF37lxNh0FERFRj5OXl4e7duypHXl7eY68ZP348BgwYgJ49e6qcT0lJQXp6Onr37i2dUygU6N69O44cOQIASEhIQEFBgUofOzs7uLi4SH1iY2OhVCrRuXNnqY+bmxuUSqXURy4am4h76tSpx7bLnZ0RERFpilwVgpCQkDJ/0M+ZMwdBQUHl9o+MjERiYiLi4+PLtKWnpwMAbGxsVM7b2NjgypUrUh8DAwOVCk1pn9Lr09PTYW1tXeb+1tbWUh+5aCxpadOmDQRBgCiWLXeVnhcETrcmIiLtJ9fqocDAQAQEBKicUygU5fa9evUqPvzwQ+zZsweGhoYV3vPR37WV+f37aJ/y+qvj97jGkhZLS0uEhoaiR48e5bafPXsWAwcOfMZRERER1VwKhaLCJOVRCQkJyMjIQPv27aVzRUVF+O233xAeHi6NaKSnp6N+/fpSn4yMDKn6Ymtri/z8fGRlZalUWzIyMtClSxepz40bN8o8PzMzs0wV52lpbE5L+/btcf36dTRu3Ljco0GDBuVWYYiIiLSNJlYP9ejRA6dPn0ZSUpJ0dOjQASNGjEBSUhKaNm0KW1tb7N27V7omPz8fhw4dkhKS9u3bQ19fX6VPWloazpw5I/Vxd3dHdnY2jh07JvU5evQosrOzpT5y0VilZezYscjJyamwvVGjRlizZs0zjIiIiEg9qrvy52mYmprCxcVF5ZyJiQksLS2l8/7+/ggODoajoyMcHR0RHBwMY2NjeHt7AwCUSiV8fX0xefJkWFpawsLCAlOmTIGrq6s0sbdly5bo27cv/Pz8sGLFCgDAmDFj4OnpCScnJ1lfk8aSltdee+2x7ebm5hg5cuQzioaIiEh9auqOuNOmTUNubi7GjRuHrKwsdO7cGXv27IGpqanUJywsDHp6ehgyZAhyc3PRo0cPREREQFdXV+qzfv16TJo0SVpl5OXlhfDwcNnjFcRaOAbzsChO0yEQ1UjmDt9oOgSiGic3daPan/HLld2y3GdQ436y3Edb8bOHiIiI1KymVlq0DZMWIiIiNWPSIo8auyMuERER0X+x0kJERKRmuqy0yELjSUt0dDTq1KmDbt26AQCWLFmClStXwtnZGUuWLCmzdTCp3z//ZKJ/rymV6rt6bSA6dHwBAPCic+VWe30W7Aevwd1UzhXkF2LTjzHYvTMOKZeu4+HDfNStWweuLzbD8BG90NnNuWovgugxGtvXw6vdXNGhTTN0eLEZnFs0hJ6eLoK+3ITQxVHlXvNiqybw6tMBL7k5o2WLhlCaGiErOwcnTqfguw37se3X4xU+T19fF2N8emGIVxc4NW8AYyMD3My6h/jEi1ga8SsOHTlb4bVvv/kyfN7qDpeWjWBqYog7dx9Iz/wluuzW7OWxsjDFyYMLYFG3DgoLi2Da9O1KXUfy0dHAkufaSONJy9SpUxEaGgoAOH36NCZPnoyAgADExMQgICCAe7VogMJAH23aOVbYfjPzDq5dzYRCoQ+nFxpJ5x93zd3sHFz6+zoAoPWLzVTacnPzMNZ3Pk4mXQQA2DWwgn0ja1y7lokD+xNxYH8i/CcPwbu+A57mZRFJJrzXDxN8K78Kw6GxNeJ2h0jfp6TewJVrmXBoZI0+r7RBn1faYN1PhzB2yooym2IaGRpg14aZcOvQAgBwOTUDf1+5D4dG1vDq2xFefTtiZvAGLFi+XeU6QRCwcbk/BvXrBAD4J+0WUlIzYG9nid4eL6K3x4tYvnYPPpr15H8j589+BxZ161T69RLVVBpPWlJSUuDsXPJX9ObNm+Hp6Yng4GAkJiaif//+Go7u+WRVry7W/vBJhe2B05bj2tVMdH+lLUxNjaXzj7sm/Jufcenv63BxbYomDvVV2tatjcbJpIswtzDFoiUfSUlNQUEhVn+7HcuWbMXihT+jR88OaNRY3i2h6fl08/Y97NyXgONJfyPh5CW8O/wVvNa/c4X9BQhIu5GF8NW7sWHL70jPuFNyXhAw9p1e+HruSPi81R2Jpy5h+do9KtdO8hsAtw4tkHEzG2++9yXik/4GAOjp6WLahMGYFfAm5k4biq27j+HSlX+3Qh86uCsG9euE3If5GD42DL8eSJLa3h3+KsJDfPH+yN7YsjMOv8clVxj7K91cMPz1bti+5zgG9u5QjXeL5MAJpPLQ+PtoYGCABw8eAAD27dsnbUxjYWGBu3fvajI0KseDnIc4sD8RAODp1bVS14iiiJ07Yv9/TdktnX8/dBIAMOb9QSpVGH19Pbw//jU4vdAIRUXFiIs987ThEwEAQhdH4c33vsK8RVHYe+gk7uc8fGz/f9Jvo9VL/liwfLuUsAAl/28vX7sHq9bvB1CSTDyq36ttAADzFkVJCQsAFBYWIXjhZiSduQw9PV30eMn1kevaAgC+/X6vSsICAGs2xmDHngQAQJ9X2lQYt0Khj0VfvIe0jCx89vVPj32NpF6a2Ma/NtJ40tKtWzcEBATgs88+w7FjxzBgQMkQwIULF9CwYUMNR0eP2r/vOHJz82BuYYqu3VyffAGAxITzuP7PTejp6aJvf7cy7XkPCwAADe3rlXu9faOSjzwvLCyuZtRETycvrwC5D/MrbN//2ykAgGPT+mXaDA0NAAApqRnlXpuSWlJd0dPTVTlvZKiv0v6o0qqMnq5uue0AMGPia2juUB+Bn/2A7HsPKuxHpC00nrSEh4dDT08PP//8M5YtW4YGDRoAAHbv3o2+fftqODp61I7tRwAAffu5lflHtiI7/39N15dcYW5uWqbd0akkOT154mKZtvz8Apw7exkA4OLqUJ2QidTOUFGSmJSX2Jz5MxUA4Na+7JwvAwM9tHUp+f864eTfKm2nk0uva1HuMzv//36PXlfKqbkdPhrriYN/nMWPvxypzMsgNdIV5Dmedxqf09KoUSPs2LGjzPmwsDANREOPk5l5B8fizgEof5inPPn5Bdjza8kKB8+B5Q8nvTfaEzH7EhHx3S4o69ZBn36doFTWweWUNIQv2ozr/9zEgIFd0PrF5vK8ECKZveFZUkGMPX6+TNtXS7fBq09HfDR2IG5n3cfP22Nx+859tGhmhzlTh6BJI2ts2PI7jj2StC+L+BXver+KYa91Q+o/N7F6w37cyMxG44b1MPmDgXDv4ITf45Lx847yP7YkPGQ0BEGA/6zv5H/BVGVcPSQPjSctiYmJ0NfXh6tryVDDL7/8gjVr1sDZ2RlBQUEwMDDQcIRUatf2IyguFtHEoT5cXJtW6ppDB5Jw7+4DmJoao3sFY+/NmjfA2vUzsSjsZyz4MhJfz//3c0Dq1q2DGTPfxtDhPeR4CUSy6/GSK7z6dgQAhC0v+wfYn3/9g1dfD8Kn04ch5JMRCJ3tI7XdvH0PH81agxXf7y1z3c3b9+AxaDY+DxwO/zGemDZhsNSW8+Ahgr7chIXf7iizWgkARg17Bd06t8SXS37B+YvXn/5F0lPjfBR5aHx4aOzYsbhw4QIA4NKlSxg2bBiMjY3x008/Ydq0aRqOjv5r5/b/T6YdWLkqS8k1JWXpXn06QqGoOAFNS7uNW7eyIYoi6lnXhdMLjWBsbIg7d+7jl6jfceH81acLnkgN7O0ssWbRBADA8rV78MexP8vv18AS1vWU0NHRwfX020g6cxn37ufCysIUPkO6w7Vlo3Kvs7M1h029ujAw0MONzGycOJ2C23fuw8TYEN6vd0OXjk5lrrGyMMXngcORei0TId9ske/FEtUAGq+0XLhwAW3atAEA/PTTT3j55ZexYcMG/PHHHxg2bBgWLlz42Ovz8vKQl5enck7Uy3/sL0iqur8uXMX586kQBAEDKpm03LlzH7//VrIyaOBjVhrt3H4EM2d8C0tLM5XN6gryC7Fi+S9YuXwb3nsnGJuiPkfDhuVP1iV61syVJtj6/QzUszTDoSNnMf2zdeX2Gza4K1YvHIcbN7PR661PcfhoyfJkfX1dBE56HYEfvo69P81Gp74zcOVqpnTdS24tse37GSgsKsawMQtUNpLze7snwj57F1sjpqPP0E8Rl/CX1DZ/9juwNDfFB1O/fezkYXq2WGmRh8YrLaIoori4ZFXIvn37pL1Z7O3tcfPmzSdeHxISAqVSqXJ8Oe97tcb8PNqxraRi0r6DE+waWFXqml93H0VhYRHsGlihbQWTCQsKCvH1/EiIooipgSOkhAUA9A30MGHSG3Dv6oKcnIf4bmXZ0juRJpgYK7B17XQ4t2iIhFOX8KbvV8jPLyzTT09PFyGfvA0dHR1Mm/u9lLAAQEFBET79+ifsPXQSZqbGmDLOS+Xa0Fk+MDQ0wLxFW8rsfLvyh31YExkDAwM9fOz/hnS+W+eWGP56N+zan4jteyreoZeePR2ZjuedxistHTp0wOeff46ePXvi0KFDWLZsGYCSTedsbJ68kVhgYCACAgJUzol6SeoI9blVXFyM3btKJvsNqOQEXODfoaEBA7tAEMr/MyP1yg3cupUNABVu1e/m1gqxf5zBubMpVQmbSC0MDPTw0+op6NTOEecuXMMgn3kV7vPS3MEWttZ1AQAHDpe/Vf+Bw2fQq/uLaNf633lixkYKvNiqcUn7HxVfN3pET5Xr2rg0AQB06eCElOPLVPrr6pb8ytPT05Xaps5di5+3lz+Rl6gm0njSsnDhQowYMQJbt27FzJkz0bx5yQqRn3/+GV26PPkXpEKhgEKhUDn3sIhDQ3KKP5qMG+m3oVDoo1fvjpW65mrqDWlb/sfNgcl5wqZeACCiZKJhXl5BpZ5NpC66ujr4YemHeKWrCy5duQHPEcG4lXWvwv6mJoZPvGdpQm/4nyHtOiaG0NF5/N/V/16nX6atrtLksdeWJlKGHEZ/Zir4u42qSONJS+vWrXH69Oky57/88kvoPmbTJHp2SvdmeXTb/sde8//hpPK27f8v+0bWEAQBoijiaNw59O1Xdiv1uNiSvzQbN7GtauhEslr59QcY2LsDrqffRn/vL5B2I+ux/S9dyUBxcTF0dHTwSrdW5VY1XunmAgC4eClNOpd56y7uZOegrtIEr3RthcRTlyq87q9L6dK58NW7Eb56d7mxNGpohfNHFvMDEzWEOYs8auwQmaGhIfT1y/4FQc/Ww4f52L+3ZGy8stv2A8Cux2zb/1/m5qbo0rXkH98vQ9Yj4fi/qy8K8gsRvmgz4v7/CbhVeT6R3L6eOxLDX++GzFt30d/7C5VJsxW5lXUPew+V7JY7f8476NrpP3O29HUxe/Jb6PlyawDAhi2/S22iKGLT/xP/GZNeh1effz8zSBAE+L3dE6OGvgIA2Pif64hqO0Esb5H/M1RUVISwsDBs2rQJqampyM9Xne1++/btKt/zYRHHaOWye2csZkxdDnMLU+w7+E2ldsE9mXQR73h/Bj09Xew79E25u+D+1/V/buK9d4KRlnYLAGBtYw5zc1Ncu5ohDR+98VZ3zJ773tO/oOecucM3mg6hRnDv0AKbVk2Rvq9jrIChoQFyHjxE7sN/hyHd+83AtbTb6NzOEQe3fgoAuPrPTVy9XvEigR5vzFX5vlEDK+z9aTYa/X/l2z9pt5B56x6aNraG2f8rl6s37MeEGatUrlOaGSM6cpY0T+VGZjb+Sb+FJvbW0ic2R8ecwFujv0ZhYdETXzMrLRXLTd345E5P6fjNnbLcp4PV8/1p9xofHpo7dy5WrVqFgIAAzJo1CzNnzsTly5exdetWzJ49W9PhPfdKh3mqsm3/jm1/AKh42/5H2TWwwqaoz7D++z04eOAEUq/cwO1bd2FqZoy27VrgtTe7o2cvfjotyUdPTxdWFmX/3zQxNoSJ8b/zUHT+P3nVwODffyrtG1jBvpIr6AAg9Z+b6NR3Bib49sOAnu3R3MEW1lZKZGXn4Ej8CUREHiizOggAsu8+gMdrs/H+O73xWv9OeMGxIVq3bIzsew9w8I+z2Bh1GOt+OlTu5nJU89TYYQ0to/FKS7NmzbBo0SIMGDAApqamSEpKks7FxcVhw4YNVb4nKy1E5WOlhaisZ1FpSZSp0tLuOa+0aDz5S09Pl7bwr1OnDrKzS5a/enp6YudOef4jExERaZIgiLIczzuNJy0NGzZEWlrJrPnmzZtjz549AID4+PgyS5mJiIi0kSDT8bzTeNLy2muvYf/+/QCADz/8ELNmzYKjoyPeeecdvPceJ14SEZH2EwR5juedxifizps3T/r6zTffRMOGDXHkyBE0b94cXl5ej7mSiIiInicaT1oe5ebmBjc3N02HQUREJBsWSeShkaRl27Ztle7LagsREWk7fsqzPDSStAwePLhS/QRBQFHRkzdNIiIiotpPI0lLcXGxJh5LRESkESy0yKPGzWkhIiKqbbjyRx4aW/IcExMDZ2dn3L17t0xbdnY2WrVqhd9++00DkREREVFNpLGkZeHChfDz84OZmVmZNqVSibFjxyIsLEwDkREREcmLm8vJQ2NJy8mTJ9G3b98K23v37o2EhIRnGBEREZF6MGmRh8aSlhs3bkBfX7/Cdj09PWRmZj7DiIiIiKgm01jS0qBBA5w+fbrC9lOnTqF+/frPMCIiIiL10BHkOZ53Gkta+vfvj9mzZ+Phw4dl2nJzczFnzhx4enpqIDIiIiJ5cXhIHoIoihr5rOsbN26gXbt20NXVxYQJE+Dk5ARBEJCcnIwlS5agqKgIiYmJsLGxqfK9HxbFqSFiIu1n7vCNpkMgqnFyUzeq/RkX726X5T7NzQbKch9tpbF9WmxsbHDkyBF88MEHCAwMRGnuJAgC+vTpg6VLl1YrYSEiIqLaSaObyzVu3Bi7du1CVlYWLl68CFEU4ejoCHNzc02GRUREJCsO7cijRuyIa25ujo4dO2o6DCIiIrXgjrjy0NhEXCIiIqKqqBGVFiIiotqMFQJ5MGkhIiJSMw4PyYPJHxEREWkFVlqIiIjUjIUWebDSQkREpGaCIM9RFSEhIejYsSNMTU1hbW2NwYMH4/z58yp9RFFEUFAQ7OzsYGRkBA8PD5w9e1alT15eHiZOnAgrKyuYmJjAy8sL165dU+mTlZUFHx8fKJVKKJVK+Pj44M6dO9V5qx6LSQsREVEtdOjQIYwfPx5xcXHYu3cvCgsL0bt3b+Tk5Eh95s+fjwULFiA8PBzx8fGwtbVFr169cO/ePamPv78/oqKiEBkZicOHD+P+/fvw9PREUVGR1Mfb2xtJSUmIjo5GdHQ0kpKS4OPjI/tr0tg2/urEbfyJysdt/InKehbb+F/LkWcb/4Ym1d/GPzMzE9bW1jh06BBefvlliKIIOzs7+Pv7Y/r06QBKqio2NjYIDQ3F2LFjkZ2djXr16mHdunUYOnQoAOD69euwt7fHrl270KdPHyQnJ8PZ2RlxcXHo3LkzACAuLg7u7u74888/4eTk9PQv/P9YaSEiIlIzuT7lOS8vD3fv3lU58vLyKhVDdnY2AMDCwgIAkJKSgvT0dPTu3Vvqo1Ao0L17dxw5cgQAkJCQgIKCApU+dnZ2cHFxkfrExsZCqVRKCQsAuLm5QalUSn3kwqSFiIhIzeT6lOeQkBBp3kjpERIS8sTni6KIgIAAdOvWDS4uLgCA9PR0ACjzOX82NjZSW3p6OgwMDMp8vM6jfaytrcs809raWuojF64eIiIi0hKBgYEICAhQOadQKJ543YQJE3Dq1CkcPny4TJvwyAxfURTLnHvUo33K61+Z+1QVKy1ERERqJgiiLIdCoYCZmZnK8aSkZeLEidi2bRsOHDiAhg0bSudtbW0BoEw1JCMjQ6q+2NraIj8/H1lZWY/tc+PGjTLPzczMLFPFeVpMWoiIiNRMruGhqhBFERMmTMCWLVsQExMDBwcHlXYHBwfY2tpi79690rn8/HwcOnQIXbp0AQC0b98e+vr6Kn3S0tJw5swZqY+7uzuys7Nx7Ngxqc/Ro0eRnZ0t9ZELh4eIiIhqofHjx2PDhg345ZdfYGpqKlVUlEoljIyMIAgC/P39ERwcDEdHRzg6OiI4OBjGxsbw9vaW+vr6+mLy5MmwtLSEhYUFpkyZAldXV/Ts2RMA0LJlS/Tt2xd+fn5YsWIFAGDMmDHw9PSUdeUQwKSFiIhI7TTx2UPLli0DAHh4eKicX7NmDUaNGgUAmDZtGnJzczFu3DhkZWWhc+fO2LNnD0xNTaX+YWFh0NPTw5AhQ5Cbm4sePXogIiICurq6Up/169dj0qRJ0iojLy8vhIeHy/6auE8L0XOE+7QQlfUs9mnJfLhNlvvUM/SS5T7ainNaiIiISCtweIiIiEjNWCGQB5MWIiIiNdPEnJbaiMkfERERaQVWWoiIiNSOpRY5MGkhIiJSM4FJiyyYtBAREamZIHA2hhz4LhIREZFWYKWFiIhI7Tg8JAcmLURERGrGOS3y4PAQERERaQVWWoiIiNSOlRY5MGkhIiJSM64ekgffRSIiItIKrLQQERGpHYeH5MCkhYiISM24ekgeHB4iIiIircBKCxERkZqx0iIPJi1ERERqx4ENOTBpISIiUjNBYKVFDkz9iIiISCuw0kJERKR2rLTIgUkLERGRmnEirjw4PERERERagZUWIiIitWONQA5MWoiIiNSMw0PyYOpHREREWoGVFiIiIjXjPi3yYNJCRESkdkxa5MDhISIiItIKrLQQERGpmcAagSyYtBAREakdh4fkwKSFiIhIzTgRVx6sVxEREZFWYKWFiIhI7VhpkQOTFiIiIjXjRFx58F0kIiIircBKCxERkdpxeEgOTFqIiIjUjB+YKA8ODxEREZFWYKWFiIhIzbhPizyYtBAREakdBzbkwHeRiIiItAIrLURERGrGibjyYNJCRESkdkxa5MCkhYiISM04EVcenNNCREREWoGVFiIiIrVjjUAOTFqIiIjUjBNx5cHUj4iIiLSCIIqiqOkgqHbKy8tDSEgIAgMDoVAoNB0OUY3Bnw2i6mHSQmpz9+5dKJVKZGdnw8zMTNPhENUY/Nkgqh4ODxEREZFWYNJCREREWoFJCxEREWkFJi2kNgqFAnPmzOFEQ6JH8GeDqHo4EZeIiIi0AistREREpBWYtBAREZFWYNJCREREWoFJC1WaIAjYunWrpsMgqlH4c0H07DBpIQBAeno6Jk6ciKZNm0KhUMDe3h4DBw7E/v37NR0aAEAURQQFBcHOzg5GRkbw8PDA2bNnNR0W1XI1/ediy5Yt6NOnD6ysrCAIApKSkjQdEpFaMWkhXL58Ge3bt0dMTAzmz5+P06dPIzo6Gq+88grGjx+v6fAAAPPnz8eCBQsQHh6O+Ph42NraolevXrh3756mQ6NaSht+LnJyctC1a1fMmzdP06EQPRsiPff69esnNmjQQLx//36ZtqysLOlrAGJUVJT0/bRp00RHR0fRyMhIdHBwED/55BMxPz9fak9KShI9PDzEOnXqiKampmK7du3E+Ph4URRF8fLly6Knp6dYt25d0djYWHR2dhZ37txZbnzFxcWira2tOG/ePOncw4cPRaVSKS5fvvwpXz1R+Wr6z8V/paSkiADEEydOVPv1EmkDPQ3nTKRht2/fRnR0NL744guYmJiUaa9bt26F15qamiIiIgJ2dnY4ffo0/Pz8YGpqimnTpgEARowYgbZt22LZsmXQ1dVFUlIS9PX1AQDjx49Hfn4+fvvtN5iYmODcuXOoU6dOuc9JSUlBeno6evfuLZ1TKBTo3r07jhw5grFjxz7FO0BUljb8XBA9j5i0POcuXrwIURTxwgsvVPnaTz75RPq6SZMmmDx5Mn788UfpH+fU1FRMnTpVurejo6PUPzU1FW+88QZcXV0BAE2bNq3wOenp6QAAGxsblfM2Nja4cuVKleMmehJt+Lkgeh5xTstzTvz/hsiCIFT52p9//hndunWDra0t6tSpg1mzZiE1NVVqDwgIwOjRo9GzZ0/MmzcPf//9t9Q2adIkfP755+jatSvmzJmDU6dOPfF5j8YoimK14iZ6Em36uSB6njBpec45OjpCEAQkJydX6bq4uDgMGzYM/fr1w44dO3DixAnMnDkT+fn5Up+goCCcPXsWAwYMQExMDJydnREVFQUAGD16NC5dugQfHx+cPn0aHTp0wOLFi8t9lq2tLYB/Ky6lMjIyylRfiOSgDT8XRM8ljc6ooRqhb9++VZ5w+NVXX4lNmzZV6evr6ysqlcoKnzNs2DBx4MCB5bbNmDFDdHV1LbetdCJuaGiodC4vL48TcUmtavrPxX9xIi49L1hpISxduhRFRUXo1KkTNm/ejL/++gvJyclYtGgR3N3dy72mefPmSE1NRWRkJP7++28sWrRI+msRAHJzczFhwgQcPHgQV65cwR9//IH4+Hi0bNkSAODv749ff/0VKSkpSExMRExMjNT2KEEQ4O/vj+DgYERFReHMmTMYNWoUjI2N4e3tLf8bQoSa/3MBlEwYTkpKwrlz5wAA58+fR1JSUpmqJFGtoemsiWqG69evi+PHjxcbN24sGhgYiA0aNBC9vLzEAwcOSH3wyNLOqVOnipaWlmKdOnXEoUOHimFhYdJflHl5eeKwYcNEe3t70cDAQLSzsxMnTJgg5ubmiqIoihMmTBCbNWsmKhQKsV69eqKPj4948+bNCuMrLi4W58yZI9ra2ooKhUJ8+eWXxdOnT6vjrSCS1PSfizVr1ogAyhxz5sxRw7tBpHmCKP5/xhkRERFRDcbhISIiItIKTFqIiIhIKzBpISIiIq3ApIWIiIi0ApMWIiIi0gpMWoiIiEgrMGkhIiIircCkhagGCQoKQps2baTvR40ahcGDBz/zOC5fvgxBEJCUlFRhnyZNmmDhwoWVvmdERATq1q371LEJgoCtW7c+9X2ISPswaSF6glGjRkEQBAiCAH19fTRt2hRTpkxBTk6O2p/9zTffICIiolJ9K5NoEBFpMz1NB0CkDfr27Ys1a9agoKAAv//+O0aPHo2cnBwsW7asTN+CggLo6+vL8lylUinLfYiIagNWWogqQaFQwNbWFvb29vD29saIESOkIYrSIZ3vvvsOTZs2hUKhgCiKyM7OxpgxY2BtbQ0zMzO8+uqrOHnypMp9582bBxsbG5iamsLX1xcPHz5UaX90eKi4uBihoaFo3rw5FAoFGjVqhC+++AIA4ODgAABo27YtBEGAh4eHdN2aNWvQsmVLGBoa4oUXXsDSpUtVnnPs2DG0bdsWhoaG6NChA06cOFHl92jBggVwdXWFiYkJ7O3tMW7cONy/f79Mv61bt6JFixYwNDREr169cPXqVZX27du3o3379jA0NETTpk0xd+5cFBYWVjkeIqp9mLQQVYORkREKCgqk7y9evIhNmzZh8+bN0vDMgAEDkJ6ejl27diEhIQHt2rVDjx49cPv2bQDApk2bMGfOHHzxxRc4fvw46tevXyaZeFRgYCBCQ0Mxa9YsnDt3Dhs2bICNjQ2AksQDAPbt24e0tDRs2bIFALBy5UrMnDkTX3zxBZKTkxEcHIxZs2Zh7dq1AICcnBx4enrCyckJCQkJCAoKwpQpU6r8nujo6GDRokU4c+YM1q5di5iYGEybNk2lz4MHD/DFF19g7dq1+OOPP3D37l0MGzZMav/111/x9ttvY9KkSTh37hxWrFiBiIgIKTEjouechj+wkajGGzlypDho0CDp+6NHj4qWlpbikCFDRFEUxTlz5oj6+vpiRkaG1Gf//v2imZmZ+PDhQ5V7NWvWTFyxYoUoiqLo7u4uvv/++yrtnTt3Fl988cVyn3337l1RoVCIK1euLDfOlJQUEYB44sQJlfP29vbihg0bVM599tlnoru7uyiKorhixQrRwsJCzMnJkdqXLVtW7r3+q3HjxmJYWFiF7Zs2bRItLS2l70s/kTguLk46l5ycLAIQjx49KoqiKL700kticHCwyn3WrVsn1q9fX/oej3yqMhE9PzinhagSduzYgTp16qCwsBAFBQUYNGgQFi9eLLU3btwY9erVk75PSEjA/fv3YWlpqXKf3Nxc/P333wCA5ORkvP/++yrt7u7uOHDgQLkxJCcnIy8vDz169Kh03JmZmbh69Sp8fX3h5+cnnS8sLJTmyyQnJ+PFF1+EsbGxShxVdeDAAQQHB+PcuXO4e/cuCgsL8fDhQ+Tk5MDExAQAoKenhw4dOkjXvPDCC6hbty6Sk5PRqVMnJCQkID4+XqWyUlRUhIcPH+LBgwcqMRLR84dJC1ElvPLKK1i2bBn09fVhZ2dXZqJt6S/lUsXFxahfvz4OHjxY5l7VXfZrZGRU5WuKi4sBlAwRde7cWaVNV1cXACCKYrXi+a8rV66gf//+eP/99/HZZ5/BwsIChw8fhq+vr8owGlCyZPlRpeeKi4sxd+5cvP7662X6GBoaPnWcRKTdmLQQVYKJiQmaN29e6f7t2rVDeno69PT00KRJk3L7tGzZEnFxcXjnnXekc3FxcRXe09HREUZGRti/fz9Gjx5dpt3AwABASWWilI2NDRo0aIBLly5hxIgR5d7X2dkZ69atQ25urpQYPS6O8hw/fhyFhYX4+uuvoaNTMlVu06ZNZfoVFhbi+PHj6NSpEwDg/PnzuHPnDl544QUAJe/b+fPnq/ReE9Hzg0kLkRr07NkT7u7uGDx4MEJDQ+Hk5ITr169j165dGDx4MDp06IAPP/wQI0eORIcOHdCtWzesX78eZ8+eRdOmTcu9p6GhIaZPn45p06bBwMAAXbt2RWZmJs6ePQtfX19YW1vDyMgI0dHRaNiwIQwNDaFUKhEUFIRJkybBzMwM/fr1Q15eHo4fP46srCwEBATA29sbM2fOhK+vLz755BNcvnwZX331VZVeb7NmzVBYWIjFixdj4MCB+OOPP7B8+fIy/fT19TFx4kQsWrQI+vr6mDBhAtzc3KQkZvbs2fD09IS9vT3eeust6Ojo4NSpUzh9+jQ+//zzqv+HIKJahauHiNRAEATs2rULL7/8Mt577z20aNECw4YNw+XLl6XVPkOHDsXs2bMxffp0tG/fHleuXMEHH3zw2PvOmjULkydPxuzZs9GyZUsMHToUGRkZAErmiyxatAgrVqyAnZ0dBg0aBAAYPXo0Vq1ahYiICLi6uqJ79+6IiIiQlkjXqVMH27dvx7lz59C2bVvMnDkToaGhVXq9bdq0wYIFCxAaGgoXFxesX78eISEhZfoZGxtj+vTp8Pb2hru7O4yMjBAZGSm19+nTBzt27MDevXvRsWNHuLm5YcGCBWjcuHGV4iGi2kkQ5RjQJiIiIlIzVlqIiIhIKzBpISIiIq3ApIWIiIi0ApMWIiIi0gpMWoiIiEgrMGkhIiIircCkhYiIiLQCkxYiIiLSCkxaiIiISCswaSEiIiKtwKSFiIiItAKTFiIiItIK/wMAnGojV/nD2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.04      0.05      1169\n",
      "           1       0.92      0.94      0.93     13662\n",
      "\n",
      "    accuracy                           0.87     14831\n",
      "   macro avg       0.49      0.49      0.49     14831\n",
      "weighted avg       0.85      0.87      0.86     14831\n",
      "\n",
      "====================================================================================\n",
      "Model net performance evaluation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.26      0.10      1266\n",
      "           1       0.01      0.04      0.02       279\n",
      "           2       0.92      0.70      0.79     18455\n",
      "\n",
      "    accuracy                           0.66     20000\n",
      "   macro avg       0.33      0.33      0.31     20000\n",
      "weighted avg       0.85      0.66      0.74     20000\n",
      "\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# classifier 2-A alone\n",
    "print(\"2-A performance evaluation\")\n",
    "perf_evaluate_plot(y_Final_test_2_A, y_Final_test_2_A_pred, n_class=2)\n",
    "\n",
    "# classifier 2-B alone\n",
    "print(\"2-B performance evaluation\")\n",
    "perf_evaluate_plot(y_Final_test_2_B, y_Final_test_2_B_pred, n_class=2)\n",
    "\n",
    "# Net performance\n",
    "print(\"Model net performance evaluation\")\n",
    "perf_evaluate_plot(Final_test_set[\"long_cat\"], Final_test_set[\"2_B_label\"], n_class=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words\n",
    "\n",
    "The result is horrible to say the least. It was much better with the actual dataset for the problem that this model was built to solve. The main reason is the proportion of label 0 in both cases was very small. Although oversampling was used for counterbalancing, it was not effective. It says a lot about the importance of the quality of data for machine learning tasks.\n",
    "\n",
    "Anyways, the idea of this notebook is to demonstrate how to test different algorithms with hyperparameter tuning to train a model and how to evaluate a model that has two-level architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
