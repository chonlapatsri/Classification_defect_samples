{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification with deep learning neural network\n",
    "The idea of this notebook is to demonstrate how to test different algorithms with hyperparameter tuning to train a model and how to evaluate a model that has one-level architecture which is a redacted version on my work on a very specific dataset on a totally unrelated topic.\n",
    "\n",
    "\n",
    "This the Deep Learning neural network for multiclass classification. In order to improve the overall performance of the model, hyperparameter tuning was carried out and at the same time earlystopping and callback were used to prevent overfitting and minimise training time. One Cycle learning rate scheduler technique was also used to get as close to the global optimal as possible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset Preparation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  0\n",
       "0                5.1               3.5                1.4               0.2  0\n",
       "1                4.9               3.0                1.4               0.2  0\n",
       "2                4.7               3.2                1.3               0.2  0\n",
       "3                4.6               3.1                1.5               0.2  0\n",
       "4                5.0               3.6                1.4               0.2  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download IRIS dataset for classification problem\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Display the DataFrame\n",
    "x = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "y = pd.DataFrame(iris.target)\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {0:'species'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'species']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we need to remove any unwanted columns\n",
    "param_to_remove = ['sepal length (cm)', 'sepal length (cm)']\n",
    "for col in df.columns.tolist():\n",
    "    if '(c' in col or 'm)' in col:\n",
    "        param_to_remove.append(col)\n",
    "\n",
    "others_to_remove = []\n",
    "\n",
    "remove_list = param_to_remove + others_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the DataFrame\n",
    "# Display the DataFrame\n",
    "x = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "y = pd.DataFrame(iris.target)\n",
    "\n",
    "df = pd.concat([x, y], axis=1)\n",
    "df = df.rename(columns = {0:'species'})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species Label_1 Label_2 Label_3  \n",
       "0        0       B      A2      B2  \n",
       "1        0       A      A2       C  \n",
       "2        0       C       C       C  \n",
       "3        0       B       D      B2  \n",
       "4        0       A      A2       C  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding three more random label columns\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "new_cols = {'Label_1': np.random.choice(['A', 'B', 'C', 'D'], size=num_rows),\n",
    "            'Label_2': np.random.choice(['A2', 'A2', 'C', 'D'], size=num_rows),\n",
    "            'Label_3': np.random.choice(['B2', 'B', 'C', 'D'], size=num_rows)}\n",
    "\n",
    "df = df.assign(**new_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More columns and rows filtering can be done here, in the original data there are others\n",
    "df[\"Label_2\"] = df.apply(lambda x: 'A' if 'A' in x[\"Label_2\"] else x[\"Label_2\"], axis=1)\n",
    "df[\"Label_3\"] = df.apply(lambda x: 'B' if 'B' in x[\"Label_3\"] else x[\"Label_3\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check for null values, in this case there isn't any because it's a dummy dataset\n",
    "print(df.columns[df.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column that collects every labels that exist in a row (except when it's A) which will be used for stratification\n",
    "key_types = ['species', 'Label_1', 'Label_2', 'Label_3']\n",
    "df[\"labels\"] = df.apply(lambda x: ','.join(x[x.index.isin(key_types)].index\n",
    "                                           [x[x.index.isin(key_types)] != 'A' ]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the df into final_test_set and global_train_set using defect combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: labels, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find row with a unique combination of types that only have one sample which will create problem during split\n",
    "df[\"labels\"].value_counts().loc[lambda x: x<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the row that have unique combination (we will add them to the test set), before dropping them from the main df\n",
    "unique_combination_ind = df[\"labels\"].value_counts().loc[lambda x: x<2].index\n",
    "unique_combination_df = df[df[\"labels\"].isin(unique_combination_ind)]\n",
    "\n",
    "#print(unique_combination_df)\n",
    "\n",
    "# drop rows with unique_combination\n",
    "#print(\"before drop: \", df.shape)\n",
    "df = df.drop(df[df[\"labels\"].isin(unique_combination_ind)].index).reset_index(drop=True)\n",
    "#print(\"after drop: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "# Defect_cat is 0 for without Niv or Nall, 1 for with Niv, Nall, or Both \n",
    "for train_index, test_index in split.split(df, df[\"labels\"]):\n",
    "    Global_train_set = df.loc[train_index]\n",
    "    Final_test_set_original = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species,Label_1,Label_3            11\n",
       "species,Label_1,Label_2,Label_3    11\n",
       "species,Label_2,Label_3             4\n",
       "species,Label_3                     4\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the unique combination rows to the Final_test_set\n",
    "Final_test_set_original = pd.concat([Final_test_set_original, unique_combination_df], ignore_index=True)\n",
    "\n",
    "Final_test_set_original[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the labels colmun from test and train sets\n",
    "Global_train_set = Global_train_set.drop(\"labels\", axis=1)\n",
    "Final_test_set_original = Final_test_set_original.drop(\"labels\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "69                 5.6               2.5                3.9               1.1   \n",
       "132                6.4               2.8                5.6               2.2   \n",
       "31                 5.4               3.4                1.5               0.4   \n",
       "39                 5.1               3.4                1.5               0.2   \n",
       "36                 5.5               3.5                1.3               0.2   \n",
       "\n",
       "     species Label_1 Label_2 Label_3  \n",
       "69         1       C       C       C  \n",
       "132        2       A       A       B  \n",
       "31         0       A       D       C  \n",
       "39         0       B       C       B  \n",
       "36         0       B       C       B  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End final test set split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Multiclass training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Global_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if there is any column that is not numeric \n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "#df_cat.head()\n",
    "\n",
    "# Add categorical columns that are number manually can convert them to categorical type\n",
    "other_cat_col = []\n",
    "df[other_cat_col] = df[other_cat_col].astype(\"category\")\n",
    "#df[other_cat_col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_encoded = ordinal_encoder.fit_transform(df_cat)\n",
    "#print(df_cat_encoded)\n",
    "\n",
    "df[df_cat.columns.tolist()] = df_cat_encoded\n",
    "df[df_cat.columns.tolist()] = df[df_cat.columns.tolist()].astype(\"category\")\n",
    "#df[df_cat.columns.tolist()].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train/Val split (normal split here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[\"species\"]\n",
    "X_train = df.drop(\"species\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Visualisation on train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Oversampling the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35\n",
       "2    34\n",
       "0    27\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.364583\n",
       "2    0.354167\n",
       "0    0.281250\n",
       "Name: species, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check the ratio of the labels\n",
    "y_train.value_counts() / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the size of class is too different, we can use oversampling below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling Counter({1: 35, 2: 34, 0: 27})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print('Before oversampling', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if oversampling:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote = SMOTE(sampling_strategy='not majority', random_state = 42) # sampling_strategy = float only works for Binary \n",
    "    \n",
    "    X_train_pre_transf, y_train_pre_transf = smote.fit_resample(X_train, y_train)\n",
    "    counter = Counter(y_train_pre_transf)\n",
    "    print('After', counter)\n",
    "else:\n",
    "    X_train_pre_transf = X_train\n",
    "    y_train_pre_transf = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "97                 6.2               2.9                4.3               1.3   \n",
       "133                6.3               2.8                5.1               1.5   \n",
       "42                 4.4               3.2                1.3               0.2   \n",
       "91                 6.1               3.0                4.6               1.4   \n",
       "75                 6.6               3.0                4.4               1.4   \n",
       "\n",
       "    Label_1 Label_2 Label_3  \n",
       "97      3.0     2.0     0.0  \n",
       "133     0.0     0.0     0.0  \n",
       "42      2.0     0.0     0.0  \n",
       "91      1.0     2.0     1.0  \n",
       "75      0.0     0.0     1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(X_train_pre_transf[df_cat.columns.tolist()].value_counts())\n",
    "X_train_pre_transf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end of step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set = X_train_pre_transf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs = X_train_set.select_dtypes(include='category').columns.tolist()\n",
    "#print(cat_attribs)\n",
    "\n",
    "X_train_num_lst = X_train_set.drop(cat_attribs, axis=1).columns.tolist()\n",
    "X_train_cat_lst = X_train_set[cat_attribs].columns.tolist()\n",
    "\n",
    "#print(X_train_num_lst)\n",
    "#print(X_train_cat_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforamtion class to add, combine, fuse, extract features for the numeric PL\n",
    "# stat_feature_head_to_tail is to use only the absolute 'ab_maximum' or 'average' value of each statistical features  \n",
    "class Attrib_transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stat_features = 'ab_maximum'):\n",
    "        self.stat_features = stat_features\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.stat_features is not None:\n",
    "            stat_feature = ['sepal', 'petal']\n",
    "            measurement = ['length', 'width']\n",
    "            \n",
    "            new_X = X.copy() # so the original df is not changed\n",
    "            # See the commnad line argument and match it to pre-defined case \n",
    "            match self.stat_features:\n",
    "                case 'ab_maximum':\n",
    "                    for stat in stat_features:\n",
    "                        meaurement_list= []\n",
    "                        for measure in measurement:                            \n",
    "                            # create a list of all measurement of each feature\n",
    "                            temp = stat + ' ' + measure + ' (cm)'\n",
    "                            meaurement_list.append(temp)\n",
    "                            \n",
    "                        \n",
    "                        # Get the absolute maximum value of each row, keep the sign, and put them in a new colmun\n",
    "                        col_name = measure + '_' + self.stat_features\n",
    "                        row_max = X[meaurement_list].abs().max(axis=1)\n",
    "                        new_X[col_name] = X[meaurement_list].max(axis=1).mask(lambda x: x < row_max, -row_max)\n",
    "                        new_X = new_X.drop(meaurement_list, axis=1)\n",
    "                \n",
    "                case 'average':\n",
    "                    for stat in stat_feature:\n",
    "                        meaurement_list= []\n",
    "                        for measure in measurement:                            \n",
    "                            # create a list of all measurement of each feature\n",
    "                            temp = stat + ' ' + measure + ' (cm)'\n",
    "                            meaurement_list.append(temp)\n",
    "                            \n",
    "                        # Get the mean value of each row and put them in a new colmun \n",
    "                        col_name = measure + '_' + self.stat_features\n",
    "                        new_X[col_name] = X[meaurement_list].mean(axis=1)\n",
    "                        new_X = new_X.drop(meaurement_list, axis=1)\n",
    "                    \n",
    "                case _:   # 'case _' is for any other input that does not match None or the above\n",
    "                    sys.exit(\"please choose from 'ab_maximum', 'average', or \\\n",
    "                    'None' for stat_featurs in Attrib_transformer\")\n",
    "                \n",
    "            #print(list(new_X.columns))\n",
    "            return new_X\n",
    "            \n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transforamtion class to drop unwanted features\n",
    "class Attrib_drop(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d_list=[], keep_only_length=False):\n",
    "        self.d_list = d_list\n",
    "        self.keep_only_length = keep_only_length\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.keep_only_length:\n",
    "            Vert_acc_indices = []\n",
    "            for i, col in enumerate(X.columns):\n",
    "                if 'length' in col:\n",
    "                    length_indices.append(i)\n",
    "            return X.iloc[:,length_indices]\n",
    "        elif self.d_list:\n",
    "            keep_indices = []\n",
    "            for i, col in enumerate(X.columns):\n",
    "                if col not in self.d_list:\n",
    "                    keep_indices.append(i)\n",
    "            return X.iloc[:,keep_indices]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the numerical features to be dropped to manually drop columns from the df\n",
    "drop_list_num = [] # Here we can add columns that should be dropped from the df\n",
    "\n",
    "num_pl = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attrib_transform', Attrib_transformer(stat_features= None)),\n",
    "    ('attrib_drop', Attrib_drop(keep_only_length=False, d_list=drop_list_num)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "#For testing num_pl\n",
    "#num_prep = num_pl.fit_transform(X_train_set[X_train_num_lst])\n",
    "#print('shape after transformation: ', num_prep.shape)\n",
    "#num_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the categorical features to be dropped to manually drop columns from the df\n",
    "drop_list_cat = ['Lane']\n",
    "\n",
    "cat_pl = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('attrib_drop', Attrib_drop(d_list=drop_list_cat)),\n",
    "    ('One_Hot', OneHotEncoder(sparse_output=False)),\n",
    "])\n",
    "\n",
    "# For testing cat_pl\n",
    "#cat_prep = cat_pl.fit_transform(X_train_set[X_train_cat_lst])\n",
    "#cat_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_pl = ColumnTransformer([\n",
    "    (\"num\", num_pl, X_train_num_lst),\n",
    "    (\"cat\", cat_pl, X_train_cat_lst),\n",
    "])\n",
    "\n",
    "X_train_prep = full_pl.fit_transform(X_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after transformation:  (96, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.38410194, -0.38865542,  0.22497286, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.51081598, -0.64420967,  0.7035855 , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.89675082,  0.37800732, -1.56982451, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.00975252, -1.41087241, -0.55277266, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.13646656,  0.88911582, -1.39034477, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.7779564 , -0.38865542,  1.42150444, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape after transformation: ', X_train_prep.shape)\n",
    "X_train_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 OPTIONAL: PCA for unsupervised feature selectiion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components:  7\n"
     ]
    }
   ],
   "source": [
    "use_PCA = True\n",
    "\n",
    "if use_PCA:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
    "              svd_solver='auto', tol=0.0, whiten=False)\n",
    "    \n",
    "    X_train_prep = pca.fit_transform(X_train_prep)\n",
    "    print('number of components: ', pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after transformation:  (96, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.78709166e-01, -1.93324252e-01,  1.89616821e-02,\n",
       "         1.05439574e+00, -5.96767886e-02,  3.50796520e-01,\n",
       "        -4.67428094e-01],\n",
       "       [ 1.00876542e+00, -4.65271362e-01, -9.15504150e-01,\n",
       "        -2.29969164e-01,  5.56465353e-01, -3.29285333e-01,\n",
       "         5.43700751e-02],\n",
       "       [-2.84783031e+00, -5.21531690e-01, -6.10356986e-01,\n",
       "         9.12142287e-03, -5.97634418e-01, -3.40609864e-02,\n",
       "         7.10563185e-01],\n",
       "       [ 4.87120370e-01,  1.32342662e-01,  8.71583469e-01,\n",
       "         3.29588135e-02, -5.50094507e-01, -5.64727357e-01,\n",
       "        -8.22095400e-01],\n",
       "       [ 7.73251757e-01,  1.75675233e-01,  1.34932346e-01,\n",
       "        -1.14448548e+00,  5.71262220e-01, -4.23108563e-01,\n",
       "        -1.03126852e-01],\n",
       "       [ 9.55411309e-01,  4.84988913e-01,  1.54675322e-01,\n",
       "        -1.11482113e+00, -5.09437966e-01, -3.28274271e-02,\n",
       "        -4.21394936e-01],\n",
       "       [ 1.92554165e+00,  9.91013519e-01, -9.45482387e-01,\n",
       "        -1.27940973e-01, -6.37815896e-01,  3.42262761e-03,\n",
       "        -2.50857653e-01],\n",
       "       [ 1.44717393e+00,  1.19067607e+00,  7.69237947e-01,\n",
       "        -1.79811049e-01,  9.42025543e-01, -4.53720003e-01,\n",
       "         2.23781505e-01],\n",
       "       [ 1.75698496e+00,  8.56403356e-01,  6.13311700e-01,\n",
       "         6.12364138e-01, -4.51642451e-01, -2.56085869e-01,\n",
       "         3.46664574e-01],\n",
       "       [ 1.98976438e+00,  8.92124397e-01,  1.06441385e+00,\n",
       "         6.35478501e-03,  3.96855876e-01,  6.99367119e-01,\n",
       "         1.48312819e-01],\n",
       "       [ 1.40353428e+00,  3.12988311e-01, -3.06802260e-01,\n",
       "         8.48034538e-01,  5.12996272e-01, -8.18773235e-01,\n",
       "        -3.33011930e-01],\n",
       "       [ 1.93188511e-01, -1.18083863e+00, -8.24070497e-01,\n",
       "        -1.62010894e-01, -5.29958757e-01,  7.57187534e-03,\n",
       "        -2.79399671e-01],\n",
       "       [-2.56188054e+00,  1.21751617e+00, -1.92964669e-01,\n",
       "         5.45489506e-01,  5.30145958e-02,  2.74028321e-01,\n",
       "         9.87872408e-01],\n",
       "       [ 2.17204016e+00,  1.96578494e+00, -8.09118065e-01,\n",
       "        -6.63152818e-02, -5.75201804e-01, -1.27325554e-02,\n",
       "         8.68321102e-01],\n",
       "       [-6.55523454e-02, -3.15449802e-01,  2.41951626e-01,\n",
       "        -9.75020254e-01,  4.58884528e-01, -5.32457051e-01,\n",
       "        -1.23464492e-01],\n",
       "       [ 1.26214673e+00,  2.07123424e-01, -9.85038558e-01,\n",
       "        -2.89500712e-01,  5.65004303e-01, -2.83474985e-01,\n",
       "         5.00100235e-02],\n",
       "       [-2.62625773e+00,  6.85423900e-01,  1.25780231e-01,\n",
       "        -1.14484645e+00,  4.87742948e-01, -3.30719577e-01,\n",
       "        -2.62114938e-01],\n",
       "       [ 9.34135993e-01, -7.87661473e-01,  6.39561505e-01,\n",
       "        -5.47056440e-01, -2.59162676e-01,  4.19411102e-01,\n",
       "        -1.63777194e-01],\n",
       "       [-2.57822055e+00, -5.14911534e-01, -2.09141983e-01,\n",
       "         8.56145436e-01, -5.68550010e-01, -3.56877186e-01,\n",
       "        -8.06418315e-01],\n",
       "       [ 7.12305202e-02, -1.15836471e+00,  4.76928251e-01,\n",
       "         2.10103566e-01,  1.16863553e+00,  4.28422196e-03,\n",
       "         2.02568759e-01],\n",
       "       [ 4.58593619e-02, -5.03555832e-01,  7.36228992e-01,\n",
       "         6.74471621e-01, -4.46184559e-01, -2.80706574e-01,\n",
       "         3.01425419e-01],\n",
       "       [ 3.18499984e-01, -1.34965042e-01,  2.53890230e-01,\n",
       "        -9.64678651e-01, -6.05318817e-01, -1.49577793e-01,\n",
       "        -4.28468910e-01],\n",
       "       [ 1.10404817e+00, -9.55713481e-01,  5.82638041e-02,\n",
       "         8.35553603e-01,  4.94047100e-01,  8.54550031e-01,\n",
       "         2.79119356e-01],\n",
       "       [-2.69171716e+00, -1.88960538e-01,  1.08004855e+00,\n",
       "        -1.19471396e-01, -1.14324519e-02, -5.55196301e-02,\n",
       "         8.89293295e-01],\n",
       "       [-2.85334750e+00, -9.45608835e-01,  1.24776811e+00,\n",
       "         3.31210635e-01, -1.70113719e-01,  1.51525573e-01,\n",
       "        -7.21254128e-01],\n",
       "       [ 1.06000659e+00, -3.75261291e-01,  7.21698572e-01,\n",
       "         4.49925701e-01,  5.24619001e-01,  1.12158770e+00,\n",
       "         1.27695080e-01],\n",
       "       [ 1.22590938e+00,  4.82443612e-01, -3.13222401e-01,\n",
       "         8.33486486e-01,  5.23532947e-01, -7.81268053e-01,\n",
       "        -3.48359744e-01],\n",
       "       [-6.09527481e-01, -2.18623045e+00, -4.24339802e-01,\n",
       "         2.22903241e-01, -1.66663453e-01,  6.20324924e-01,\n",
       "        -6.93221157e-02],\n",
       "       [ 5.90868175e-01,  9.37687788e-01,  3.83855925e-01,\n",
       "         4.18108840e-01, -4.60515478e-01, -5.58964901e-02,\n",
       "        -8.47879086e-01],\n",
       "       [ 1.08462106e+00, -1.85432779e+00, -5.57174347e-01,\n",
       "         1.96197665e-02, -4.76459372e-01, -1.78485773e-01,\n",
       "         9.13067801e-01],\n",
       "       [-2.37040774e+00,  1.71149857e+00, -4.54020537e-01,\n",
       "         3.80576881e-01,  7.75959284e-03,  4.07341366e-01,\n",
       "        -1.50951460e-01],\n",
       "       [ 2.29077605e+00,  2.78174839e+00, -2.44508664e-01,\n",
       "         8.28496816e-01,  5.88138054e-03,  5.82369899e-01,\n",
       "        -4.68309449e-01],\n",
       "       [ 1.96802929e+00,  8.39088932e-01, -9.62728126e-01,\n",
       "        -1.93220176e-01, -5.78198758e-01,  4.83103782e-02,\n",
       "        -2.48721568e-01],\n",
       "       [-4.64345674e-01, -2.32615115e+00,  7.11131011e-01,\n",
       "        -6.00165228e-01, -1.68447518e-01,  4.39664188e-01,\n",
       "        -1.91193200e-01],\n",
       "       [-2.07967071e-01, -4.95253850e-01,  5.16177572e-01,\n",
       "        -7.76896694e-01, -5.93338682e-01, -2.93624250e-01,\n",
       "         6.94752635e-01],\n",
       "       [-2.18475667e+00,  1.59637022e+00, -5.15035569e-01,\n",
       "         2.80383430e-01,  1.13985155e+00,  6.79743822e-02,\n",
       "         1.75706760e-01],\n",
       "       [-2.50825957e+00, -6.67530801e-01,  8.27030457e-01,\n",
       "        -3.41871274e-01,  1.08492545e+00, -3.10073434e-01,\n",
       "         8.90391350e-02],\n",
       "       [ 1.21715021e+00, -2.07153677e+00, -4.70383831e-01,\n",
       "         1.45967742e-01, -7.88516752e-02,  6.44679006e-01,\n",
       "         3.14353623e-03],\n",
       "       [-2.45656223e+00, -2.88143493e-01, -9.50779012e-01,\n",
       "        -3.11095391e-01,  5.33394231e-01, -2.12965669e-01,\n",
       "        -9.84031181e-02],\n",
       "       [ 2.88586014e+00,  3.01609821e-01,  1.04185466e-01,\n",
       "        -1.19138687e+00,  6.47706310e-01, -4.15302592e-01,\n",
       "        -1.93921936e-02],\n",
       "       [ 1.70761296e+00, -3.66150032e-01, -8.91903771e-01,\n",
       "        -1.37478353e-01,  4.86792310e-01, -4.20044868e-01,\n",
       "         8.80780399e-02],\n",
       "       [-2.39314781e+00, -5.74313609e-01, -2.03323141e-01,\n",
       "        -6.58902968e-01,  6.07494001e-01,  4.19749777e-02,\n",
       "        -2.32104622e-01],\n",
       "       [ 1.87300892e+00,  1.02447160e+00,  3.50225143e-01,\n",
       "        -9.69204782e-01, -4.72081035e-01, -1.29925980e-01,\n",
       "         7.38529740e-01],\n",
       "       [ 1.17105091e+00, -1.70728631e-01,  1.84995691e-01,\n",
       "        -1.12806098e+00, -4.63048963e-01, -4.78871054e-02,\n",
       "        -3.97762109e-01],\n",
       "       [-2.47141223e+00,  3.89313616e-01, -3.57093651e-01,\n",
       "         4.34829754e-01,  2.97333405e-02,  3.28600581e-01,\n",
       "        -1.23029294e-01],\n",
       "       [ 9.68355030e-01, -7.14251722e-01,  1.18701954e+00,\n",
       "         5.98508832e-02,  4.23939760e-01,  6.43394547e-01,\n",
       "         1.40870003e-01],\n",
       "       [-2.08235765e+00,  7.39014665e-02, -6.86623131e-01,\n",
       "        -7.35695615e-02, -5.56932799e-01,  1.79026765e-02,\n",
       "         7.28651658e-01],\n",
       "       [-2.32278132e+00, -7.99438166e-01, -1.87757730e-01,\n",
       "        -6.39650224e-01,  5.98971248e-01,  9.31442079e-03,\n",
       "        -2.21335066e-01],\n",
       "       [ 2.77800675e+00,  7.86809359e-01,  7.66402296e-02,\n",
       "        -1.16801356e+00,  5.89878908e-01, -4.38012625e-01,\n",
       "        -2.99451494e-02],\n",
       "       [ 1.09670826e+00, -7.53531118e-01,  1.26845803e+00,\n",
       "         4.53043420e-01, -1.98388261e-01, -1.10573194e-02,\n",
       "        -5.51099303e-01],\n",
       "       [-7.59391921e-02, -7.84653646e-01, -2.06240863e-02,\n",
       "         7.09533041e-01,  7.92214074e-02,  5.13370324e-02,\n",
       "         1.14503560e+00],\n",
       "       [ 1.94178883e+00,  5.18200091e-01, -9.21970428e-01,\n",
       "        -1.33184647e-01, -6.11290242e-01, -9.47659236e-03,\n",
       "        -2.39312150e-01],\n",
       "       [-2.29592661e+00, -6.35414644e-01, -5.95979931e-01,\n",
       "         7.10280704e-04, -1.07358902e-01,  8.62058046e-01,\n",
       "        -1.85461284e-01],\n",
       "       [-2.44078164e+00,  1.95395619e+00, -1.16304450e+00,\n",
       "        -5.20413227e-01,  5.81857971e-01,  8.50366503e-03,\n",
       "        -1.57005278e-01],\n",
       "       [-2.56792161e-01, -1.03524636e+00,  3.99564032e-02,\n",
       "         1.02670001e+00, -4.84631585e-01, -5.54308312e-01,\n",
       "         4.42686319e-01],\n",
       "       [ 1.57871973e+00,  1.21535091e+00,  1.03955530e+00,\n",
       "         2.08280251e-01, -5.70324593e-01, -6.88719245e-01,\n",
       "         3.37524437e-01],\n",
       "       [ 5.12000642e-01, -2.03848850e-01, -2.68097661e-01,\n",
       "         8.51947453e-01,  5.24107376e-01, -8.11191615e-01,\n",
       "        -3.60938558e-01],\n",
       "       [ 2.44486207e+00,  3.32765855e-02, -6.85566035e-01,\n",
       "        -7.38809750e-02,  6.24254845e-03,  8.43903836e-01,\n",
       "        -4.97252747e-04],\n",
       "       [-2.21927890e+00,  6.14428887e-01,  9.75847740e-01,\n",
       "        -2.59410408e-01,  6.50359121e-02,  6.35234593e-02,\n",
       "         8.85413918e-01],\n",
       "       [ 9.23705535e-01, -1.07915597e-02,  2.56364349e-01,\n",
       "        -9.37432041e-01, -6.19361766e-01, -1.75418360e-01,\n",
       "        -4.04641472e-01],\n",
       "       [-2.21547238e+00, -5.73307918e-01, -2.75657277e-01,\n",
       "         7.55661880e-01,  5.62429747e-01, -7.00824266e-01,\n",
       "        -4.72913893e-01],\n",
       "       [ 3.42940632e-01,  9.40220518e-01,  1.11712879e+00,\n",
       "         3.02714235e-01, -1.79018067e-01,  1.70813161e-01,\n",
       "        -6.28810824e-01],\n",
       "       [ 1.04717605e+00,  7.61555728e-01, -4.35975458e-02,\n",
       "        -5.41181010e-01,  8.53123606e-02,  1.23318517e+00,\n",
       "        -2.22291861e-01],\n",
       "       [-2.57673580e+00,  5.11866686e-01, -1.87013152e-02,\n",
       "        -5.12534883e-01, -4.65139896e-01,  3.64260925e-01,\n",
       "         5.52478109e-01],\n",
       "       [ 1.79151886e+00,  3.31981703e-01, -3.92696117e-02,\n",
       "         8.34603148e-01,  4.14839395e-01,  8.33939019e-01,\n",
       "         2.87963074e-01],\n",
       "       [-2.67265931e+00,  2.42325617e+00,  5.08839892e-01,\n",
       "         4.49214591e-01,  1.47139627e-03,  9.39745009e-01,\n",
       "        -8.13915420e-01],\n",
       "       [ 2.51841242e-01, -7.73451974e-01, -8.65054073e-01,\n",
       "        -1.61067149e-01,  5.06847120e-01, -3.71171559e-01,\n",
       "         3.11535638e-02],\n",
       "       [ 2.11326173e-01, -3.41264927e-01, -8.74341519e-01,\n",
       "        -1.21952675e-01,  4.53287949e-01, -3.88375643e-01,\n",
       "         2.16922090e-02],\n",
       "       [ 1.18439343e+00, -1.30243290e+00,  1.80071719e-01,\n",
       "         1.31132589e+00, -1.91772429e-01,  1.06966470e-01,\n",
       "        -4.00180041e-01],\n",
       "       [ 1.41142776e-01, -6.11534143e-01, -5.62571495e-01,\n",
       "         1.04453046e-01, -1.37005045e-01,  7.45796560e-01,\n",
       "        -7.86060285e-02],\n",
       "       [ 4.81913220e-02, -3.82593204e-01, -5.82481564e-01,\n",
       "         1.18905862e-01, -6.28152375e-01, -1.59085868e-01,\n",
       "         8.34512761e-01],\n",
       "       [ 1.34052682e+00, -4.37191520e-01, -1.43238909e-01,\n",
       "         1.09417367e+00, -6.92448819e-01, -6.27243954e-01,\n",
       "        -6.26679842e-01],\n",
       "       [-2.40343222e+00,  1.36886104e+00, -3.55490233e-01,\n",
       "         7.53977692e-01, -5.77506099e-01, -2.22504538e-01,\n",
       "        -8.46723077e-01],\n",
       "       [-1.34107043e-01, -1.80721101e+00, -7.73510996e-01,\n",
       "        -1.30596267e-01, -5.27791358e-01, -2.61381926e-02,\n",
       "        -2.78328451e-01],\n",
       "       [ 1.80872213e+00,  2.74867514e-01,  1.12298048e+00,\n",
       "         5.89743479e-02,  3.85852140e-01,  6.48579881e-01,\n",
       "         1.56117157e-01],\n",
       "       [ 1.78402757e+00, -3.58097241e-01, -8.87541646e-01,\n",
       "        -1.20688005e-01,  4.72719452e-01, -4.37386567e-01,\n",
       "         9.25432149e-02],\n",
       "       [ 8.66230773e-01, -1.91523971e-01, -5.79728815e-01,\n",
       "         1.36908328e-01, -1.73586604e-01,  7.12823996e-01,\n",
       "        -5.43074820e-02],\n",
       "       [ 5.72887183e-01,  5.69113169e-01,  1.11839382e+00,\n",
       "         2.99222511e-01, -6.25790317e-01, -7.53973571e-01,\n",
       "         3.12519050e-01],\n",
       "       [-2.07404412e+00,  6.07362271e-01,  7.57419138e-01,\n",
       "        -1.28281344e-01,  5.37319350e-01, -8.03141011e-01,\n",
       "        -6.26109058e-01],\n",
       "       [ 8.13852650e-01, -8.80712437e-02, -9.46797363e-01,\n",
       "        -3.06909699e-01, -4.60603560e-01,  1.37221462e-01,\n",
       "        -2.83871199e-01],\n",
       "       [-1.77893947e-01, -1.18647368e+00, -5.29864048e-01,\n",
       "         1.48078193e-01, -6.22448793e-01, -2.12959419e-01,\n",
       "         8.46466619e-01],\n",
       "       [ 5.53045819e-01,  6.52228481e-01, -4.04364436e-01,\n",
       "         4.49919517e-01,  1.10988093e+00, -1.38343187e-01,\n",
       "         3.21203408e-01],\n",
       "       [ 2.79313491e-01, -1.96952710e+00,  3.92198596e-01,\n",
       "        -8.77384065e-01, -5.82951208e-01, -2.71056573e-01,\n",
       "        -3.84649150e-01],\n",
       "       [-2.45659182e+00,  1.46960115e-01,  2.24405647e-01,\n",
       "        -1.04906367e+00, -5.96156559e-01, -5.88321210e-03,\n",
       "        -5.60604444e-01],\n",
       "       [-2.48390365e+00,  1.60085457e+00, -8.22419710e-01,\n",
       "        -1.98314225e-01, -5.45844971e-01,  1.62929299e-01,\n",
       "         6.71957811e-01],\n",
       "       [ 8.79827951e-02, -8.53066132e-01,  7.40711146e-01,\n",
       "         4.13345935e-01,  5.61411037e-01,  1.15887583e+00,\n",
       "         9.42823877e-02],\n",
       "       [ 1.44274460e+00,  8.08726863e-01, -4.14149056e-02,\n",
       "         1.10842970e+00, -6.10605626e-01, -5.98638301e-01,\n",
       "         4.78440524e-01],\n",
       "       [ 2.10298272e+00,  7.12660965e-01,  1.04100562e+00,\n",
       "         1.56174808e-01, -5.00028197e-01, -6.83100340e-01,\n",
       "         3.70497576e-01],\n",
       "       [-2.51331778e+00,  4.76815327e-01, -9.66917252e-01,\n",
       "        -3.14182649e-01, -5.46587617e-01,  2.24633557e-01,\n",
       "        -4.39414999e-01],\n",
       "       [ 1.52944436e+00, -5.71918195e-01,  2.41060172e-01,\n",
       "        -9.81461654e-01,  4.99291579e-01, -5.79048338e-01,\n",
       "        -4.73723647e-02],\n",
       "       [ 7.90571151e-01, -2.53934021e-02, -2.92221992e-01,\n",
       "         6.23727020e-01,  1.02072220e+00, -2.82830048e-01,\n",
       "         3.52312139e-01],\n",
       "       [-7.58965176e-03, -3.47357543e-01,  1.20165864e-01,\n",
       "        -3.21303514e-01, -3.85199281e-02,  1.07291718e+00,\n",
       "        -2.35959135e-01],\n",
       "       [-2.64877712e+00,  3.25010624e-01,  1.04413459e+00,\n",
       "        -1.45891228e-01, -1.04737283e-02, -1.23848413e-02,\n",
       "         8.76797616e-01],\n",
       "       [-6.54154026e-01, -1.60581924e+00, -1.48326519e-01,\n",
       "         9.52774299e-01,  4.86855030e-01, -9.17690152e-01,\n",
       "        -3.72743032e-01],\n",
       "       [-2.33378592e+00,  4.70269710e-01,  1.07447138e+00,\n",
       "         1.53359979e-01, -5.68689706e-01, -5.98977651e-01,\n",
       "         1.85351355e-01],\n",
       "       [ 2.30020519e+00,  2.50368073e-01,  1.25012238e-02,\n",
       "        -4.75935201e-01,  9.31195918e-02,  1.15865965e+00,\n",
       "        -1.56829471e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('shape after transformation: ', X_train_prep.shape)\n",
    "X_train_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Transform X_val as well using the pipeline that has been fitted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components:  7\n",
      "shape after transformation:  (24, 7)\n"
     ]
    }
   ],
   "source": [
    "#Transform the X_test as the train set has been transformed\n",
    "X_val_prep = full_pl.transform(X_val)\n",
    "#print('shape before PCA: ', X_train_prep.shape)\n",
    "\n",
    "if use_PCA:\n",
    "    X_val_prep = pca.transform(X_val_prep)\n",
    "    print('number of components: ', pca.n_components_)\n",
    "\n",
    "print('shape after transformation: ', X_val_prep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from hyperopt import hp, tpe, fmin, STATUS_OK, Trials, space_eval\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for onecycle learning rate rescheduler\n",
    "K = keras.backend\n",
    "\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_prep.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_neurons, rho, dropout_rate, inputshape=input_size):\n",
    "    \"\"\"\n",
    "    Function to build the neural network model based on the provided hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        params (dict): Dictionary containing the hyperparameters.\n",
    "        inputshape (int): Number of input features.\n",
    "    \n",
    "    Returns:\n",
    "        model (Sequential): Compiled Keras model.\n",
    "    \"\"\"\n",
    "    #print(n_hidden, n_neurons, rho, dropout_rate)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(n_neurons, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=(inputshape,))\n",
    "    ])\n",
    "\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "        model.add(keras.layers.AlphaDropout(rate=dropout_rate))  # Add AlphaDropout layer with specified dropout rate\n",
    "\n",
    "    model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.RMSprop(rho=rho)\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization. Calculates the loss value (1 - accuracy) based on cross-validation.\n",
    "    \n",
    "    Args:\n",
    "        params (dict): Dictionary containing the hyperparameters.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the loss value, status, and cross-validation score.\n",
    "    \"\"\" \n",
    "    mod_params = params.copy()\n",
    "    mod_params.pop('max_lr')\n",
    "    mod_params.pop('batch_size')\n",
    "    n_epochs = 1000\n",
    "    model = build_model(**mod_params)\n",
    "    \n",
    "    #print(\"params['batch_size']: \", params['batch_size'])\n",
    "    #print(\"params['max_lr']: \", params['max_lr'])\n",
    "    print(params)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=20, \n",
    "                               restore_best_weights = False)  # Define early stopping callback\n",
    "    \n",
    "    onecycle = OneCycleScheduler(math.ceil(len(X_train) / params['batch_size']) * n_epochs, max_rate=params['max_lr'])\n",
    "    \n",
    "    model_file = \"best_weights.h5\" # File to save the best weights\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_file, monitor=\"val_loss\", mode=\"min\", \n",
    "                                                    save_best_only=True, verbose=1) # Define checkpoint to save best weights\n",
    "    \n",
    "    history = model.fit(X_train_prep, y_train_pre_transf, callbacks=[early_stop, checkpoint, onecycle], \n",
    "                        validation_data=(X_val_prep, y_val), epochs=n_epochs, batch_size=params['batch_size'], verbose=0)\n",
    "    \n",
    "    model.load_weights(model_file) # reload the best weights saved by checkpoint\n",
    "    \n",
    "    loss = history.history['loss'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    \n",
    "    return {'loss': val_loss, 'train_loss': loss, 'status': STATUS_OK, 'model': model, 'history': history} \n",
    "    # switch places of the loss varaible so that hyperopt select the best yperparameter based on val_loss instead of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout_rate': 0.37690446216767304, 'max_lr': 0.03373909723766116, 'n_hidden': 9, 'n_neurons': 64, 'rho': 0.7077285727937878}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.37978, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 1.37978 to 1.01889, saving model to best_weights.h5\n",
      "\n",
      "  0%|                               | 0/46 [00:02<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chonl\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 3: val_loss improved from 1.01889 to 0.81255, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.81255 to 0.71043, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.71043 to 0.70457, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.70457\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.70457\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.39568230609296084, 'max_lr': 0.03333562960073355, 'n_hidden': 4, 'n_neurons': 32, 'rho': 0.8016208517899654}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.85636, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.85636 to 0.52407, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.52407 to 0.44739, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.44739 to 0.42017, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.42017 to 0.40985, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.40985\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.40985\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.2149720480097515, 'max_lr': 0.04000528063635955, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.838185921484868}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.88734, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.88734 to 0.72649, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.72649 to 0.65925, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.65925 to 0.65687, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.65687\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.65687\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.65687\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.65687\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.65687\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.65687\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss improved from 0.65687 to 0.52105, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss improved from 0.52105 to 0.48023, saving model to best_weights.h5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.48023\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss improved from 0.48023 to 0.47623, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.47623\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.47623\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.47623\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss improved from 0.47623 to 0.44385, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.44385\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.44385\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.44385\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.44385\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.44385\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss improved from 0.44385 to 0.44080, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss improved from 0.44080 to 0.43780, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 52: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 54: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 55: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 56: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 57: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 58: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 59: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 60: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 61: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 62: val_loss did not improve from 0.43780\n",
      "\n",
      "                                                                           \n",
      "Epoch 63: val_loss did not improve from 0.43780\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.33994995345482637, 'max_lr': 0.0371746755371364, 'n_hidden': 14, 'n_neurons': 32, 'rho': 0.8368914184410532}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.54009, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 1.54009 to 1.39540, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 1.39540 to 1.22127, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 1.22127 to 1.10515, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 1.10515 to 1.04427, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss improved from 1.04427 to 1.04394, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss improved from 1.04394 to 1.02193, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 1.02193\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 1.02193\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.11183695208513333, 'max_lr': 0.037213285383966024, 'n_hidden': 14, 'n_neurons': 32, 'rho': 0.7950487182163115}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.58236, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.58236\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.58236\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.58236\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.58236\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.58236\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.58236\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss improved from 0.58236 to 0.53572, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss improved from 0.53572 to 0.45549, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.45549\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.45549\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.45549\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss improved from 0.45549 to 0.44589, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss improved from 0.44589 to 0.44398, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.44398\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.44398\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.44398\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss improved from 0.44398 to 0.44143, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss improved from 0.44143 to 0.43588, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.43588\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.43588\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss improved from 0.43588 to 0.43329, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.43329\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss improved from 0.43329 to 0.42699, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss improved from 0.42699 to 0.42614, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss did not improve from 0.42614\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss improved from 0.42614 to 0.38643, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.38643\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 52: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 54: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 55: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 56: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 57: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 58: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 59: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 60: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 61: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 62: val_loss did not improve from 0.38643\n",
      "\n",
      "                                                                           \n",
      "Epoch 63: val_loss did not improve from 0.38643\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.26985708464793356, 'max_lr': 0.03629665272241746, 'n_hidden': 14, 'n_neurons': 128, 'rho': 0.8190895528477803}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.66073, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.66073 to 0.59901, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.59901 to 0.50849, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.50849 to 0.50838, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.50838 to 0.40769, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.40769\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.40769\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.30490808595576074, 'max_lr': 0.04569511770351139, 'n_hidden': 14, 'n_neurons': 64, 'rho': 0.7331880630247597}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.54867, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 1.54867\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 1.54867\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 1.54867 to 1.30074, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 1.30074 to 0.89287, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss improved from 0.89287 to 0.77574, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.77574\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss improved from 0.77574 to 0.72120, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss improved from 0.72120 to 0.58366, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss improved from 0.58366 to 0.50706, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss improved from 0.50706 to 0.50348, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.50348\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.50348\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.34583539098114513, 'max_lr': 0.03324301810301523, 'n_hidden': 4, 'n_neurons': 64, 'rho': 0.7156359549205145}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.93314, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.93314\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss improved from 0.93314 to 0.78851, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss improved from 0.78851 to 0.68123, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.68123\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.68123\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.3484486017825073, 'max_lr': 0.04606944438510647, 'n_hidden': 9, 'n_neurons': 64, 'rho': 0.9068462107093114}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.68422, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.68422 to 0.44772, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.44772 to 0.35460, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.35460\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.35460\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.35460\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.3291152262739249, 'max_lr': 0.04165986181537438, 'n_hidden': 4, 'n_neurons': 128, 'rho': 0.9026359543029379}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.82441, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.82441\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.82441\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.25804437190026186, 'max_lr': 0.04276345879532645, 'n_hidden': 9, 'n_neurons': 128, 'rho': 0.7391921107087897}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.59666, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.59666\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.59666\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.15250349060996263, 'max_lr': 0.038274610809247545, 'n_hidden': 4, 'n_neurons': 64, 'rho': 0.9188956054472194}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.52948, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.52948\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.52948\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.52948\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.52948 to 0.41380, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.41380\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss improved from 0.41380 to 0.39707, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss improved from 0.39707 to 0.27966, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.27966\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.27966\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.3597552918390631, 'max_lr': 0.03497136400193834, 'n_hidden': 14, 'n_neurons': 64, 'rho': 0.8631565223077794}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.05194, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 1.05194 to 1.00655, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 1.00655\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss improved from 1.00655 to 0.97167, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss improved from 0.97167 to 0.91674, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss improved from 0.91674 to 0.88842, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss improved from 0.88842 to 0.88832, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.88832\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.88832\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss improved from 0.88832 to 0.86965, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss improved from 0.86965 to 0.80509, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 52: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 54: val_loss did not improve from 0.80509\n",
      "\n",
      "                                                                           \n",
      "Epoch 55: val_loss did not improve from 0.80509\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.28747218294881505, 'max_lr': 0.04187037011246304, 'n_hidden': 14, 'n_neurons': 128, 'rho': 0.7714630524375318}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.65940, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 1.65940 to 0.97294, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.97294\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss improved from 0.97294 to 0.45508, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.45508\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss improved from 0.45508 to 0.44312, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.44312\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.44312\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.44312\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.3016263809313312, 'max_lr': 0.031109958265912535, 'n_hidden': 14, 'n_neurons': 64, 'rho': 0.7023936012267143}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.93752, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.93752\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.93752\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.93752\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.93752\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss improved from 0.93752 to 0.89597, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss improved from 0.89597 to 0.89401, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.89401\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.89401\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss improved from 0.89401 to 0.85341, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss improved from 0.85341 to 0.84424, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss improved from 0.84424 to 0.81684, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss improved from 0.81684 to 0.79120, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss improved from 0.79120 to 0.72951, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss improved from 0.72951 to 0.68667, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.68667\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss improved from 0.68667 to 0.59929, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.59929\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss improved from 0.59929 to 0.55882, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.55882\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss improved from 0.55882 to 0.47987, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss improved from 0.47987 to 0.45087, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 52: val_loss did not improve from 0.45087\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss improved from 0.45087 to 0.44063, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 54: val_loss did not improve from 0.44063\n",
      "\n",
      "                                                                           \n",
      "Epoch 55: val_loss did not improve from 0.44063\n",
      "\n",
      "                                                                           \n",
      "Epoch 56: val_loss did not improve from 0.44063\n",
      "\n",
      "                                                                           \n",
      "Epoch 57: val_loss did not improve from 0.44063\n",
      "\n",
      "                                                                           \n",
      "Epoch 58: val_loss did not improve from 0.44063\n",
      "\n",
      "                                                                           \n",
      "Epoch 59: val_loss did not improve from 0.44063\n",
      "\n",
      "                                                                           \n",
      "Epoch 60: val_loss did not improve from 0.44063\n",
      "\n",
      "                                                                           \n",
      "Epoch 61: val_loss improved from 0.44063 to 0.43688, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 62: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 63: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 64: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 65: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 66: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 67: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 68: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 69: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 70: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 71: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 72: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 73: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 74: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 75: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 76: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 77: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 78: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 79: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 80: val_loss did not improve from 0.43688\n",
      "\n",
      "                                                                           \n",
      "Epoch 81: val_loss did not improve from 0.43688\n",
      "\n",
      "{'batch_size': 48, 'dropout_rate': 0.39379815810825103, 'max_lr': 0.037908586566896725, 'n_hidden': 14, 'n_neurons': 64, 'rho': 0.9434736604683818}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.93745, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.93745 to 0.79763, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.79763 to 0.66120, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.66120 to 0.58888, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.58888 to 0.57004, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.57004\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.57004\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss improved from 0.57004 to 0.56346, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.56346\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.56346\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.30418842223891585, 'max_lr': 0.03524467827839681, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.9456794415505196}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.08365, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 1.08365 to 0.96819, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.96819 to 0.81295, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.81295 to 0.73311, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.73311 to 0.71849, saving model to best_weights.h5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.71849\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.71849\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.2868131802042167, 'max_lr': 0.04596884852375827, 'n_hidden': 4, 'n_neurons': 64, 'rho': 0.9364406019487773}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.45368, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.45368\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.45368\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.2923548284501222, 'max_lr': 0.03365988215311933, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.968132054966088}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.87366, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.87366 to 0.75018, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.75018 to 0.65992, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.65992 to 0.60001, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.60001 to 0.56400, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss improved from 0.56400 to 0.52484, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss improved from 0.52484 to 0.49969, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss improved from 0.49969 to 0.49362, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.49362\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.49362\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.49362\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.49362\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.49362\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.49362\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss improved from 0.49362 to 0.49099, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss improved from 0.49099 to 0.46830, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss improved from 0.46830 to 0.44783, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss improved from 0.44783 to 0.43146, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss improved from 0.43146 to 0.42775, saving model to best_weights.h5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.42775\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss improved from 0.42775 to 0.42748, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.42748\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.42748\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.3120898396558827, 'max_lr': 0.039823761978343794, 'n_hidden': 4, 'n_neurons': 128, 'rho': 0.7781139354088404}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.21906, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 1.21906\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 1.21906 to 0.98256, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.98256\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss improved from 0.98256 to 0.89708, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.89708\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.89708\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.89708\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.89708\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss improved from 0.89708 to 0.83864, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.83864\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss improved from 0.83864 to 0.50982, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.50982\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 42: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 52: val_loss did not improve from 0.50982\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss did not improve from 0.50982\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.2069931167643506, 'max_lr': 0.03035574459292204, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.9833289983187793}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.87585, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.87585 to 0.68632, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.68632 to 0.62793, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.62793\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss improved from 0.62793 to 0.51973, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss improved from 0.51973 to 0.47269, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.47269\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss improved from 0.47269 to 0.46017, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss improved from 0.46017 to 0.44924, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss improved from 0.44924 to 0.44698, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.44698\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.44698\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss improved from 0.44698 to 0.44109, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.44109\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.44109\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.44109\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.44109\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss improved from 0.44109 to 0.44021, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 52: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 54: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 55: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 56: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 57: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 58: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 59: val_loss did not improve from 0.44021\n",
      "\n",
      "                                                                           \n",
      "Epoch 60: val_loss did not improve from 0.44021\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.10377264984871482, 'max_lr': 0.03163731358160639, 'n_hidden': 4, 'n_neurons': 32, 'rho': 0.9677283695518762}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.57805, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.57805 to 0.54199, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.54199\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.54199 to 0.53712, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.53712 to 0.52336, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss improved from 0.52336 to 0.42993, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss improved from 0.42993 to 0.32989, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss improved from 0.32989 to 0.29685, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss improved from 0.29685 to 0.26760, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.26760\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.26760\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.26760\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss improved from 0.26760 to 0.24445, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.24445\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss improved from 0.24445 to 0.24331, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss improved from 0.24331 to 0.23897, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss improved from 0.23897 to 0.22971, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss improved from 0.22971 to 0.21195, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss improved from 0.21195 to 0.18389, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss improved from 0.18389 to 0.17413, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.17413\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.17413\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.22607148434359345, 'max_lr': 0.031426214824655394, 'n_hidden': 4, 'n_neurons': 32, 'rho': 0.9840693206957872}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.78669, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.78669\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.78669\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.78669\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.78669\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.78669\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.78669\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss improved from 0.78669 to 0.76638, saving model to best_weights.h5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 9: val_loss improved from 0.76638 to 0.74660, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss improved from 0.74660 to 0.70008, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss improved from 0.70008 to 0.64129, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.64129\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.64129\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.64129\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.64129\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.64129\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.64129\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss improved from 0.64129 to 0.60882, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss improved from 0.60882 to 0.54407, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.54407\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss improved from 0.54407 to 0.51656, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.51656\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss improved from 0.51656 to 0.48121, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss improved from 0.48121 to 0.43430, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss improved from 0.43430 to 0.42179, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.42179\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss did not improve from 0.42179\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss did not improve from 0.42179\n",
      "\n",
      "                                                                           \n",
      "Epoch 52: val_loss improved from 0.42179 to 0.38299, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss improved from 0.38299 to 0.33950, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 54: val_loss improved from 0.33950 to 0.33686, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 55: val_loss improved from 0.33686 to 0.33098, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 56: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 57: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 58: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 59: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 60: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 61: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 62: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 63: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 64: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 65: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 66: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 67: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 68: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 69: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 70: val_loss did not improve from 0.33098\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 71: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 72: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 73: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 74: val_loss did not improve from 0.33098\n",
      "\n",
      "                                                                           \n",
      "Epoch 75: val_loss did not improve from 0.33098\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.1586495809561046, 'max_lr': 0.03223352036493735, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.8749328315530722}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.63129, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.63129\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.63129\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.63129\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.63129 to 0.60637, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.60637\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.60637\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.60637\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss improved from 0.60637 to 0.52026, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss improved from 0.52026 to 0.36027, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.36027\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.36027\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.17692977266809273, 'max_lr': 0.032104311185174005, 'n_hidden': 4, 'n_neurons': 32, 'rho': 0.969319881501338}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.81665, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.81665 to 0.69675, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.69675\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.69675\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.69675\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.69675\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss improved from 0.69675 to 0.65103, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss improved from 0.65103 to 0.54963, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss improved from 0.54963 to 0.45328, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss improved from 0.45328 to 0.44798, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss improved from 0.44798 to 0.43215, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss improved from 0.43215 to 0.43061, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss improved from 0.43061 to 0.41097, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.41097\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.41097\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.2398680844787533, 'max_lr': 0.03016594486461487, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.8665602829563579}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.04539, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 1.04539 to 0.92632, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.92632 to 0.88356, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.88356 to 0.86593, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.86593 to 0.86005, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.86005\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.86005\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.12292274905380199, 'max_lr': 0.04890725527321044, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.96293423644629}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.61548, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.61548\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss improved from 0.61548 to 0.47958, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss improved from 0.47958 to 0.43181, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.43181\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.43181\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.43181\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.1887563246039722, 'max_lr': 0.03457089361433373, 'n_hidden': 4, 'n_neurons': 32, 'rho': 0.8823355684676387}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 1.21767, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 1.21767 to 0.66388, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss improved from 0.66388 to 0.53088, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss improved from 0.53088 to 0.48677, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss improved from 0.48677 to 0.48514, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.48514\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.48514\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.48514\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.48514\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.48514\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss improved from 0.48514 to 0.45105, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss improved from 0.45105 to 0.44359, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 23: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 24: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 25: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 26: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 27: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 28: val_loss did not improve from 0.44359\n",
      "\n",
      "                                                                           \n",
      "Epoch 29: val_loss improved from 0.44359 to 0.40980, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 30: val_loss did not improve from 0.40980\n",
      "\n",
      "                                                                           \n",
      "Epoch 31: val_loss did not improve from 0.40980\n",
      "\n",
      "                                                                           \n",
      "Epoch 32: val_loss did not improve from 0.40980\n",
      "\n",
      "                                                                           \n",
      "Epoch 33: val_loss improved from 0.40980 to 0.31288, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 34: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 35: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 36: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 37: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 38: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 39: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 40: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 41: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 42: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 43: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 44: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 45: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 46: val_loss did not improve from 0.31288\n",
      "\n",
      "                                                                           \n",
      "Epoch 47: val_loss improved from 0.31288 to 0.31134, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 48: val_loss did not improve from 0.31134\n",
      "\n",
      "                                                                           \n",
      "Epoch 49: val_loss did not improve from 0.31134\n",
      "\n",
      "                                                                           \n",
      "Epoch 50: val_loss improved from 0.31134 to 0.30956, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 51: val_loss improved from 0.30956 to 0.26708, saving model to best_weights.h5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Epoch 52: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 53: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 54: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 55: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 56: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 57: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 58: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 59: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 60: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 61: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 62: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 63: val_loss did not improve from 0.26708\n",
      "\n",
      "                                                                           \n",
      "Epoch 64: val_loss improved from 0.26708 to 0.24760, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 65: val_loss did not improve from 0.24760\n",
      "\n",
      "                                                                           \n",
      "Epoch 66: val_loss did not improve from 0.24760\n",
      "\n",
      "                                                                           \n",
      "Epoch 67: val_loss did not improve from 0.24760\n",
      "\n",
      "                                                                           \n",
      "Epoch 68: val_loss improved from 0.24760 to 0.24742, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 69: val_loss improved from 0.24742 to 0.23841, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 70: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 71: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 72: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 73: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 74: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 75: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 76: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 77: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 78: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 79: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 80: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 81: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 82: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 83: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 84: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 85: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 86: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 87: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 88: val_loss did not improve from 0.23841\n",
      "\n",
      "                                                                           \n",
      "Epoch 89: val_loss did not improve from 0.23841\n",
      "\n",
      "{'batch_size': 64, 'dropout_rate': 0.13630610468599874, 'max_lr': 0.030039196601075912, 'n_hidden': 9, 'n_neurons': 32, 'rho': 0.924936746090005}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.57505, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.57505\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.57505\n",
      "\n",
      "{'batch_size': 32, 'dropout_rate': 0.245028242120029, 'max_lr': 0.033962582446127196, 'n_hidden': 4, 'n_neurons': 32, 'rho': 0.9898858462668549}\n",
      "                                                                           \n",
      "Epoch 1: val_loss improved from inf to 0.54954, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 2: val_loss improved from 0.54954 to 0.54237, saving model to best_weights.h5\n",
      "\n",
      "                                                                           \n",
      "Epoch 3: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 4: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 5: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 6: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 7: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 8: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 9: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 10: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 11: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 12: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 13: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 14: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 15: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 16: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 17: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 18: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 19: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 20: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 21: val_loss did not improve from 0.54237\n",
      "\n",
      "                                                                           \n",
      "Epoch 22: val_loss did not improve from 0.54237\n",
      "\n",
      " 65%|█▉ | 30/46 [02:14<01:11,  4.48s/trial, best loss: 0.27081719040870667]\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'n_hidden': hp.choice('n_hidden', [4, 9, 14]),  # Hyperparameter space for the number of hidden layers\n",
    "    'n_neurons': hp.choice('n_neurons', [32, 64, 128]),  # Hyperparameter space for the number of neurons per layer\n",
    "    'max_lr': hp.loguniform('max_lr', np.log(0.03), np.log(0.05)),  # Hyperparameter space for the max learning rate (1cycle)\n",
    "    'rho': hp.loguniform('rho', np.log(0.7), np.log(0.99)),  # Hyperparameter space for the momentum\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.4),  # Hyperparameter space for the dropout rate\n",
    "    'batch_size': hp.choice('batch_size', [32, 48, 64])  # Hyperparameter space for the batch size\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=46, \n",
    "            early_stop_fn=no_progress_loss(8), trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': [0], 'dropout_rate': [0.10377264984871482], 'max_lr': [0.03163731358160639], 'n_hidden': [0], 'n_neurons': [0], 'rho': [0.9677283695518762]}\n",
      "Best Loss: 0.27081719040870667\n"
     ]
    }
   ],
   "source": [
    "best_trial = trials.best_trial\n",
    "best_params = best_trial[\"misc\"][\"vals\"]\n",
    "best_loss = best_trial[\"result\"][\"loss\"]\n",
    "\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Loss:\", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'dropout_rate': 0.10377264984871482,\n",
       " 'max_lr': 0.03163731358160639,\n",
       " 'n_hidden': 4,\n",
       " 'n_neurons': 32,\n",
       " 'rho': 0.9677283695518762}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_best_params = space_eval(search_space, best)\n",
    "final_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.27081719040870667,\n",
       " 'train_loss': 0.16132333874702454,\n",
       " 'status': 'ok',\n",
       " 'model': <keras.src.engine.sequential.Sequential at 0x275c95ffca0>,\n",
       " 'history': <keras.src.callbacks.History at 0x275b4b514e0>}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epoch_best = np.argmax(best_trial[\"result\"]['history'].history['val_accuracy']) + 1\n",
    "n_epoch_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_rate': 0.10377264984871482,\n",
       " 'n_hidden': 4,\n",
       " 'n_neurons': 32,\n",
       " 'rho': 0.9677283695518762}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_final_best_params = final_best_params.copy()\n",
    "mod_final_best_params.pop('max_lr')\n",
    "mod_final_best_params.pop('batch_size')\n",
    "mod_final_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1/3 [=========>....................] - ETA: 2s - loss: 1.6795 - accuracy: 0.3438\n",
      "Epoch 1: val_loss improved from inf to 0.84930, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 1s 137ms/step - loss: 1.4929 - accuracy: 0.3438 - val_loss: 0.8493 - val_accuracy: 0.5833\n",
      "Epoch 2/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8966 - accuracy: 0.5625\n",
      "Epoch 2: val_loss did not improve from 0.84930\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9518 - accuracy: 0.5417 - val_loss: 0.8628 - val_accuracy: 0.7083\n",
      "Epoch 3/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7229 - accuracy: 0.7188\n",
      "Epoch 3: val_loss improved from 0.84930 to 0.79615, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.6031 - accuracy: 0.7292 - val_loss: 0.7961 - val_accuracy: 0.6667\n",
      "Epoch 4/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5060 - accuracy: 0.7500\n",
      "Epoch 4: val_loss improved from 0.79615 to 0.67710, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.5751 - accuracy: 0.7292 - val_loss: 0.6771 - val_accuracy: 0.7083\n",
      "Epoch 5/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2838 - accuracy: 0.8750\n",
      "Epoch 5: val_loss did not improve from 0.67710\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2940 - accuracy: 0.8542 - val_loss: 1.3773 - val_accuracy: 0.6667\n",
      "Epoch 6/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.4767 - accuracy: 0.7500\n",
      "Epoch 6: val_loss improved from 0.67710 to 0.46903, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5137 - accuracy: 0.7917 - val_loss: 0.4690 - val_accuracy: 0.8750\n",
      "Epoch 7/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.7776 - accuracy: 0.7500\n",
      "Epoch 7: val_loss improved from 0.46903 to 0.39414, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6699 - accuracy: 0.7604 - val_loss: 0.3941 - val_accuracy: 0.8333\n",
      "Epoch 8/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.3210 - accuracy: 0.8125\n",
      "Epoch 8: val_loss improved from 0.39414 to 0.38904, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.3594 - accuracy: 0.8438 - val_loss: 0.3890 - val_accuracy: 0.8333\n",
      "Epoch 9/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2827 - accuracy: 0.9062\n",
      "Epoch 9: val_loss did not improve from 0.38904\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2786 - accuracy: 0.9167 - val_loss: 0.4677 - val_accuracy: 0.7917\n",
      "Epoch 10/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1801 - accuracy: 0.9375\n",
      "Epoch 10: val_loss improved from 0.38904 to 0.31305, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.2283 - accuracy: 0.9167 - val_loss: 0.3130 - val_accuracy: 0.8750\n",
      "Epoch 11/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.5593 - accuracy: 0.8125\n",
      "Epoch 11: val_loss improved from 0.31305 to 0.25513, saving model to best_model_weights.h5\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.3432 - accuracy: 0.8750 - val_loss: 0.2551 - val_accuracy: 0.9167\n",
      "Epoch 12/12\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2282 - accuracy: 0.8750\n",
      "Epoch 12: val_loss did not improve from 0.25513\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2757 - accuracy: 0.8750 - val_loss: 0.2594 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# Train a model with the best hyperparameters\n",
    "n_epochs=12\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=3, \n",
    "                               restore_best_weights = False)  # Define early stopping callback\n",
    "    \n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train) / final_best_params['batch_size']) * n_epochs, \n",
    "                             max_rate=final_best_params['max_lr'])\n",
    "    \n",
    "best_model_file = \"best_model_weights.h5\" # File to save the best weights\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(best_model_file, monitor=\"val_loss\", mode=\"min\", \n",
    "                                                    save_best_only=True, verbose=1) # Define checkpoint to save best weights\n",
    "\n",
    "\n",
    "best_model_use_val = build_model(**mod_final_best_params)\n",
    "history__use_val = best_model_use_val.fit(X_train_prep, y_train_pre_transf, epochs=n_epochs, batch_size=final_best_params['batch_size'], \n",
    "                         callbacks=[early_stop, checkpoint, onecycle], validation_data=(X_val_prep, y_val), verbose=1)\n",
    "\n",
    "best_model_use_val.load_weights(best_model_file) # reload the best weights saved by checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 1.3740 - accuracy: 0.4375\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.6354\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6979\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.6979\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8646\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7812\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.8125\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7708\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8333\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8854\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8333\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.9271\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2677 - accuracy: 0.8958\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8750\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "# Train another model with a full train set (train+val) using n_epoch_best instead of validation and early_stop\n",
    "\n",
    "X_train_full = np.concatenate((X_train_prep, X_val_prep), axis=0)\n",
    "y_train_full = np.concatenate((y_train_pre_transf, y_val), axis=0)\n",
    "\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train) / final_best_params['batch_size']) * n_epochs, \n",
    "                             max_rate=final_best_params['max_lr'])\n",
    "\n",
    "best_model_epoch = build_model(**mod_final_best_params)\n",
    "history_epoch = best_model_epoch.fit(X_train_prep, y_train_pre_transf, epochs=n_epoch_best, \n",
    "                                     batch_size=final_best_params['batch_size'], callbacks=[onecycle], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model saved from hyperopt direcly\n",
    "\n",
    "best_model_saved = best_trial[\"result\"]['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evalution using Final_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Final_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test_set = Final_test_set_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>Label_1</th>\n",
       "      <th>Label_2</th>\n",
       "      <th>Label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "15                5.0               2.0                3.5               1.0   \n",
       "16                6.3               3.3                6.0               2.5   \n",
       "17                4.4               3.0                1.3               0.2   \n",
       "18                4.9               3.0                1.4               0.2   \n",
       "19                6.3               2.9                5.6               1.8   \n",
       "20                5.4               3.7                1.5               0.2   \n",
       "21                6.2               3.4                5.4               2.3   \n",
       "22                7.7               2.6                6.9               2.3   \n",
       "23                5.2               4.1                1.5               0.1   \n",
       "24                5.0               3.3                1.4               0.2   \n",
       "25                5.2               3.4                1.4               0.2   \n",
       "26                4.6               3.6                1.0               0.2   \n",
       "27                4.6               3.4                1.4               0.3   \n",
       "28                5.0               3.4                1.5               0.2   \n",
       "29                6.5               2.8                4.6               1.5   \n",
       "\n",
       "    species Label_1 Label_2 Label_3  \n",
       "15        1       C       C       C  \n",
       "16        2       D       A       B  \n",
       "17        0       B       C       B  \n",
       "18        0       A       A       C  \n",
       "19        2       C       C       D  \n",
       "20        0       B       A       D  \n",
       "21        2       A       A       B  \n",
       "22        2       B       C       B  \n",
       "23        0       D       D       C  \n",
       "24        0       B       A       C  \n",
       "25        0       B       A       D  \n",
       "26        0       A       C       B  \n",
       "27        0       A       A       C  \n",
       "28        0       A       D       D  \n",
       "29        1       D       A       C  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test_set.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make prediction with the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if there is any column that is not numeric \n",
    "Final_test_set_cat = Final_test_set.select_dtypes(exclude=[np.number])\n",
    "#Final_test_set_cat.head()\n",
    "\n",
    "# Add categorical columns that are number manually can convert them to categorical type\n",
    "Final_test_set[other_cat_col] = Final_test_set[other_cat_col].astype(\"category\")\n",
    "#Final_test_set[other_cat_col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test_set_cat_encoded = ordinal_encoder.fit_transform(Final_test_set_cat)\n",
    "#print(Final_test_set_cat_encoded)\n",
    "\n",
    "Final_test_set[Final_test_set_cat.columns.tolist()] = Final_test_set_cat_encoded\n",
    "Final_test_set[Final_test_set_cat.columns.tolist()] = Final_test_set[Final_test_set_cat.columns.tolist()].astype(\"category\")\n",
    "#Final_test_set[Final_test_set_cat.columns.tolist()].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test = Final_test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15\n",
       "2    10\n",
       "1     5\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_test[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Final_test = Final_test.drop(\"species\", axis=1)\n",
    "y_Final_test = Final_test[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of components:  7\n",
      "shape after transformation:  (30, 7)\n"
     ]
    }
   ],
   "source": [
    "#Transform the X_test as the train set has been transformed\n",
    "X_Final_test_prep = full_pl.transform(X_Final_test)\n",
    "#print('shape before PCA: ', X_train_prep.shape)\n",
    "\n",
    "if use_PCA:\n",
    "    X_Final_test_prep = pca.transform(X_Final_test_prep)\n",
    "    print('number of components: ', pca.n_components_)\n",
    "\n",
    "print('shape after transformation: ', X_Final_test_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use 3 models to make prediction\n",
    "\n",
    "y_pred_use_val_prob = best_model_use_val.predict(X_Final_test_prep) # use own validation\n",
    "y_pred_epoch_prob = best_model_epoch.predict(X_Final_test_prep) # use known best n_epochs\n",
    "y_pred_saved_prob = best_model_saved.predict(X_Final_test_prep) # use the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_probabilities_to_labels(predictions):\n",
    "    labels = np.argmax(predictions, axis=1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_use_val_label = convert_probabilities_to_labels(y_pred_use_val_prob)\n",
    "y_pred_epoch_label = convert_probabilities_to_labels(y_pred_epoch_prob)\n",
    "y_pred_saved_label = convert_probabilities_to_labels(y_pred_saved_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate the model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_evaluate_plot(y_test, y_pred, model = 1):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Define class names\n",
    "    if model == 1:\n",
    "        classes = ['Class 0', 'Class 1']\n",
    "    elif model == 2:\n",
    "        classes = ['Class 1', 'Class 2']\n",
    "    elif model == 3:\n",
    "        classes = ['Class 0', 'Class 1', 'Class 2']\n",
    "    else:\n",
    "        sys.exit(\"n_class can only be 2 or 3\")\n",
    "    \n",
    "    # Define plot parameters\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\", xticklabels=classes, yticklabels=classes, annot_kws={\"fontsize\":16})\n",
    "    \n",
    "    # Set plot labels\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"====================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own validation net performance evaluation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.80      0.81        30\n",
      "weighted avg       0.92      0.90      0.89        30\n",
      "\n",
      "====================================================================================\n",
      "n_epoch Model net performance evaluation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.80      0.81        30\n",
      "weighted avg       0.92      0.90      0.89        30\n",
      "\n",
      "====================================================================================\n",
      "Saved Model performance evaluation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.80      0.81        30\n",
      "weighted avg       0.92      0.90      0.89        30\n",
      "\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# use_val performance\n",
    "print(\"Own validation net performance evaluation\")\n",
    "perf_evaluate_plot(Final_test[\"species\"], y_pred_use_val_label, model=3)\n",
    "\n",
    "# best n_epoch performance\n",
    "print(\"n_epoch Model net performance evaluation\")\n",
    "perf_evaluate_plot(Final_test[\"species\"], y_pred_epoch_label, model=3)\n",
    "\n",
    "# Saved model performance\n",
    "print(\"Saved Model performance evaluation\")\n",
    "perf_evaluate_plot(Final_test[\"species\"], y_pred_saved_label, model=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final words\n",
    "\n",
    "The result based on the saved model is not so good. The two-level DL model performed better than this multiclass version. It was actually a bit of a surprise becuase this model was the best-performing model when tested on the actual dataset of the problem that it was built to solve (not IRIS). Out of the three final models, the best model automatically saved from the training phase is much much better that the retrained model, while their performances were comparable on the actual dataset. This highlights the fact that machine learning can be specific and customised solution is usually needed to treat each problem.\n",
    "\n",
    "Anyways, the idea of this notebook is to demonstrate how to use deep learning neural network to perform classification problem when the model has two-level architecture. It is possible to compare the performance of the classifier of each level to the global performance to observe the performance drop caused by error propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
